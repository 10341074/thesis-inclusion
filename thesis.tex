\documentclass[10pt, a4paper, twoside, openright]{book}
% \usepackage[english]{babel}
\usepackage[italian, english]{babel}

\usepackage[utf8]{inputenc} % needed for bibtex
\usepackage{fontenc}
\usepackage{mathrsfs}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
%\usepackage{nccmath} % mfrac
%\mathbb needs amsfonts or amssymb
\usepackage{amsfonts}
\usepackage{bm} % bold symbols math

% \usepackage[overload]{empheq} % left\{ for align % no crash kile ?
\usepackage{cases}
\usepackage[usenames,dvipsnames]{xcolor} % before tikz, options for more colors
\definecolor{light-gray}{gray}{0.95}

% \usepackage[sort, numbers]{natbib}
% \setcitestyle{square}
% \usepackage{bbold}

\usepackage{graphicx}

\usepackage{booktabs}
\usepackage{caption}
\usepackage{subfig}
% \captionsetup[figure]{width=.85\textwidth}
\captionsetup[subfigure]{margin=0.5cm}
\usepackage{tikz}
\usetikzlibrary{matrix}
\usetikzlibrary{positioning}
% set arrows as stealth fighter jets
\tikzset{>=stealth}
% bezier
\usetikzlibrary{decorations.pathreplacing}
\tikzset{%
  show curve controls/.style={
    postaction={
      decoration={
        show path construction,
        curveto code={
          \draw [blue] 
            (\tikzinputsegmentfirst) -- (\tikzinputsegmentsupporta)
            (\tikzinputsegmentlast) -- (\tikzinputsegmentsupportb);
          \fill [red, opacity=0.5] 
            (\tikzinputsegmentsupporta) circle [radius=.5ex]
            (\tikzinputsegmentsupportb) circle [radius=.5ex];
        }
      },
      decorate
}}}
\tikzstyle{mybox} = [draw=gray, fill=light-gray, very thick,
    rectangle, rounded corners, inner sep=10pt, inner ysep=20pt]
\tikzstyle{mytitle} =[fill=gray, text=white]

% plots
\usepackage{pgfplots}

%\usepackage{color}

\usepackage{xcolor}
\definecolor{bookColor}{cmyk}{1	, 1  , 0   , 0}  % 0.90\% of black
%\color{bookColor}

\usepackage{hyperref}
% \hypersetup{pdftex,colorlinks=true,allcolors=blue}

% \usepackage[hidelinks]{hyperref}
% \usepackage{xcolor}
\AtBeginDocument{
\hypersetup{
% %     colorlinks=false,
% %     citebordercolor = {Green},
% %     filebordercolor = {Blue}
    linkbordercolor = {Blue}
% %     linkcolor={red!50!black},
% %     citecolor={blue!50!black},
% %     urlcolor={blue!80!black}
}
}


\usepackage{hypcap}
\usepackage{etoolbox}

\usepackage{csquotes}
%\usepackage[autostyle, italian=guillemets]{csquotes}

% \usepackage[chapter]{placeins} % floatbarrier

\usepackage[backend=biber, style=alphabetic]{biblatex}
\addbibresource{sources.bib}
\DeclareFieldFormat[article]{title}{\textit{#1}}

\theoremstyle{definition}
\newtheorem{definition}[subsection]{Definition}
\theoremstyle{plain}
\newtheorem{theorem}[subsection]{Theorem}
\theoremstyle{plain}
\newtheorem{corollary}[subsection]{Corollary}
\theoremstyle{plain}
\newtheorem{proposition}[subsection]{Proposition}
\theoremstyle{plain}
\newtheorem{remark}[subsection]{Remark}
\theoremstyle{plain}
\newtheorem{lemma}[subsection]{Lemma}
\theoremstyle{plain}
\newtheorem{example}[subsection]{Example}

\theoremstyle{plain}
\newtheorem{assumption}[subsection]{Assumption}
\theoremstyle{plain}
\newtheorem{problem}[subsection]{Problem}

\DeclareMathOperator{\divergence}{div}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\real}{Re}
\DeclareMathOperator{\imag}{Im}

\providetoggle{verbose}
\settoggle{verbose}{true}
\providetoggle{old}
\settoggle{old}{false}
\providetoggle{fig}
\settoggle{fig}{true}
% \toggletrue{paper}
% \togglefalse{paper}
\renewcommand{\i}{\textup{i}}
\let\phi\varphi
\let\epsilon\varepsilon
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amssymb,tikz}

\newcommand{\mysetminusD}{\hbox{\tikz{\draw[line width=0.6pt,line cap=round] (3pt,0) -- (0,6pt);}}}
\newcommand{\mysetminusT}{\mysetminusD}
\newcommand{\mysetminusS}{\hbox{\tikz{\draw[line width=0.45pt,line cap=round] (2pt,0) -- (0,4pt);}}}
\newcommand{\mysetminusSS}{\hbox{\tikz{\draw[line width=0.4pt,line cap=round] (1.5pt,0) -- (0,3pt);}}}

\newcommand{\mysetminus}{\mathbin{\mathchoice{\mysetminusD}{\mysetminusT}{\mysetminusS}{\mysetminusSS}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\usepackage{environ}
\NewEnviron{mybox}{%
\begin{center}
\colorbox{light-gray}{\color{black}\parbox{\textwidth}{%
% \fcolorbox{gray}{light-gray}{
\BODY
}}
\end{center}
}

\usepackage{fancyhdr}
\newcommand{\fncyblank}{\fancyhf{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% abstract e sommario
\newenvironment{abstract} %
{\cleardoublepage
\fncyblank\null\vfill\begin{center} %
\bfseries\abstractname
\end{center}} %
{\vfill\null}
\newenvironment{abstractone} %
{\clearpage
\fncyblank\null\vfill\begin{center} %
\bfseries\abstractname
\end{center}} %
{\vfill\null}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Numerical Reconstruction of Inclusions in Electrical Conductors}
\author{Giacomo Milan}
\date{3 Ottobre 2017}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\frontmatter
\begin{titlepage}
    \begin{center}
        \Large
        \textsc{Politecnico di Milano}\\
        \large
        Scuola di Ingegneria Industriale e dell'Informazione\\
        Corso di Laurea in Ingegneria Matematica\\
        
        \vspace{1cm}
        \includegraphics[width=0.5\textwidth]{fig/logo}
        
%       \vfill
%       \normalsize
%       \large
        

        \vspace{1cm}
        \huge
        \textsc{Numerical Reconstruction of Inclusions in Electrical Conductors}
        
        \vspace{3cm}
        \begin{flushleft}
        \large
        Relatore: Prof. Michele Di Cristo         
        \end{flushleft}
        \vspace{0.2cm}
        \begin{flushright}
        \normalsize
        Tesi di Laurea di: \\
        \large
        {Giacomo Milan \\ Matr. 841530}         
        \end{flushright}
        \normalsize
        \vfill
        Anno Accademico 2016-2017
        
    \end{center}
\end{titlepage}

\begin{abstract}
 In this work we show some of the main methods 
 to approach the inverse inclusion problem, which consists in determining 
 the support of an unknown conductor object embedded in a background material. 
 Discontinuous conductivity requires a separate analysis from the issue 
 of the inverse impedance problem, which has been widely treated in literature. 
 Furthermore we conclude the exposition with some numerical simulations 
 of the algorithms proposed.
\end{abstract}
\selectlanguage{italian}
\begin{abstractone}
 In questo lavoro mostriamo i principali metodi per avvicinare il problema
 inverso dell'inclusione, il quale consiste nella determinazione del 
 supporto di un corpo di conduttività incognita, contenuto in una regione di fondo.
 La discontinuità della conduttività richiede una analisi distinta dal problema
 inverso dell'impedenza, largamente trattato in letteratura.
 Inoltre concludiamo la presente esposizione con alcune simulazioni numeriche 
 degli algoritmi proposti.
\end{abstractone}
\selectlanguage{english}

\selectlanguage{italian}
\begin{abstractone}
% \chapter*{Sommario}
In questa tesi prenderemo in esame il \emph{problema inverso dell'impedenza}, 
che descrive il comportamento di un campo elettromagnetico definito in un 
ambiente con conduttività variabile.
Il problema proposto per la prima volta alla comunità scientifica da 
Calder\'on \cite{Ca}, è diventato un classico esempio di problema inverso, 
noto come Electrical Impedance Tomography (EIT),
in cui si chiede di stimare 
la conduttività.        
% i parametri che compaiono nel modello matematico, 
% nel nostro caso la conduttività, avendo a disposizione la conoscenza completa 
% o parziale della mappa che descrive le grandezze misurabili (output) a partire dai 
% dati iniziali (input).
Questo genere di problemi è di cruciale importanza nelle applicazioni, dove
molto spesso lo scenziato non può accedere allo spazio in cui è definito il modello 
matematico e deve accontentarsi di misurazioni all'esterno di esso. 
Innumerevoli esempi sono dati da applicazioni non invasive in ambito biomedicale, 
oltre a Raggi X o RMI, 
dove la presenza di muscoli, cartilagini, ossa, tessuti molli o duri, determina 
la variabilità della conduttività. La scala di valori dei parametri è ancora 
più ampia in ambito geofisico, dove si vuole stimare le proprietà del 
sottosuolo o individuare eventuali corpi estranei.
L'equazione dell'impedenza per il potenziale $u$ è la seguente
$$\left\{\begin{array}{ll}
\mathrm{div}\big(\gamma\nabla u\big)=0, & \textrm{in }\Omega,\\
u=f, & \textrm{on }\partial\Omega,
\end{array}\right.$$
dove $f\in H^{1/2}(\partial \Omega)$ è il potenziale fissato al bordo, e 
$\partial u/\partial \nu$ è la densità di corrente.
L'unicità di $\gamma$ in $\mathbb{R}^3$ è stata risolta da Sylvester e Uhlmann 
in \cite{Sy-Uh} e in \cite{Sy-Uh86}, costruendo un insieme di soluzioni definite in 
tutto $\mathbb{R}^3$, con andamento asintotico esponenziale, ispirandosi al lavoro 
di Calder\'on.
\par
In questa tesi tratteremo un caso particolare dell'impedenza, noto come \emph{problema inverso 
dell'inclusione}, in cui, nota la conduttività del materiale di fondo $a(x)$, si chiede di 
stimare il supporto di una regione incognita $D\subset \Omega$ di conduttività $a(x) + b(x)$, 
con $b(x)$ incognita. La discontinuità della conduttività lungo la superficie $\partial D$ 
richiede una analisi a parte del problema, 
del quale ci occuperemo in tutti gli aspetti. 
% Dato per consolidata la 
% \emph{buona posizione} del problema diretto, ovvero \emph{esistenza}, \emph{unicità} e \emph{dipedendenza 
% continua} della soluzione $u$ dai dati, prenderemo in esame per il problema inverso
% \begin{enumerate}
%  \item l'\emph{unicità} della regione $D$ e della conduttività $a(x) + b(x)\chi_D$ incognite, data 
%  la completa conoscenza dei dati di Cauchy $u|_{\partial \Omega}$, 
%  $\partial_\nu u|_{\partial \Omega}$ al bordo;
%  \item la \emph{dipendenza continua dai dati}, necessaria per avere una formulazione stabile, 
%  che garantisca un controllo dell'errore della soluzione calcolata a partire da piccoli errori 
%  nei dati;
%  \item il \emph{metodo numerico} per ricostruire la regione incognita $D$.
% \end{enumerate}
Il principale risultato di unicità per determinare $a(x)$ e $b(x)$ è stato dimostrato da Isakov in \cite{Is88}, 
mentre Alessandrini e Di Cristo in \cite{Al-DC} hanno dimostrato un dipendenza di tipo logaritmico nella 
stima di stabilità per il supporto $\partial D$.
Nel seguito ci limiteremo al caso con conduttività costante, scegliendo in particolare $a(x)=1$ e $b(x)=k-1$ in $D$.
Prenderemo in considerazione alcuni metodi già impiegati nell'affrontare il problema, 
come il \emph{linear sampling method} nel Capitolo \ref{ch:linear-sampling} e il 
\emph{factorization method} nel Capitolo \ref{ch:factorization}. Nel Capitolo \ref{ch:reciprocity} 
esamineremo il \emph{reciprocity gap method}, già usato per il problema inverso dello 
scattering, che verrà confrontato con i precedenti metodi nel Capitolo \ref{ch:link}.
Infine nel Capitolo \ref{ch:implementation} proporremo i risultati ottenuti 
dall'implementazione numerica degli algoritmi proposti.
\end{abstractone}
\selectlanguage{english}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Ringraziamenti}
{\parindent0pt
Grazie a mio padre e a mia madre, per esserci ed avermi sostenuto;

grazie a Irene, Stefano, Filippo;

grazie a chi in questi anni mi ha visto poco e mi ha pensato tanto;

grazie al professor. Di Cristo, per aver creduto in me, per averlo fatto in modo sincero, 
ed avermi guidato lungo il percorso;

grazie al professor. Micheletti per i preziosi consigli;

grazie ai professori che sono stati maestri per me;

grazie a tutti voi, miei compagni di viaggio, siete stati tanti, diversi e unici.
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \maketitle
\tableofcontents
\listoffigures
%\listoftables
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mainmatter
\chapter{Introduction}
In this thesis we will consider the inverse conductivity problem, or Electrical Impedance Tomography (EIT),
that was proposed to the mathematical community by Calder\'on \cite{Ca} in 1980.
This problem is a classical problem in applications and its goal is to determine the conductivity of a body by making electrostatic
measurements on the boundary. Since different materials display different electrical properties, the aim is to give a pointwise
description of the conductivity and thus to image the internal geometry and the features of the body, performing currents and voltages measurements.
These problems arise in non invasive techniques and they may be applied in various fields. For instance, there has been a
great development in medical applications as a possible diagnostic tool.
Muscles tissues, fat tissues, bones, inner organs, lungs have different conductive properties, thus it should be possible, in principle,
to give an imaging method that in some cases could accomplish other well known techniques such as X-rays or MRI, providing different information.

Keeping in mind such medical applications, we will focus on a special instance of the conductivity problem known as the Inverse Inclusion Problem.
Denoting by $\Omega$ a conductor body, whose conductivity is known, let us assume that in a region $D$ compactly contained in $\Omega$,
the conductivity is unknown and different from the conductivity of the surrounding material. If $\gamma(x)$ is the conductivity function,
assuming that the conductivity in $\Omega$ is equal to $1$ and the conductivity in $D$ is equal to some unknown constant $k$, $k\neq1$,
$\gamma$ reads
$$\gamma(x)=1+(k-1)\chi_D,$$
where $\chi_D$ is the characteristic function of the set $D$.

Prescribing a voltage $f\in H^{1/2}(\partial\Omega)$, the induced potential $u$ is the solution of the problem
$$\left\{\begin{array}{ll}
\mathrm{div}\big((1+(k-1)\chi_D)\nabla u\big)=0, & \textrm{in }\Omega,\\
u=f, & \textrm{on }\partial\Omega.
\end{array}\right.$$
The current density that we measure on the boundary is given by the normal derivative of the potential
$\partial_\nu u|_{\partial\Omega}$. The idea is to recover information on the inclusion $D$ performing infinitely many
boundary measurements. For this purpose we define the so called Dirichlet--to--Neumann map
$$\begin{array}{crcl}
\Lambda_D : & H^{1/2}(\partial\Omega) & \longrightarrow & H^{-1/2}(\partial\Omega)\\
            &   f                     & \longmapsto & \partial_\nu u|_{\partial\Omega},
\end{array}$$
which maps the voltage $f$ to the corresponding current density measured on the boundary.
The inverse problem we are addressing to is to determine $D$ from a knowledge of the map $\Lambda_D$.
We can divide this problem into three main issues.
\begin{enumerate}
\item Uniqueness: this means if it is possible to determine uniquely the inclusion $D$ from the Dirichlet--to--Neumann map.
\item Stability: how the inclusion $D$ depends on the Dirichlet--to--Neumann map. In particular it is interesting
to determine the modulus of continuity of such a dependence.
\item Numerical Reconstruction: provide numerical algorithms to find an approximation of the inclusion $D$ given the boundary data.
\end{enumerate}
In this thesis we will focus our attention on the numerical reconstruction issue.
Specifically we will derive a new method to reconstruct $D$ and we will compare it with several existing ones
emphasizing advantages and disadvantages.

In the next two sections of this introduction, we will review the main results of uniqueness and stability
for the inverse conductivity problem and the inverse inclusion problem respectively.


%\chapter{The Inverse Inclusion Problem}
%\label{cap2}
\section{The Inverse Conductivity Problem}
\label{globuniq}
Let $\Omega\subset\mathbb{R}^{n}$ be a domain with Lipschitz boundary and let
us denote with $\gamma(x)$ the electrical conductivity of $\Omega$.
For $f\in H^{1/2}(\partial\Omega)$,
the potential $u\in H^{1}(\Omega)$ will be the weak
solution of the boundary value problem
\begin{eqnarray}
\label{eqcond}  
&\mathrm{div}(\gamma\nabla u)=0\qquad&\textrm{in }\Omega,\\
\label{dirdatum}
&u=f\qquad&\textrm{on }\partial\Omega.
\end{eqnarray}
Since for any $f\in H^{1/2}(\partial\Omega)$, there exists a unique solution $u\in H^{1}(\Omega)$
to the Dirichlet problem (\ref{eqcond})--(\ref{dirdatum}),
we can define the Dirichlet--to--Neumann map $\Lambda_{\gamma}$ as follows
\begin{equation}
\label{dirtoneum}
\begin{array}{crcl}
\Lambda_{\gamma}:&H^{1/2}(\partial\Omega)&\longrightarrow&H^{-1/2}(\partial\Omega)\\
&f&\longmapsto&\left(\gamma\partial_\nu u\right)|_{\partial\Omega}.
\end{array}
\end{equation}
Using the divergence theorem we have
\begin{equation}
\label{Qmap}
Q_{\gamma}(f)\coloneqq\int_{\Omega}\gamma|\nabla u|^{2}dx
=\int_{\partial\Omega}\Lambda_\gamma(f)fd\sigma,
\end{equation}
where $d\sigma$ denotes surface measure and $u$ is the solution
of (\ref{eqcond})--(\ref{dirdatum}).

Calder\'on considered the map
\begin{equation}
\label{Q}
Q\,:\,\gamma\longrightarrow Q_{\gamma},
\end{equation}
which is the quadratic form associated to the linear map
$\Lambda_{\gamma}(f)$ and it represents
the energy needed to maintain the potential
$f$ at the boundary.
In \cite{Ca} the question was reduced to whether the products of gradients
of harmonic functions is dense in $L^{2}(\Omega)$.

Calder\'on
took the following harmonic functions
\begin{equation}
\label{caldfun}
u(x)=\mathrm{e}^{x\cdot\rho},\qquad v(x)=\mathrm{e}^{-x\cdot\overline{\rho}},
\end{equation}
where $\rho\in\mathbb{C}^{n}$ with $\rho\cdot\rho=0$ and he
showed that if the Fr\'echet derivative of $Q$
at $\gamma=\mathrm{const.}$ in the direction $h$ is zero,
then $h=0$, that is $dQ|_{\gamma=\mathrm{const.}}$ is injective.
Calder\'on also observed that using the solutions (\ref{caldfun})
one can find an approximation for the conductivity $\gamma$ of the form
\begin{equation}
\label{1+gamma}
\gamma=1+h,
\end{equation}
with $h$ small enough in $L^{\infty}$ norm.
Thus he was able to reconstruct conductivities $\gamma$ of the form (\ref{1+gamma}).

Studying Calder\'on's solutions (\ref{caldfun}) Sylvester and Uhlmann in \cite{Sy-Uh}
(see also \cite{Sy-Uh86})
constructed exponentially growing solutions of $L_{\gamma}(u)=\mathrm{div}(\gamma\nabla u)=0$
in $\Omega$ of the form
$$u(x,\xi)=\mathrm{e}^{x\cdot\xi}\gamma^{-1/2}(1+\psi(x,\xi)),$$
where $\xi\in\mathbb{C}^n$ with $\xi\cdot\xi=0$
and $\psi\to0$ as $|\xi|\to+\infty$, see the subsequent Theorem~\ref{expgrowsol},
that allow them to prove the following identifiability result.

\begin{theorem}
\label{sy-ul-teo}
Let $\Omega\subset\mathbb{R}^n$, $n\geq3$, be a domain with
$C^{\infty}$ boundary. Suppose $\gamma_1, \gamma_2\in C^{\infty}(\overline{\Omega})$,
$\gamma_1$, $\gamma_2>0$ in $\overline{\Omega}$, and
\begin{equation}
\label{1=2}
Q_{\gamma_1}(f)=Q_{\gamma_2}(f)\qquad\textrm{for all }
f\in H^{1/2}(\partial\Omega),
\end{equation}
then
$$\gamma_1=\gamma_2.$$
\end{theorem}
\begin{proof}
Let $\gamma=(1-t)\gamma_1+t\gamma_2$.
For each $t\in[0,1]$, Sylvester and Uhlmann have proved the following theorem.

\begin{theorem}
\label{expgrowsol}
Let $\Omega\subset\subset\mathbb{R}^n$, $n\geq3$, be a bounded domain
and $s>n/2$.
There exist constants $c_1$ and $c_2$ such that if
$$\xi\cdot\xi=0,\qquad\xi\in\mathbb{C}^n,$$
and
$$|\xi|>c_1\Vert q\Vert_{H^s(\Omega)},
\qquad q=\frac{\Delta\gamma^{1/2}}{\gamma^{1/2}},$$
then there exists $u(x,\xi,t)$ solving (\ref{eqcond})--(\ref{dirdatum})
such that
\begin{equation}
\label{opticsol}
u(x,\xi,t)=\mathrm{e}^{x\cdot\xi}\gamma^{-1/2}(1+\psi(x,\xi,t)),
\end{equation}
where
\begin{equation}
\label{optics2}
\Vert\psi\Vert_{H^s(\Omega)}\leq\frac{c_2}{|\xi|}
\Vert q\Vert_{H^s(\Omega)}.
\end{equation}
In addition,
\begin{equation}
\label{opt}
u(x,\xi,0)|_{\partial\Omega}=u(x,\xi,1)|_{\partial\Omega}.
\end{equation}
\end{theorem}
Note that for $|\xi|$ large, these solutions behave like Calder\'on's
exponential solutions (\ref{caldfun}).

Let
\begin{align*}
&w(t)=u(x,\xi_1,t),&v(t)=u(x,\xi_2,t).
\end{align*}
We denote by $Q_{\gamma}(f,g)$ the bilinear form obtained from the quadratic
form by polarization (or parallelogram identity). According to \eqref{1=2},
$$0=Q_{\gamma_1}(w(0)|_{\partial\Omega},v(0)|_{\partial\Omega})-
Q_{\gamma_2}(w(0)|_{\partial\Omega},v(0)|_{\partial\Omega}).$$
Applying \eqref{opt},
$$0=Q_{\gamma_1}(w(0)|_{\partial\Omega},v(0)|_{\partial\Omega})-
Q_{\gamma_2}(w(1)|_{\partial\Omega},v(1)|_{\partial\Omega})$$
or
$$0=\int_0^1dt\{Q_{\gamma}(w|_{\partial\Omega},v|_{\partial\Omega})\}^{\bm\cdot},
\qquad(\,\,)^{\bm\cdot}=\frac{d}{dt},$$
which becomes
\begin{equation}
\label{sul}
0=\int_0^1dt\left\{\int_{\Omega}\dot{\gamma}\nabla w\cdot\nabla v
+\int_{\partial\Omega}\gamma\left(\dot{w}\frac{\partial v}{\partial\nu}+
\dot{v}\frac{\partial w}{\partial\nu}\right)\right\},
\end{equation}
where we have integrated by parts.
The following lemma holds (see \cite[Lemma 2.8]{Sy-Uh}).
\begin{lemma}
\label{lemmasu}
$$\int_0^1dt\int_{\partial\Omega}\gamma\left(\dot{w}\frac{\partial v}{\partial\nu}+
\dot{v}\frac{\partial w}{\partial\nu}\right)=0.$$
\end{lemma}
Application of the lemma to \eqref{sul} yields
\begin{equation}
\label{sul2}
0=\int_0^1dt\int_{\mathbb{R}^n}\dot{\gamma}\nabla w\cdot\nabla v,
\end{equation}
where we have replaced the domain of integration by all of $\mathbb{R}^n$.
It is possible to extend $\dot{\gamma}$ to be identically zero outside
$\Omega$. The identity
$$L_{\gamma}(uw)=wL_{\gamma}v+vL_{\gamma}w
+2\gamma\nabla v\cdot\nabla w,$$
combined with \eqref{sul2} and an integration by parts yields
$$0=\int_0^1dt\int_{\Omega}L_{\gamma}\left(
\frac{\dot{\gamma}}{\gamma}\right)vw.$$
If we recall \eqref{opticsol}, this becomes
\begin{equation}
\label{sul3}
0=\int_0^1dt\int_{\mathbb{R}^n}\frac{1}{\gamma}
L_{\gamma}\left(\frac{\dot{\gamma}}{\gamma}\right)
\mathrm{e}^{x\cdot(\xi_1+\xi_2)}(1+\psi(x,\xi_1,t))
(1+\psi(x,\xi_2,t)),
\end{equation}
we choose
\begin{align*}
&\xi_1=i\left(\frac{k}{2}+r\eta\right)+\zeta,
&\xi_2=i\left(\frac{k}{2}-r\eta\right)-\zeta,
\end{align*}
where $k$ is an arbitrary real vector, $r$ is an arbitrary number, and
$\eta$ and $\zeta$ are real vectors chosen to satisfy
\begin{align*}
\langle k,\eta\rangle\,=\,\langle k,\zeta \rangle \,=\,\langle \eta,\zeta\rangle=0,\\
|\eta|=1,\quad|\zeta|^2=\frac{|k|^2}{4}+r^2.
\end{align*}
With this choice of $\xi_1$ and $\xi_2$, \eqref{sul3} becomes
$$0=\int_0^1dt\int_{\mathbb{R}^n}\frac{1}{\gamma}
L_{\gamma}\left(\frac{\dot{\gamma}}{\gamma}\right)
\mathrm{e}^{x\cdot k}(1+\psi(x,\xi_1,t))
(1+\psi(x,\xi_2,t)).$$
Now let $r$ approach infinity and apply \eqref{optics2} to obtain
$$0=\int_{\mathbb{R}^n}\left[\int_0^1dtL_{\gamma}\left(\frac{\dot{\gamma}}{\gamma}\right)
\frac{1}{\gamma}
\right]\mathrm{e}^{ix\cdot k}\qquad\textrm{for all }k\in\mathbb{R}^n.$$
The inversion theorem for the Fourier transform implies
$$\int_0^1dtL_{\gamma}\left(\frac{\dot{\gamma}}{\gamma}\right)
\frac{1}{\gamma},$$
or
$$0=\int_0^1dt[\Delta(\log\gamma)+\frac{1}{2}|\nabla\log\gamma|^2]^{\bm{\cdot}}.$$
By the fundamental theorem calculus
$$0=\Delta(\log\gamma_2-\log\gamma_1)+\frac{1}{2}
\left[|\nabla(\log\gamma_2)|^2-|\nabla(\log\gamma_1)|^2\right],$$
or
$$0=\Delta(\log\gamma_2-\log\gamma_1)+\frac{1}{2}\nabla
(\log\gamma_2+\log\gamma_1)\cdot\nabla(\log\gamma_2-\log\gamma_1),$$
which is a linear equation for the function $\log\gamma_2-\log\gamma_1$, which vanishes
on $\partial\Omega$. The maximum principle applies to give
$$\log\gamma_2-\log\gamma_1\equiv0\qquad\textrm{in }\Omega,$$
or
$$\gamma_2\equiv\gamma_1\qquad\textrm{in }\Omega.$$
\end{proof}


The proof of Theorem \ref{sy-ul-teo} is based on the fact that
the set $\{\xi\in\mathbb{C}^n\,:\,\xi\cdot\xi=0\}$
forms a codimension-2 real submanifold of $\mathbb{C}^n$.
Sylvester and Uhlmann exploit the extra freedom to gain information
using the Fourier transform.
This method is not valid any longer if we consider the dimension $n=2$.
In \cite{Na96} Nachman proved that one can uniquely determine conductivities
in $W^{2,p}(\Omega)$ for some $p>1$ in a planar domain from
the Dirichlet--to--Neumann map constructing solutions of the
form \eqref{opticsol} and applying the so called
$\overline{\partial}$-method.

In dimension greater or equal 3
the uniqueness result of Nachman in
\cite{Na88} concerns the identifiability of conductivity
in a domain $\Omega$ with $C^{1,1}$ boundary. Nachman uniquely recovers
real valued conductivities $\gamma$ that are $C^{1,1}$ functions.
Beside the relaxation of hypotheses on the domain and on the conductivity,
the novelty here is that it is given a solution to Calder\'on reconstruction problem:
calculate $\gamma$ in term of $Q_{\gamma}$.
Nachman proves that one can reduce the problem of determining $\gamma$
from $\Lambda_{\gamma}$
to that of recovering the potential given a scattering amplitude $A$.
The key point is solving a different exterior problem and
he obtains, instead of $A$ an object called scattering transform from which
$\gamma$ can be found directly without analytic continuation.
Also in this case an important role is played by the exponentially growing
solutions
\eqref{opticsol} proposed by Sylvester and Uhlmann in \cite{Sy-Uh}, whose uniqueness
proof already contained the idea of converting the problem at the boundary
to one ``at infinity'', hidden on the fact that solutions
\eqref{opticsol} behave for $\xi$ large like Calder\'on's function \eqref{caldfun}.

The stability issue of this problem has been studied by Alessandrini in \cite{Al88} who under
some a priori constraints, shows that the modulus of continuity
is of logarithmic type.

Let $\Omega\subset\mathbb{R}^{n}$, $n\geq3$, be a bounded domain with
$C^{\infty}$ boundary.
We denote by $R=R(\Omega)$ a sufficiently large number such that
$\Omega\subset B_{R}$. Given $s$ and $E$, $s>n/2$, $E>0$,
we denote by $\gamma_1$, $\gamma_2$ any two functions in $H^{s+2}$
satisfying the following conditions
\begin{subequations}\label{grp2}
\begin{align}
\label{E}
&E^{-1}\leq\gamma_{i}(x)\qquad\textrm{for every }x\in\Omega,\\[2mm]
\label{gamma3}
&\Vert\gamma_i\Vert_{H^{s+2}(\Omega)}\leq E,
\end{align}
\end{subequations}
for $i=1,2$.
\begin{theorem}
\label{stabcondteo}
Let $\gamma_1$, $\gamma_2$ satisfy (\ref{grp2}).
There exists a positive constant $c$ depending on $E$, $s$, $n$
and $\Omega$ such that
\begin{equation}
\label{stabcond}
\Vert\gamma_1-\gamma_2\Vert_{L^{\infty}(\Omega)}
\leq c\,\omega\left(\Vert\Lambda_{\gamma_1}-\Lambda_{\gamma_2}
\Vert_{\mathcal{L}(H^{1/2}(\partial \Omega),H^{-1/2}(\partial \Omega))} \right),
\end{equation}
where the function $\omega$ is such that
\begin{equation}
\label{omega}
\omega(t)\leq|\log t|^{-\delta}\quad\textrm{for every }t,\,\,0<t<1/\textrm{e},
\end{equation}
and $\delta$, $0<\delta<1$, depending on $n$ and $s$.
\end{theorem}




\section{The Inverse Inclusion Problem}
\label{incluniq}
As we already mentioned, the inverse inclusion problem is a special instance of the conductivity problem.
Denoting by $D$ a subset compactly contained in $\Omega$, we want to study the situation in which the
conductivity of $D$ is different from the conductivity of the surrounding material. Therefore $\gamma$ has the form
$$\gamma(x)=a(x)+b(x)\chi_D,$$
where $a\in C^2(\overline{\Omega})$ is given, $b\in C^2(\overline{D})$
is an unknown positive function
and $\chi_D$ is the characteristic function of the set $D$.
We denote by $\Lambda_D$ the Dirichlet--to--Neumann map
defined in (\ref{dirtoneum}).
Let $D_1$, $D_2$ be two possible inclusions,
$b_1\in C^2(\overline{D}_1)$, $b_2\in C^2(\overline{D}_2)$
and $\gamma_i=a(x)+b_i(x)\chi_{D_i}$, $i=1,2$.
In 1988 Isakov \cite{Is88} proved the following uniqueness theorem.
\begin{theorem}
\label{isuniq}
Suppose $D_1$, $D_2$ are two open sets with Lipschitz boundary,
$\overline{D}_i\subset\Omega$, $i=1,2$,
 and $\Omega\backslash\overline{D}_i$ are connected.
If $\Lambda_{D_1}=\Lambda_{D_2}$ then
$D_1=D_2$,
$b_1=b_2$ on $\partial D_1$ and, in the case $n=3$,
$\gamma_1=\gamma_2$ in $\Omega$.
\end{theorem}

Let $\mathcal{G}$ be the connected component of
$\Omega\backslash(\overline{D}_1\cup\overline{D}_2)$ whose boundary
contains
$\partial\Omega$ and let $\Omega_D=\Omega\backslash\overline{\mathcal{G}}$.

\begin{lemma}
There holds the orthogonality relation
\label{ortog}
\begin{equation}
\label{ortogrel}
\int_{D_1}b_1\nabla u_1\cdot\nabla u_2=\int_{D_2}b_2\nabla u_1\cdot\nabla u_2,
\end{equation}
for solutions $u_1$, $u_2$ to equation (\ref{eqcond})
in an open set that is in arbitrary
vicinities of $\overline{\Omega}_D$,
with $\gamma$ replaced by $\gamma_1$, $\gamma_2$ respectively.
\end{lemma}
\begin{proof}
Using unique continuation it is not difficult to see that
$u_{1}=u_2$ on $\mathcal{G}$.
Subtracting the equation (\ref{eqcond}) with $\gamma=\gamma_1$
from those with $\gamma=\gamma_2$, one establishes the equality
(\ref{ortogrel}) for any $u_2$ as in Lemma \ref{ortog} and for $u_1$ which
is solution to problem (\ref{eqcond})--(\ref{dirdatum}).
It is now possible to obtain the lemma using the Runge Approximation
Theorem and extending the equality (\ref{ortogrel})
onto all $u_1$ solving equation \eqref{eqcond} in the vicinities of $\overline{\Omega}_D$.

Let $X$ be the space of such $u_1$. It is sufficient to prove that solution to
the Dirichlet problem \eqref{eqcond}--\eqref{dirdatum}
with $\gamma=\gamma_1$ approximate in $H^1(\Omega_D)$ any
solution from $X$.

Denote by $X_1$ the space of solutions to the Dirichlet problem
\eqref{eqcond}--\eqref{dirdatum}, for any boundary data $f$. In view of the
Hahn--Banach theorem we show that any $f\in H^{-1}(\Omega_D)$ which
is zero on $X_1$ is zero as well.
For $f_1\in H^{1}(\Omega_D)$ we shall use the notation
$f(f_1)=\langle f,f_1\rangle$.
Let $\Omega_0$ be a bounded domain with $C^2$ boundary
such that $\Omega\subset\Omega_0$, $\Omega\neq\Omega_0$.
Let $G_1(x,y)$ be the Green's function to the Dirichlet problem for the
operator $\mathrm{div}(\gamma_1\nabla\cdot)$ in $\Omega_0$, with forcing term 
$\delta_x$.
Let $f=0$ on $X_1$.
For $x\in\Omega_0\backslash\overline{\Omega}$,
the function
$u_1(\cdot)=G_1(x,\cdot)$ belongs to $X_1$.
Thus the potential
$$U_f(x)\coloneqq\langle f,G_1(x,\cdot)\rangle=0\qquad
\textrm{on }\Omega_0\backslash\overline{\Omega}.$$
Since $\mathrm{supp}\,f\subset\overline{\Omega}_D$, $U_f$ solves
the equation

$$\mathrm{div}(a\nabla U_f)=0\qquad
\textrm{in }\Omega_0\backslash\overline{\Omega}_D.$$

Since $a\in C^1(\overline{\Omega})$, this equation has the property
of unique continuation, therefore $U_f(x)=0$ in $\Omega_0\backslash\overline{\Omega}_D$.
Let $u_1\in X$, then $u_1$ is solution to the homogeneous
equation near $\overline{\Omega}_1$, where
$\Omega_1$ is an open set with $C^{\infty}$ boundary
and $\overline{\Omega}_D\subset\Omega_1$, $\overline{\Omega}_1\subset\Omega$.
Using the single layer potential representation we have
$$u_1(y)=\int_{\partial\Omega_1}g(x)G_1(x,y)d\sigma(x),$$
where $g\in C(\partial\Omega_1)$.
Applying the functional $f$ and using the equality $U_f(x)=0$
if $x\in\partial \Omega_1$, we get $\langle f,u_1\rangle=0$.
So if $f=0$ on $X_1$ then $f=0$ on $X$.
\end{proof}

\begin{proof}[Proof of Theorem~\ref{isuniq}]
We will not give all details of the proof,
we refer to \cite{Is88, Is98} for it.
We  only show that $D_1=D_2$.
Assume, by contradiction, that $D_1\neq D_2$.
Then we may assume that $D_1$ is not contained in $D_2$,
hence there exists a point $P\in\partial D_1\backslash\overline{D}_2$
such that $P\in\partial\mathcal{G}$.
Let $r$ be a positive number such that
$\overline{B}_r(P)\subset\Omega$,
$\overline{B}_r(P)\cap D_2=\emptyset$ and $\partial\Omega_D\cap\overline{B}_r(P)$
is a Lipschitz surface.
There exists a $C^2(\overline{D}_1\cup\overline{B}_r(P))$-function
$\gamma_3$ such that $\gamma_3\equiv\gamma_1$ on $D_1$.
We extend $\gamma_3$ onto
$\Omega\backslash(\overline{D}_1\cup\overline{B}_r(P))$ as $a$.
Using Lemma \ref{ortog} it is possible to prove the following lemma.
\begin{lemma}
\label{ortog2}
Under hypothesis of Lemma \ref{ortog}
\begin{equation}
\int_{D_1}b_1\nabla u_3\cdot\nabla u_2
=\int_{D_2}b_2\nabla u_3\cdot\nabla u_2,
\end{equation}
for any solution $u_3$ to equation $\mathrm{div}(\gamma_3\nabla u_3)=0$
near $\overline{\Omega}_D$ and any solution $u_2$
to the equation \eqref{eqcond} near $\overline{\Omega}_D$ with $\gamma=\gamma_2$.
\end{lemma}
Let $G_2$ be the Green's function to the Dirichlet problem for the
operator $\mathrm{div}(\gamma_2\nabla\cdot)$
in $\Omega$ and $G_3$ for the operator
$\mathrm{div}(\gamma_3\nabla\cdot)$. Then, for $j=1,2$ we have
(see \cite{miranda:book})
\begin{equation}
\label{mir}
\nabla_y G_j(x,y)=c_j(y)\left(1+O(y,x-y)\right)|x-y|^{-n}(x-y),
\end{equation}
if $x$ is closed to $P$ and $y\in\overline B_r(P)$.
Here $c_j(y)$ are certain positive $C^2(B_r(P))$ functions
and $O(y,x-y)$ stands for a matrix with the property
$$\Vert O(y,x-y)\Vert\leq c|x-y|.$$
Henceforth we can choose $r_1<r$ so that in $B_{r_1}(P)$
$$\Vert O(y,x-y)\Vert\leq\frac{1}{2}.$$
From \eqref{mir} and standard estimates of the Dirichlet problem in
$\Omega\backslash B_{r_1}(P)$, we deduce that
$\nabla_y G_j(x,\cdot)$ are bounded in $L^2(\Omega\backslash B_{r_1}(P))$
provided $x$ is close to $P$.

From Lemma~\ref{ortog2} with $u_3=G_3(x,\cdot)$, $u_2=G_2(x,\cdot)$,
$x\in B_{r_1}(P)\backslash\overline\Omega_D$ we have
\begin{multline*}
\int_{D_1\cap B_{r_1}(P)}b_1\nabla G_3(x,\cdot)\cdot\nabla G_2(x,\cdot)=
-\int_{D_1\backslash B_{r_1}(P)}b_1\nabla G_3(x,\cdot)\cdot\nabla G_2(x,\cdot)\\
+\int_{D_2}b_2\nabla G_3(x,\cdot)\cdot\nabla G_2(x,\cdot).
\end{multline*}
The right side is bounded when $x$ tends to $P$ and
$x\in B_{r_1}(P)\backslash\overline\Omega_D$.

According to our assumptions on the conductivity there exist $\varepsilon>0$ such that
either $0<\varepsilon<b_1$ or $b_1<-\varepsilon$ on $B_{r_1}(P)$.
In the first case the representation \eqref{mir} and the choice of
$B_{r_1}(P)$ give
$$\varepsilon_1\int_{D_1\cap B_{r_1}(P)}|x-y|^{2-2n}dy
\leq\int_{D_1\cap B_{r_1}(P)}b_1\nabla G_3(x,\cdot)\cdot\nabla G_2(x,\cdot).$$
The left side tends to $+\infty$ as $x$ tends to $P$
and $x\in B_{r_1}(P)\backslash\overline\Omega_D$, so we have a contradiction.
Similarly, we get a contradiction in the case $b_1<-\varepsilon$.
Thus $D_1=D_2$.
\end{proof}
The stability issue of this problem has been considered in \cite{Al-DC}.
The argument is based on quantitative estimates of unique continuation and the use of singular solutions.
\begin{theorem}
Let $\Omega\subset\mathbb R^n$, $n\geq2$, be a $C^{1,\alpha}$ bounded domain and
$D_i$, $i=1,2$, be $C^{1,\alpha}$ subsets compactly contained in $\Omega$ such that
$\Omega\setminus\overline D_i$ are connected. If given $\varepsilon>0$
$$\|\Lambda_{D_1}-\Lambda_{D_2}\|\leq\varepsilon,$$
then
$$d_\mathcal H(\partial D_1,\partial D_2)\leq\omega(\varepsilon),$$
where $\omega$ is an increasing function on $[0,+\infty)$ which satisfies
$$\omega(t)\leq C|\log t|^{-\eta},\quad\textrm{ for every } 0<t<1,$$
and $C>0$, $0<\eta<1$ are constants depending on the a priori data only.
\end{theorem}
We wish to mention here that the stability estimates of these problems are extremely weak
and, keeping as minimal as possible the a priori assumptions, they can not be improved as it
is showed in \cite{Ma} for the conductivity problem and in \cite{DC-Ro} for the inclusion problem.
This emphasizes the difficulty in the numerical reconstruction as small errors in the data
can lead to enormous errors in the solution.
In this thesis we will go through some numerical algorithms present in literature
(linear sampling method in Chapter \ref{ch:linear-sampling} and factorization method in Chapter \ref{ch:factorization}), 
and propose a new method (reciprocity gap principle in Chapter \ref{ch:reciprocity}) to reconstruct the defect.
We will also try in Chapter \ref{ch:link} to compare these methods and understand how they work.

Let us conclude this introduction with a final remark concerning the boundary measurements.
It is physically meaningful prescribe the current density at the boundary and measure the corresponding voltage.
In this case we define the Neumann--to--Dirichlet map $N_D$ (or $N_\gamma$ for the conductivity case) as follows.
We will denote throughout the chapters, with the subscript zero, $H^s_0(\partial\Omega)\subset H^s(\partial\Omega)$, the closed subspace of functions with vanishing mean on the boundary
\begin{align}
&H^s_0(\partial\Omega) = \Big\{ f \in H^s(\partial\Omega): \langle f,1\rangle = 0\Big\},\\
&H^1_0(\Omega) = \Big\{ u \in H^1(\Omega): u|_{\partial\Omega} \in H^{1/2}_0(\partial\Omega)\Big\}.
\end{align}
The advantage, in this last definition, is to avoid trivial constant functions, to recover uniqueness for second order differential problems.
We introduce the following notation
\begin{enumerate}
 \item let $u\in H^1_0(\Omega)$ be the unique solution of the \emph{Laplace problem} in the background material
 \begin{equation}
 \label{eq:NtoD-laplace}
  \left\{
  \begin{aligned}
  \Delta v = \divergence(\nabla v) &= 0, \quad\text{in}\,\Omega, \\
            \partial_\nu v &= f, \quad\text{on}\,\partial \Omega,
  \end{aligned}
  \right.
 \end{equation}
 and define
 \begin{align}
 &M_0: H^{-1/2}_0(\partial \Omega) \to H^1_0(\Omega) && M_0f = v, \label{eq:def-T_0}\\
 &{N_0}: H^{-1/2}_0(\partial \Omega) \to H^{1/2}_0(\partial\Omega) && {N_0} f = v|_{\partial\Omega},
 \end{align}
 \item let $v\in H^1_0(\Omega)$ be the unique solution of the \emph{inclusion problem} with $D\subset \Omega$
 \begin{equation}
 \label{eq:NtoD-inclusion}
  \left\{
  \begin{aligned}
  \divergence(\gamma\nabla u) &= 0, \quad\text{in}\,\Omega, \\
            \partial_\gamma u &= f, \quad\text{on}\,\partial \Omega,
  \end{aligned}
  \right.
 \end{equation}
 with $\gamma(x) = a(x)\chi_{\Omega\backslash\overline{D}} + k(x)\,\chi_D$, and define
 \begin{align}
 &M_D: H^{-1/2}_0(\partial \Omega) \to H^1_0(\Omega) && M_Df = u, \label{eq:def-T_D}\\
 &{N_D}: H^{-1/2}_0(\partial \Omega) \to H^{1/2}_0(\partial\Omega) && {N_D}f = u|_{\partial\Omega}.
 \end{align}
\end{enumerate}
\begin{remark}
Also in this case all results remain valid observing  that, denoting by $\tilde\Lambda_D$ the restriction of 
$\Lambda_D$ to $H_0^{1/2}(\partial\Omega)$, we have the identity
$$N_{D_1}-N_{D_2}=N_{D_2}(\tilde\Lambda_{D_2}-\tilde\Lambda_{D_1})N_{D_1}.$$
\end{remark}

% \chapter{Numerical Algorithms}

\chapter{Linear Sampling Method}
\label{ch:linear-sampling}

\begin{figure}[tb]
\begin{center}
 \begin{tikzpicture}
  \draw [dashed] (2,2) ellipse (3cm and 2cm);
  \draw [dashed] (2,2) ellipse (1.5cm and 1cm);
  \draw (2,2) circle (0.5cm);
  %\draw (2,2) rectangle (1cm and 3cm);
  \node at (-0.5,2){$B$};
  \node at (1,2){$\Omega$};
  \node at (2,2){$D,k$};
 \end{tikzpicture}
\end{center}
\caption{Geometry of the problem}
\end{figure}

In this chapter we will analyze the classical formulation of the linear sampling method. 
There is a direct part first, which we try to invert then, with data in the image space, 
depending on the sampling point $z\in\Omega$.
\par
We denote by $\Omega$ an open simply connected domain, in which the differential problem is defined.
To fix ideas, its boundary represents the external surface, where we usually are allowed to operate.
We will consider an inclusion $D$ of the following form.
\begin{assumption}
\label{assumption:connected}
 Let $\bigl\{D_j\bigr\}_{j=1}^N$ be a collection of open simply connected domains.
 We denote $D\coloneqq\bigcup_{j=1}^ND_j$ such that $\Omega\backslash D$ is connected.
\end{assumption}
Mostly we will deal with the case $D=D_1$, a single simply connected open set, but it's not restrictive, 
since our results can be applied to any component of $D$, under the previous assumption.
\section{Relative Neumann--to--Dirichlet map}
In the previous chapter we have introduced two Neumann--to--Dirichlet type operators ${N_D}$ and ${N_0}$, 
whose properties are well summed up by Kirsch in \cite{kirsch:book}. 
Following the approach of Somersalo \cite{somersalo:preprint}, throughout the chapter, 
we formulate the linear sampling method.
\par
Each weak formulation \eqref{eq:NtoD-inclusion} and \eqref{eq:NtoD-laplace} satisfies the hypotheses of Lax-Milgram's theorem for 
variational formulations, by coercivity in $H^1_0(\Omega)$ and continuity of bilinear forms. 
\par
In the inverse inclusion problem, a crucial role is played by the 
\textit{relative} Neumann--to--Dirichlet map as well illustrated in \cite{somersalo:preprint}. More precisely we define 
\begin{equation}
 -{N_r} \coloneqq {N_D} - {N_0}.
\end{equation}
For fixed $f\in  H^{-1/2}(\partial \Omega)$,
\begin{enumerate}
 \item ${N_0} f$ is the trace of the potential generated by sources on the boundary $\partial \Omega$;
 \item ${N_D} f$ is generated by sources on the boundary $\partial \Omega$ and by a simple layer of 
 zero mean on $\partial D$, induced by the presence of the field.
\end{enumerate}
Then it's reasonable to expect that the difference $\bigl({N_D}-{N_0}\bigr)f$, in some cases, 
can approximate the scalar field of a dipole.
Moreover, the operator should be able to discriminate the support of the inclusion $D$.
\par
It is important to establish injectivity of ${N_D} - {N_0}$, so it guarantees that the operators 
${N_D}$ and ${N_0}$ map, in different ways, two geometries, with and without inclusion respectively, 
yielding a non trivial difference.
Injectivity can be achieved eventually by an appropriate construction of quotient space with the kernel of the operator.
\par
To do this, we need to reformulate the problem differently.
The relative operator ${N_D} - {N_0}$ is strictly connected to a formulation which
\begin{enumerate}
 \item \emph{jointly involves} both ${N_D}$ and ${N_0}$,
 \item \emph{is defined in the region} $D$, which is the real subject and responsible of different data  
 (see next section \ref{section:validation}).
\end{enumerate}

\section{Interior Transmission Problem}
The Interior Transmission Problem (ITP) couples two second order differential equations with Cauchy transmission conditions.
It is defined as follows.
% \begin{mybox}
\begin{problem}[Interior Transmission Problem (ITP)]
\label{problem:ITP-dist}
We denote \emph{strong solution} of the ITP, the couple {$(u,v) \in (H^1(D) \times H^1(D))/\mathbb{C}$} which solves, in the sense of distributions,
\begin{align}
-\divergence(\gamma\nabla u) & = 0,\quad\textup{ in }D, \\
-\Delta v & = 0, \quad\textup{ in }D,
\end{align}
and in the sense of trace operator, given $f\in H^{1/2}(\partial D)$ and $g\in H^{\,-1/2}_0(\partial D)$,
\begin{align}
  u - v & = f, \quad\textup{ on }\partial D,\\
  \partial_\gamma u - \partial_\nu v & = g, \quad\textup{ on }\partial D.
\end{align}
Note that $g\in H^{\,-1/2}_0(\partial D)$ follows from an application of divergence theorem to $\gamma\nabla u - \nabla v$.
\end{problem}
% \end{mybox}
The equivalence class $(H^1(D) \times H^1(D))/\mathbb{C}$, in which we have the uniqueness of the solution $(u,v)$, is constructed from the equivalence relation
\begin{equation}
 (u,v)\sim(u',v') \quad \text{if and only if} \quad \exists \,c \,\,\text{s.t.}\,(u,v) = (u' + c,v' + c).
\end{equation}
In order to consider the Cauchy conditions as the natural ones, we introduce the following modified version of the ITP.
% \begin{mybox}
\begin{problem}[Modified Interior Transmission Problem (MITP)]
\label{problem:MITP-dist}
We denote \emph{strong solution} of the MITP, the couple {$(u,v) \in H^1(D) \times H^1(D)$} which solves
\begin{align}
-\divergence(\gamma\nabla u) & = 0,\quad\textup{ in }D, \\
-\Delta v + v & = 0, \quad\textup{ in }D, \\
  u - v & = f, \quad\textup{ on }\partial D,\\
  \partial_\gamma u - \partial_\nu v & = g, \quad\textup{ on }\partial D.
\end{align}
given $f\in H^{1/2}(\partial D)$ and $g\in H^{\,-1/2}(\partial D)$ and assuming $\gamma>1$ in $D$.
\end{problem}
% \end{mybox}
Following on ideas of \cite{cakoni-colton-haddar:lsm}, we define the space
\begin{equation}
 H_{\divergence}(D)\coloneqq\bigl\{\bm{w}\in L^2(D;\,\mathbb{R}^3):\divergence\bm{w} \in L^2(D) \textup{ and } \curl\bm{w}=0 \bigr\},
\end{equation}
equipped with the norm
\begin{equation}
 \|\bm{w}\|_{H_{\divergence}(D)}\coloneqq\bigl(\|\bm{w}\|^2_{L^2(D;\,\mathbb{R}^3)} + \|\divergence\bm{w}\|^2_{L^2(D)}\bigr)^{1/2},
\end{equation}
and introduce the bilinear form $a$, defined for $U,V\in H^1(D)\times H_{\divergence}(D)$, where $U=(u,\bm{w})$ and $V=(\phi,\bm{\psi})$, 
and dualities $\langle\cdot,\cdot\rangle$ are defined on $H^{-1/2}(\partial D)\times H^{1/2}(\partial D)$,
\begin{equation}
 a(U,V)\coloneqq \int_D \gamma \nabla u\cdot\nabla \phi + \int_D\divergence \bm{w}\divergence\bm{\psi} + \int_D\bm{w}\cdot\bm{\psi} - \langle \bm{w}\cdot\nu, \phi \rangle- \langle u,\bm{\psi}\cdot\nu\rangle,
\end{equation}
\begin{equation}
 L(V)\coloneqq \langle g, \phi\rangle - \langle f, \bm{\psi}\cdot\nu\rangle.
\end{equation}
We recall the identity
\begin{equation}
 \label{eq:identity-duality}
 \langle\phi,\bm{\psi}\cdot\nu\rangle = \int_D\phi\divergence\bm\psi\,dy + \int_D\nabla\phi\cdot\bm{\psi}\,dy.
\end{equation}
\begin{proposition}
\label{prop:MITP-variational}
 Let $H_{\divergence}(D)$ be the subspace defined above. Then the variational problem, given $f\in H^{1/2}(\partial D)$ and $g\in H^{\,-1/2}(\partial D)$,
 assuming $\gamma>1$ in $D$,
 \begin{equation}
 \label{eq:MITP-variational}
  \textup{find }U\in H^1(D)\times H_{\divergence}(D):\,a(U,V)=L(V) \quad\forall V\in H^1(D)\times H_{\divergence}(D),
 \end{equation}
has a unique solution $U$ 
which depends continuously from data and there exists a positive constant $C$ such that
\begin{equation}
 \|u\|_{H^1(D)} + \|\bm w\|_{H_{\divergence}(D)}\leq C\Bigl(\|f\|_{H^{1/2}(\partial D)}+\|g\|_{H^{-1/2}(\partial D)}\Bigr).
\end{equation}
\end{proposition}
\begin{proof}
We divide the proof into three steps.
 \begin{enumerate}
 \item 
 The problem is weakly coercive in the Hilbert triplet $(V,H,V^*)$ with $V=H^1(D)\times H_{\divergence}(D)$ and $H=L^2(D)\times H_{\divergence}(D)$.
 Indeed using the identity \eqref{eq:identity-duality} we have the Schwarz's inequality $|\langle u ,\bm{w}\cdot\nu\rangle |\leq\|u\|_{H^1(D)}\|\bm{w}\|_{H_{\divergence}(D)}$ and 
 denoting by $\gamma_0 = \textup{inf}\,\gamma$
\begin{align}
 |a(U,V)|&\geq \gamma_0\|\nabla u\|_{L^2(D)}^2 + \|\bm{w}\|^2_{H_{\divergence}(D)}-2\langle u ,\bm{w}\cdot\nu\rangle \\
 &\geq \gamma_0\|\nabla u\|_{L^2(D)}^2 + \|\bm{w}\|^2_{H_{\divergence}(D)}-2\|u\|_{H^1(D)}\|\bm{w}\|_{H_{\divergence}(D)}.
 \end{align}
 By Young's inequality
 \begin{equation}
 |a(U,V)| + \gamma_0\|u\|^2_{L^2(D)} \geq \gamma_0\|u\|_{H^1(D)}^2 + \|\bm{w}\|^2_{H_{\divergence}(D)}-\epsilon\|u\|^2_{H^1(D)} - \frac{1}{\epsilon}\|\bm{w}\|^2_{H_{\divergence}(D)},
 \end{equation}
 and taking $\epsilon=t\gamma_0$, for $t\in[0,1]$ sufficiently close to $1$ such that $t\gamma_0>1$ (since $\gamma>1$) we get
 \begin{equation}
  |a(U,V)| + \gamma_0\|u\|^2_{L^2(D)}\geq (1-t)\gamma_0\|u\|_{H^1(D)}^2 + \frac{t\gamma_0 - 1}{t\gamma_0}\|\bm{w}\|^2_{H_{\divergence}(D)}.
 \end{equation}
 \item We proceed with the identification of the kernel of the adjoint form $a^*(U,V)$
\begin{equation*}
  a^*(U,V)= \int_D \gamma \nabla \phi \cdot\nabla u + \int_D\divergence \bm{\psi}\divergence\bm{w} + \int_D\bm{\psi}\cdot\bm{w} - \langle \bm{\psi}\cdot\nu, u \rangle- \langle \phi,\bm{w}\cdot\nu\rangle.
\end{equation*}
 Denoting by $A_c\coloneqq\{x\in D: u>c\}$ we take $V=(\phi_c^+, \bm{0})$ with $\phi_c^+(x)\coloneqq (u(x)-c)\chi_{A_c}(x) + c$
\begin{equation*}
  0 = a^*(U,V)= \int_{A_c} |\nabla u|^2\,dy - c\int_{\partial D}\bm{w}\cdot\nu\, dy.
\end{equation*}
 Instead taking $V=(\phi_c^-,\bm{0})$ with $\phi_c^-(x)\coloneqq (2c - u(x) - c)\chi_{A_c}(x) + c$, we get that
 $\int_{\partial D}\bm{w}\cdot\nu\,dy$ vanishes and $\nabla u=0$ in $D$. 
 Now, since the arbitrariness of $V=(\phi, \bm 0)$, we get $\bm{w}\cdot\nu =0$.
 On the other end, taking $V=(0, \bm{w})$, after last substitutions, we get
\begin{equation*}
 0=a^*(U,V)=\int_D|\divergence \bm{w}|^2\,dy + \int_D|\bm{w}|^2\,dy,
\end{equation*}
which forces $\bm{w}=\bm{0}$. Taking $U=(c,\bm 0)$, arbitrariness of $V=(0,\bm \psi)$ yields $u=c=0$. 
In conclusion, the kernel $\mathcal{N}(a^*)=\{0\}$ is trivial.
\item By application of Fredholm's alternative for variational formulations, 
there exists a unique solution.
Continuous dependence of solution from data derives from the Bounded Inverse Map's theorem, considering the continuous and bijective map from the solution $U=(u,\bm w )$ in $H^1(D)\times H_{\divergence}(D)$ to data $(f,g)$.
\end{enumerate}
\end{proof}
\begin{proposition}
\label{prop:MITP-equivalence}
 The strong formulation of MITP (Problem \ref{problem:MITP-dist}) and variational formulation 
 \eqref{eq:MITP-variational} are equivalent.
 That is, for any strong solution $(u,v)$ of MITP, $U\coloneqq(u,\nabla v)$ satisfies the variational one. 
 On the contrary, for any solution $U=(u,\bm w)$, we can construct a couple $(u,v({\bm w}))$ 
 which solves MITP, such that $\nabla v(\bm w)=\bm w$.
\end{proposition}
\begin{proof}
 The first implication is left to the reader, since it's sufficient to multiply and integrate by parts, 
 for any test function $\phi$ and $\divergence\bm \psi$. Let us prove only the converse.
 Let $U=(u, \bm w)$ be a solution of the variational formulation \eqref{eq:MITP-variational}. 
 Since $\curl \bm w=0$ and $D$ is simply connected, there exists a potential $v$ 
 for the vector field $\bm w = \nabla v$, which is determined up to an additive constant. 
 For $\phi\in H^1_0(D)$ and $\phi\in H^1(D)$ we obtain
 \begin{align}
  -\divergence(\gamma\nabla u)&=0,\quad\textup{ in }D, \\
  \partial_\gamma u - \partial_\nu v&= g,\quad\textup{ on }\partial D.
 \end{align}
 The remaining part is
 \begin{equation}
 \label{eq:remaining-equivalence}
  \int_D(\Delta v - v)\divergence\bm\psi + \langle v-u + f,\bm\psi\cdot\nu\rangle = 0 \quad \forall\bm\psi\in H_{\divergence}(D).
 \end{equation}
Following \cite{cakoni-colton-haddar:lsm}, we first consider $\bm w_1 = \nabla \chi_1 $, 
where $\chi_1$ is the solution, for $\phi \in L^2_0(D)$, of
\begin{align}
 \Delta \chi_1 &= \phi, \, \textup{ in }D,\\
 \partial_\nu \chi_1 &= 0,\, \textup{ on }\partial D.
\end{align}
This forces $\Delta v - v = c_1$ to be constant, equal to $c_1$. Next, for $\bm w_2 = \nabla\chi_2$, where $\chi_2$ solves, for $\phi\in L^2_0(\partial D)$,
\begin{align}
 \Delta \chi_2 &= 0, \, \textup{ in }D,\\
 \partial_\nu \chi_2 &= \phi,\, \textup{ on }\partial D,
\end{align}
we find the condition $v-u+f=c_2$ on $\partial D$, constant equal to $c_2$. 
If we substitute these two founded conditions in \eqref{eq:remaining-equivalence}, 
then must be satisfied $-c_1=c_2=c=v-u+f$. Finally the corrected couple $(u,v-c)$ solves
 \begin{align}
  - \Delta v + v&=0,\,\textup{ in } D,\\
  u-v &= f,\,\textup{ on }\partial D.
 \end{align}
\end{proof}
\begin{proposition}
\label{prop:ITP-ex-un}
 Under assumption $\gamma(x)=k$ in $D$, with $k$ constant, there exists a unique solution $(u,v)\in(H^1(D) \times H^1(D))/\mathbb{C}$ of ITP. Or equivalently it's unique in the subspace $H^1(D)\times H^1_0(D)$.
\end{proposition}
\begin{remark}
Under the following assumptions for a generic symmetric $\gamma(x)$
\begin{align}
 &\exists\, \alpha>0\,\forall \zeta \in \mathbb{C}^m\quad \real(\overline{\zeta}\cdot\gamma(x)\zeta)     \geq\,  \alpha|\zeta|^2 \quad x\in \Omega,\\
 &\exists\, \beta>0\,\forall \zeta \in \mathbb{C}^m\quad \imag(\overline{\zeta}\cdot\gamma(x)\zeta)        \leq\,  -\beta|\zeta|^2 \quad x\in \mathcal{O} \subset D \text{ some open set },
\end{align}
uniqueness  of ITP is easily demonstrated in \cite{somersalo:preprint}, while existence requires a weak formulation starting from the article \cite{cakoni-colton-haddar:lsm}, where the Helmholtz equation for the scattering problem is studied.
\end{remark}
\begin{proof}[Proof of \ref{prop:ITP-ex-un}]
 We prove uniqueness, in the framework of the above proposition. 
 We assume $f=g=0$, and define $w\coloneqq u-v$ be the difference, then it's harmonic, 
 with homogeneous Dirichlet data on the boundary $w=0$ on $\partial D$. Then uniqueness implies $w=0$. Neumann data can be rewritten, under $u=v$, as $k\partial_\nu u - \partial_\nu v = (k-1)\partial_\nu u = 0$.
 This homogeneous Neumann condition, with Laplace equation for $u$, yields to the conclusion which $u=v=c$ must be constant, equivalent to $u=v=0$ according with the equivalence class definition.
\end{proof}
To prove existence for ITP, going back to the initial ITP problem, we define the Sobolev space of solutions, with its induced stronger norm,
\begin{equation}
 X\coloneqq\Bigl\{(u,v)\in H^1(D)\times H^1(D):\divergence(\gamma\nabla u)\in L^2(D) \textup{ and } \Delta v\in L^2(D) \Bigr\},
\end{equation}
and the space of data
\begin{equation}
 Y\coloneqq L^2(D) \times L^2(D) \times H^{1/2}(\partial D) \times H^{-1/2}(\partial D).
\end{equation}
We also define the two operators $T,K:X\to Y$:
\begin{align}
& T \coloneqq \bigl(-\divergence(\gamma\nabla u), -\Delta v + v, (u - v)|_{\partial D}, (\partial_\gamma u -\partial_\nu v)|_{\partial D}\bigr),\\
& K \coloneqq (0, -v, 0 , 0).
\end{align}
By compact embedding of $H^1(D)$ in $L^2(D)$, both $T$ and $T+K$ are Fredholm operators, 
with the same index. Theorems \ref{prop:MITP-variational} and \ref{prop:MITP-equivalence} show 
that $T$ is continuous bijective with bounded inverse. But since $T+K$ is not injective, by the 
fact that $\mathcal{N}(T+K)=\textup{span}(\{(1,1)\})$, we expect 
$\textup{codim}(\mathcal{R}(T+K))=1$. This is true since $\mathcal{R}(T+K)$ is equal to 
$Y$ after substitution of the forth slot with $H^{-1/2}_0(\partial D)$. Substituting even 
the second slot in $X$ with $H^1_0(D)$ for $v$, we construct a bijective and continuous map, with bounded inverse.
Let us summarize all these facts in the following proposition.
\begin{proposition}
 Let $f\in H^{1/2}(\partial D)$ and $g\in H^{\,-1/2}_0(\partial D)$, assuming $\gamma>1$ in $D$, then ITP (Problem \ref{problem:ITP-dist}) has a unique solution in $H^1(D)\times H^1_0(D)$, which depends continuously from data $f,g$.
\end{proposition}
\section{Linear Sampling Method}
 The linear sampling method consists in sampling a region $\Omega$ with an hypothetic function 
 singular in $z$ and trying to solve, in an approximate way, the linear system
 \begin{equation}
 \label{eq:lsm-approximate-lin-eq}
  \bigl({N_D} - {N_0}\bigr)f=\psi_{0z},
 \end{equation}
 where $\psi_{0z}$ is a singular function that will be defined later on (see Definition \ref{def:lsm-psi}).
 \par
 This method has been widely employed in the context of inverse problems for scattering (see \cite{colton-haddar-piana:lsm}, \cite{cakoni-colton-haddar:lsm}) with different boundary conditions (sound-soft obstacles, sound-hard obstacles, impedance conditions). Our aim is to use it for electrical impedance tomography.
 We begin by stating the main properties of the relative Neumann--to--Dirichlet operator ${N_D} - {N_0}$.
 \begin{proposition}
  The operator ${N_D} - {N_0}:H_0^{\,-1/2}(\partial \Omega)\to H_0^{1/2}(\partial \Omega)$ is injective and has dense range.
 \end{proposition}
 This is proved in \cite{kirsch:book}, but we present the proof for injectivity contained in \cite{somersalo:preprint}, to highlight the link with ITP.
 \begin{proof}
 Assume $({N_D} - {N_0})f = 0$. Let $u=M_Df$ and $v=M_0f$ the corresponding solutions of \eqref{eq:NtoD-inclusion} and \eqref{eq:NtoD-laplace},
 the difference $w=u-v$ is harmonic in $\Omega\backslash\overline{D}$ with vanishing Cauchy conditions on $\partial \Omega$, which entails $w=0$ in $\Omega\backslash\overline{D}$. Then the pair $(u|_D,v|_D)$ solves the ITP with conditions
 \begin{align}
  u^--v^- &=u^+ - v^+ = 0 ,&& \textup{on }\partial D,\\
  \partial_\gamma u^- - \partial_\nu v^- &= \partial_\nu u^+ - \partial_\nu v^+ = 0 ,&& \textup{on }\partial D.
 \end{align}
The uniqueness of ITP implies that $u,v$ and $f$ are identically zero. 
 \end{proof}
\begin{proposition}
  All the operators ${N_D}, {N_0}, {N_r}$ are self-adjoint.
 \end{proposition}
 \begin{proof}
 The result derives directly from the weak formulation, taking $\phi=u_f$ (we denote by $u_f=M_Df$) in the variational formulation for $u_g$. Namely
 \begin{align}
  \int_{\Omega}\gamma\nabla u_g \cdot \nabla \phi\,dy &= \int_{\partial\Omega}g\,\phi\,dy \quad \forall \phi\in H^1_0(\Omega) ,\\
  \int_{\Omega}\gamma\nabla u_g \cdot \nabla u_f\,dy &= \langle g, {N_D} f\rangle_{L^2(\partial \Omega)} \label{eq:adjoint-NtoD}.
 \end{align}
The thesis follows observing the symmetry of the left hand side of \eqref{eq:adjoint-NtoD}.
 \end{proof}
 As right term of \eqref{eq:lsm-approximate-lin-eq} we consider the solution of the problem related to the potential generated by a dipole
 \begin{equation}
 \left\{
 \begin{aligned}
   -\Delta \psi(x,z) &= \nabla\delta_{z} \cdot \vec{d}, && \textup{ in }\Omega ,\\
   \partial_\nu\psi(x,z) &= 0, &&\textup{ on }\partial \Omega,
 \end{aligned}
 \right.
 \end{equation}
 with unit vector $|\vec{d}\,|=1$. Using the notation $\vec{\Psi}(x,z)\coloneqq\nabla_x\Phi(x,z)$ for the derivative of the fundamental solution, we write the structure of the right term, which will be effectively implemented numerically.
 \begin{definition}
 \label{def:lsm-psi}
  Let $M_0$ and $M_D$ be defined as in \eqref{eq:def-T_0}, \eqref{eq:def-T_D}, we denote
 \begin{equation}
 \psi_{0z} \coloneqq \vec{\Psi}(x,z)\cdot\vec{d} - m_z - M_0\bigl(\partial_\nu \vec{\Psi}(x,z) \cdot \vec{d}\bigr),
  \end{equation}
  and
  \begin{equation}
  \psi_{z} \coloneqq \vec{\Psi}(x,z)\cdot\vec{d} - m_z - M_D\bigl(\partial_\nu \vec{\Psi}(x,z) \cdot \vec{d}\bigr),
  \end{equation}
  with $m_z$ the mean of $\vec{\Psi_z}\cdot\vec{d}$ on $\partial \Omega$. We will use the same notation for their traces on $\partial \Omega$.
 \end{definition}
 \begin{remark}
  Note that $\psi_z$ is not harmonic in $\Omega\backslash\{z\}$ and
  \begin{equation*}
  \partial_\nu \psi_{0z} = \partial_\nu \psi_z = 0,\quad\textup{ on }\,\partial \Omega.
  \end{equation*}
 \end{remark}
 Kirsch in \cite{kirsch:book} introduces the same function, starting from the \emph{Green's function for Neumann boundary problem}: $N(x,z)=\Phi(x,z)-\tilde{N}(x,z)$, with $\tilde{N}(x,z)$ such that
 \begin{equation}
 \left\{
 \begin{aligned}
   -\Delta N(x,z) &= 0, &&\textup{ in }\Omega\backslash\{z\} ,\\
   \partial_\nu N(x,z) &= -1/|\partial \Omega|,&&\textup{ on }\partial \Omega.
 \end{aligned}
 \right.
 \end{equation}
 By uniqueness, since both $\psi_{0z}$ and $\nabla_zN \cdot\vec{d}$ satisfy homogeneous Neumann
 boundary conditions  on $\partial \Omega$, there holds the identity
 \begin{equation}
  \psi_{0z}(x) = \nabla_zN(x,z) \cdot \vec{d}.
 \end{equation}
 \begin{definition}
 \label{def:layer-potentials}
 We define the following integral functions, for $\partial D$ of class $C^2$ and a given density $\psi\in C(\partial D)$
 \begin{enumerate}
  \item the \emph{single layer} potential
   \begin{equation}
    \mathcal{S}(\partial D,\psi)(x)\coloneqq \int_{\partial D} \Phi(x, y)\psi(y)\, dy,\quad x\in\mathbb{R}^m \backslash\partial D, \label{eq:definition-single-layer}
   \end{equation}
  \item the \emph{double layer} potential
   \begin{equation}
    \mathcal{D}(\partial D,\psi)(x)\coloneqq \int_{\partial D} \partial_{\nu(y)}\Phi(x, y)\psi(y)\, dy,\quad x\in\mathbb{R}^m \backslash\partial D. \label{eq:definition-double-layer}
   \end{equation}
 \end{enumerate}
\end{definition}
\begin{remark}
The single layer and the double layer potentials solve the same differential equation of the fundamental solution. In our case, they are harmonic, and so analytic in $\mathbb{R}^m\backslash \partial D$. The same regularity holds true even for less regular curves, for example the Lipschitz ones.
\end{remark}
\begin{remark}
\label{rem:dimension}
The asymptotic behavior of the layer potential depends on dimension of $\mathbb{R}^m$.
The interpretation of the space $\mathbb{R}^2$ as the parametrization of $\mathbb{R}^3$ 
when there's no dependence on the third coordinate, reflects itself on the logarithmic 
behavior and no uniqueness results in $\mathbb{R}^2$. Indeed the curve $\partial D$ is the section of an infinite cylindric surface in $\mathbb{R}^3$, which is unbounded in $\mathbb{R}^3$.
\end{remark}
 Before the main theorem, we state a density lemma which will be useful later in the proof. For convenience's sake, we consider the $\mathbb{R}^3$ case, 
 where any single layer potential $\mathcal{S}(x)\to0$ as $|x|\to \infty$.
 \par
 In the sequel, $B$ will be a bounded simply connected open set such that $\Omega\subset B$.
\begin{lemma}[Density]
 \label{lemma:lsm-density}
 In $\mathbb{R}^3$ let $v\in H^1(D)$ be harmonic $\Delta v=0$, then for any $\epsilon>0$ there exists 
 a single layer potential $v^\epsilon\coloneqq\mathcal{S}(\partial B, \sigma^\epsilon)$ such that $\|v-v^\epsilon\|_{H^1(D)}<\epsilon$.
\end{lemma}
The proof can be found in \cite{somersalo:preprint}, which take advantage of the density result Lemma \ref{lemma:density-V-0}.
\begin{remark}
 In $\mathbb{R}^2$ the same density result holds for the set of layers $\mathcal{S}(\partial B, \sigma)+ \mathcal{D}(\partial B,\mu)$.
\end{remark}
We split the main result in two propositions.
\begin{proposition}[Constructive Part]
\label{prop:lsm-constructive}
Fix $z \in D$. Then for any $\epsilon > 0$ there exists an approximating harmonic layer $\mathcal{S}(\partial B, \omega^\epsilon_z)$ with density $\omega^\epsilon_z\in L^2(\partial B)$  such that
\begin{equation}
 \|({N_D} - {N_0})\partial_\nu\mathcal{S}(\partial B, \omega^\epsilon_z) - \psi_{0z}\|_{H^{1/2}(\partial\Omega)} < \epsilon,
\end{equation}
furthermore, when $z$ approaches the boundary $\partial D$, $\|\omega^\epsilon_z\|_{L^2(\partial B)}\to + \infty$.
\end{proposition}
\begin{proposition}[Counterpart]
\label{prop:lsm-counterpart}
Fix $z \in \Omega\backslash\overline{D}$. Then for any $\delta>0$ and $\epsilon > 0$ there exists an harmonic layer $\mathcal{S}(\partial B, \omega^{\delta, \epsilon}_z)$ with density $\omega^{\delta, \epsilon}_z\in L^2(\partial B)$ such that
\begin{equation}
 \|({N_D} - {N_0})\partial_\nu\mathcal{S}(\partial B, \omega^{\delta,\epsilon}_z) - \psi_{0z}\|_{H^{1/2}(\partial\Omega)} < \delta + \epsilon,
\end{equation}
and $\|\omega^{\delta, \epsilon}_z\|_{L^2(\partial B)}\to + \infty$ as $\delta\to 0$.
\end{proposition}
\begin{proof}
 [Proof of \ref{prop:lsm-constructive} (sketch).]
 All the details can be found in \cite{somersalo:preprint}. We split the proof in more steps, such that some can be adapted to variants of the statement.
 \begin{enumerate}
  \item Fixed $z\in D$, let $(u_z, v_z)$ be the solution of the ITP with boundary data $(\psi_{0z}|_{\partial D}, \partial_\nu\psi_{0z}|_{\partial D})$
  \begin{subequations}
  \begin{align}
   u_z &= v_z + \psi_{0z}, &&\textup{ on }\partial D,  \label{eq:proof-ITP-0} \\
   \partial_\gamma u_z &= \partial_\nu v_z + \partial_\nu \psi_{0z}, &&\textup{ on }\partial D. \label{eq:proof-ITP-1}
  \end{align}
  \end{subequations}
  \item By density result Lemma \ref{lemma:lsm-density}, for any $\delta(\epsilon)>0$ there exists $v^\epsilon_z\coloneqq\mathcal{S}(\partial B, \omega^\epsilon_z)$ such that
  \begin{equation}
   \|v_z-v_z^\epsilon\|_{H^1(D)}<\delta.
  \end{equation}
  \item Furthermore, define in $\Omega$ the auxiliary 
  \begin{equation}
   u^\epsilon_z\coloneqq\chi_Du_z + (1-\chi_D)(\psi_{0z} + v^\epsilon_z),
  \end{equation}
  such that $(\partial_\nu u^\epsilon_z -\partial_\nu v^\epsilon_z )|_{\partial\Omega}=\partial_\nu\psi_{0z}|_{\partial\Omega}=0$, and define the solution of the inclusion problem $w^\epsilon_z$, with the same boundary derivative
  \begin{align}
   w^\epsilon_z&\coloneqq M\partial_\nu u^\epsilon_z, \\
   r^\epsilon_z&\coloneqq w^\epsilon_z - u^\epsilon_z,
  \end{align}
  and the residual satisfies 
  \begin{align}
  \Delta r^\epsilon_z & = 0, \quad \textup{ in }\Omega\backslash\overline{D}, \\
  \divergence\gamma\nabla r^\epsilon_z &= 0,  \quad \textup{ in }D, \\
  \partial_\nu r^\epsilon_z &=0, \quad \textup{ on }\partial \Omega,
  \end{align}
  with transmission conditions on $\partial D$, denoting $[\partial_\gamma f]^+_- \coloneqq \partial_\nu f^+ - \partial_\gamma f^-$, using \eqref{eq:proof-ITP-0}--\eqref{eq:proof-ITP-1},
  \begin{align}
   [r^\epsilon_z]^+_- = [w^\epsilon_z]^+_- -[u^\epsilon_z]^+_- &=0 - (v^\epsilon_z - v_z), && \textup{ on }\partial D, \\
   [\partial_\gamma r^\epsilon_z]^+_- = [\partial_\gamma w^\epsilon_z]^+_- -[\partial_\gamma u^\epsilon_z]^+_-&= 0 - (\partial_\nu v^\epsilon_z - \partial_\nu v_z), && \textup{ on }\partial D.
  \end{align}
  \item By Green's formula and trace theorem, there follows the estimate
  \begin{align}
   \|r^\epsilon_z\|_{H^{1/2}(\partial \Omega} & \leq C_T\|r^\epsilon_z\|_{H^1(\Omega)} \\
   & \leq C\bigl(\|v_z - v^\epsilon_z\|_{H^{1/2}(\partial D)} + \|\partial_\nu v_z - \partial_\nu v^\epsilon_z\|_{H^{\, -1/2}(\partial D)}\bigr) \\
   & \leq C \|v_z - v^\epsilon_z\|_{H^1(D)}\leq C\delta,
  \end{align}
  and finally, since $\partial_\nu\mathcal{S}(\partial B, \omega^\epsilon_z) = \partial_\nu u^\epsilon_z = \partial_\nu v^\epsilon_z$ on $\partial \Omega$
  \begin{align}
   \|({N_D} - {N_0})\partial_\nu u^\epsilon_z - \psi_{0z}\|_{H^{1/2}(\partial\Omega)} &\leq \|(w^\epsilon_z- v^\epsilon_z) - \psi_{0z}\|_{H^{1/2}(\partial\Omega)} \\
   &\leq\|r^\epsilon_z\|_{H^{1/2}(\partial \Omega)}\leq C\delta,
  \end{align}
  with arbitrary small $\delta(\epsilon)>0$.
  \qedhere
 \end{enumerate}
\end{proof}
We note that in the step 2 of the last proof, \emph{for fixed $z \in D$}, we could have constructed a sequence $v^{\epsilon_n}_z$ converging to $v_z$ in $H^1(D)$
\begin{equation}
 \|v^{\epsilon_n}_z - v_z\|_{H^1(D)} < \delta_n, \quad \textup{ for }\delta_n \to 0,
\end{equation}
which implies a \emph{stronger result} that can't be obtained for the counterpart, when $z\in\Omega\backslash\overline{D}$.
\begin{remark}
 For fixed $z\in D$, there exist a sequence 
 $v^{\epsilon_n}_z\coloneqq\mathcal{S}(\partial B, \omega^{\epsilon_n}_z)$ 
 such that it's approximating as above, that is
\begin{equation}
 \|({N_D} - {N_0})\partial_\nu v^{\epsilon_n}_z - \psi_{0z}\|_{H^{1/2}(\partial\Omega)} < \epsilon_n, \quad \textup{ for }\epsilon_n\to 0,
\end{equation}
 and it is converging to some function $v_z$ in $H^1(D)$
\begin{equation}
 \|v^{\epsilon_n}_z - v_z\|_{H^1(D)} \to 0.
\end{equation}
 Obviously, $\{v^{\epsilon_n}_z\}_{n\in\mathbb{N}}$ is bounded in the same norm $H^1(D)$.
\end{remark}
\chapter{Reciprocity Gap Principle}
\label{ch:reciprocity}
In this chapter we discuss another method to reconstruct inclusions in a conductor. 
This method was first introduced in \cite{colton-haddar:rg} to recover obstacles from the far field data in acoustic inverse scattering theory 
(see also \cite{cakoni-mbarek-haddar:electromagnetic} for the electromagnetic case). It has been developed later
by \cite{dicristo-sun:2006}, \cite{dicristo-sun:2007}, when near field data are available. Our aim is to apply it in the context of electric impedance tomography to reconstruct inclusions.
\section{The Fundamental Solution}
\label{subsection:fundamental-solution}
We introduce the problem starting from the \emph{fundamental solution}, that's the solution of 
the differential operator with the forcing term equal to $\delta_{x_0}$.
The solution is meant in the distributional sense in $\mathbb{R}^m$. 
\par
We denote by $\Phi(x,x_0)$ the fundamental solution of the Laplace operator, that is
\begin{equation}
 - \Delta \Phi(x,x_0) = \delta_{x_0} \quad \textup{ in }\mathcal{D}'(\mathbb{R}^m),\label{eq:fundamental-in-dist}
\end{equation}
and by $\Phi_D(x, x_0)$ the corresponding fundamental solution of the inclusion differential operator, that is
\begin{equation}
 - \divergence\bigl(\gamma(x)\nabla \Phi_D(x,x_0)\bigr) = \delta_{x_0}\quad\textup{ in }\mathcal{D}'(\mathbb{R}^m), \label{eq:fundamental-D-in-dist}
\end{equation}
with $\gamma(x) = 1+(k-1)\chi_D$. 
All the equations are meant in the distributional sense, that is, using the integral notation,
\begin{equation}
 \int_{\mathbb{R}^m \backslash D}\nabla \Phi_D(x,x_0) \cdot \nabla v(x) \, dx + \int_{D} k \, \nabla \Phi_D(x,x_0) \cdot \nabla v(x) \, dx = v(x_0) \, \forall v \in \mathcal{D}(\mathbb{R}^m).
\end{equation}
In the first case, $\Phi(x,x_0)$ can be explicitly written, up to any harmonic additive function,
\begin{equation}
\label{eq:definition-Phi-23}
  \Phi(x,x_0)=
  \left\{
  \begin{aligned}
   &\dfrac{1}{2\pi}\log\dfrac{1}{| x - x_0|}, && m=2, \\
   &\dfrac{1}{4\pi}\dfrac{1}{| x  - x_0|}, && m=3, 
  \end{aligned}
  \right.
\end{equation}
while, in the second case, it has to be computed numerically when needed.
\begin{remark}
 The fundamental solution $\Phi(x,x_0)\in L^2_{loc}(\mathbb{R}^m)$, but $\Phi(x,x_0)\notin H^1_{loc}(\mathbb{R}^m)$.
\end{remark}
This fact can be circumvented, eliminating the singularity and looking for the potential $\Sigma(x,x_0)$ where
\begin{equation}
 \Phi_D(x,x_0)\coloneqq \Phi(x,x_0) + \Sigma(x,x_0).
\end{equation}
From now, we will assume for the conductivity:
\begin{enumerate}
 \item $\gamma(x) = 1$ for $x\in\mathbb{R}^m\backslash\overline{D}$ in the background space,
 \item $\gamma(x) = k$ for $x\in D$, a constant value $k\in \mathbb{R}$.
\end{enumerate}
Adding and subtracting $\gamma\nabla \Phi$, we obtain the equation for $\Sigma(x,x_0)$
\begin{equation}
 -\divergence\bigl(\gamma\nabla \Sigma(x,x_0)\bigr)=\divergence\bigl((\gamma - 1)\nabla\Phi\bigr)\,\textup{ in }\mathcal{D}'(\mathbb{R}^m),
\end{equation}
or equivalently
% \begin{mybox}
\begin{equation}
 \int_{\mathbb{R}^m \backslash D}\nabla \Sigma\,\nabla v\, dx + \int_{D} k \, \nabla \Sigma\,\nabla v \, dx = - \int_D(k-1)\,\nabla \Phi\,\nabla v \,dx\quad\forall v \in \mathcal{D}(\mathbb{R}^m).
 \label{eq:variational-F}
\end{equation}
% \end{mybox}
Selecting test functions in $C^\infty_c(D)$ and in $C^\infty_c(\mathbb{R}^m\backslash \overline{D})$, and using trace's theorems for smooth boundary, the problem can be restated.
\begin{problem} Find $\Sigma\in H^1_{loc}(\mathbb{R}^m)$ such that
% \begin{mybox}
\begin{align}
 &-\Delta \Sigma(x,x_0) = 0,\quad\textup{ in }D, \label{eq:laplacian-D}\\
 &-\Delta \Sigma(x,x_0) = 0,\quad\textup{ in }\mathbb{R}^m\backslash\overline{D}, \label{eq:laplacian-outside-D}
\end{align}
with \emph{transmission conditions}
% \vspace{-0.2cm}
\begin{subequations}
\label{eq:transmissionSigma01}
\begin{align}
 \bigl[\Sigma\bigr]^+_-\bigl(y,x_0\bigr) &=0, && y \in\partial D, \label{eq:transmissionF0}\\ 
 \bigl[\partial_\gamma \Sigma\bigr]^+_-\bigl(y,x_0\bigr) &= (k - 1)\partial_\nu \Phi(y,x_0), && y \in\partial D. \label{eq:transmissionF1}
\end{align}
\end{subequations}
% \end{mybox}
\end{problem}
\begin{remark}
 We write explicitly the transmission conditions of $\Phi_D(x,x_0)$, which will be several times invoked in the sequel:
% \begin{mybox}
% \vspace{-0.2cm}
\begin{subequations}
\begin{align}
 \bigl[\Phi_D\bigr]^+_-\bigl(y,x_0\bigr)&=\Phi_D^+(y,x_0) - \Phi_D^-(y,x_0) =0, & y \in\partial D, \label{eq:transmissionPhiD0}\\ 
 \bigl[\partial_\gamma \Phi_D\bigr]^+_-\bigl(y,x_0\bigr) &= \partial_\nu \Phi_D^+(y,x_0) - k\,\partial_\nu \Phi_D^-(y,x_0) =0, & y \in\partial D. \label{eq:transmissionPhiD1}
\end{align}
\end{subequations}
% \end{mybox}
\end{remark}
\section{Surface Potentials and Representation Formulas}
In the sequel, the domain $D$ will be of class $C^2$ satisfying Assumption \ref{assumption:connected}, will be of class $C^2$, if not differently specified.
Most of the following notions, can be found in \cite{kirsch:book}, \cite{colton-kress:book}, \cite{salsa:book}.
% We refer to previous definition of layer potentials \eqref{eq:definition-single-layer}--\eqref{eq:definition-double-layer}.
\begin{remark}
To help the comprehension, let us remind the physical interpretation in electrostatics of the single and the double layers:
\begin{enumerate}
 \item the single layer potential represents the potential generated by a density $\psi$ of electric charges on $\partial D$,
 \item the double layer potential represents the potential of a layer of dipoles on $\partial D$ of momentum $\psi$, oriented along the normal $\nu$.
\end{enumerate}
\end{remark}
For further properties of single and double layer potentials, it's convenient to define the following operators.
\begin{definition}
 We denote by $S$, $K$  and $K'$ the following integral operators defined on $C(\partial D)$, where $\partial D$ is of class $C^2$
 \begin{enumerate}
  \item  $ S: C(\partial D) \to C(\partial D)$
  \begin{equation}
  S\psi(x)\coloneqq\int_{\partial D}\psi(y) \Phi(x,y)\,dy,\label{def:operator-S}
  \end{equation}
  \item  $ K,K':C(\partial D) \to C(\partial D)$
  \begin{align}
  & K\psi(x)\coloneqq\int_{\partial D} \psi(y) \partial_{\nu(y)} \Phi(x, y) \,dy =\int_{\partial D} \psi(y) \nabla_y\Phi(x, y)\cdot\nu(y) \,dy,\label{def:operator-K}\\
  & K'\psi(x)\coloneqq\int_{\partial D} \psi(y) \partial_{\nu(x)} \Phi(x, y) \,dy =\int_{\partial D} \psi(y) \nabla_x\Phi(x, y)\cdot\nu(x) \,dy.\label{def:operator-K'}
  \end{align}
 \end{enumerate}
\end{definition}
\begin{remark}
 As notation highlights, interchanging the order of integration, the operator $K'$ is the adjoint of $K$, with respect the dual system $\langle C(\partial D), C(\partial D)\rangle$, 
 where the duality pairing is defined as
 \begin{equation}
  \langle\phi,\psi\rangle\coloneqq\int_{\partial D}\phi\psi\,dy.
 \end{equation}
\end{remark}
The behavior of layer potentials across the surface $\partial D$ is described by the \emph{jumps relations}, 
specified in the following theorem.
\begin{theorem}
 Let $\psi\in C(\partial D)$, $\partial D$ be of class $C^2$, and let 
 $\mathcal{S}(\psi,\partial D)$, $\mathcal{D}(\psi,\partial D)$ be the potentials in 
 Definition \ref{def:layer-potentials}, then
 \begin{enumerate}
  \item the single layer is continuous and 
  \begin{subequations}
  \begin{align}
   \mathcal{S}^\pm(z) &\coloneqq\lim_{h\to 0^\pm}\mathcal{S}(z+h\nu(z)) = S\psi(z)=\int_{\partial D}\psi(y)\Phi(z,y)\,dy \quad z\in\partial D, \label{eq:single-pm-0}\\
   \partial_\nu\mathcal{S}^\pm(z) &\coloneqq \lim_{h\to0^\pm} \nabla\mathcal{S}(z+h\nu(z))\cdot\nu(z) =  K'\psi(z) \,\mp\,\dfrac{1}{2}\psi(z) \quad z\in\partial D,\label{eq:single-pm-1}
  \end{align}
 \end{subequations}
 \item the double layer can be continuously extended from $D$ to $\overline{D}$, from $\mathbb{R}^m\backslash \overline{D}$ to $\mathbb{R}^m\backslash D$, and
  \begin{subequations}
  \begin{align}
   \mathcal{D}^\pm(z) &= K\psi(z) \pm\dfrac{1}{2}\psi(z)\quad z\in\partial D, \label{eq:double-pm-0}\\
   \partial_\nu\mathcal{D}^+(z) &= \partial_\nu\mathcal{D}^-(z) \quad z\in\partial D. \label{eq:double-pm-1}
  \end{align}
  \end{subequations}
 \end{enumerate}
\end{theorem}
Now, we will state some essential results for our continuation.
All the details and proofs can be found in \cite{kress:book}.
\begin{definition}
 Let $X,Y$ be Banach spaces of functions defined on a domain $G$ (it will be a boundary like $\partial \Omega$ for us), and $A:X\to Y$ be a \emph{Fredholm integral operator} 
 with kernel $K(x,y):G\times G\to \mathbb{R}$, that is
 \begin{equation}
  A\phi(x)\coloneqq\int_G K(x,y)\phi(y)\,dy\quad x\in G. \label{eq:def-integral-operator}
 \end{equation}
 Then, we denote
 \begin{enumerate}
  \item an integral equation of the \emph{first kind}
   \begin{equation}
    A\phi=f,
   \end{equation}
  \item an integral equation of the \emph{second kind}
   \begin{equation}
    \phi - A\phi=f,
   \end{equation}
 \end{enumerate}
where, the operator $A$ is a compact.
\end{definition}
\begin{definition}
 Let $A$ be an integral operator with integral kernel $K(x,y):G \times G \to\mathbb{R}$. We say that
 \begin{enumerate}
  \item $K$ is a \emph{continuous} kernel if $K(x,y)$ is continuous in $G\times G$,
  \item $K$ is a \emph{weakly singular} kernel if it's defined and continuous for all $x,y\in G\subset \mathbb{R}^m$, $x\neq y$, and if there exists a positive constant $M$ and 
  there exists $\alpha\in (0,m]$ such that
  \begin{equation}
   |K(x,y)|\leq M |x-y|^{\alpha-m}\quad x,y\in G, \, x\neq y.
  \end{equation}
 \end{enumerate}
\end{definition}
\begin{lemma}
\label{lemma:K-K'-compact}
 Let $\partial D$ be a smooth domain, then the operators $K$ and $K'$ are integral operators with a weakly singular kernel and therefore they are compact.
\end{lemma}
\begin{remark}
 In two dimension, for boundary $\partial D$ of class $C^2$, the operators $K$ and $K'$ turn out to be continuous.
\end{remark}
We limit ourselves to remind that \emph{jump relations for the double layer \eqref{eq:double-pm-0}--\eqref{eq:double-pm-1} can be put in correspondence with the interior and the exterior Laplace problem with Dirichlet data}.
\begin{theorem}
\label{theo:K-nullspace}
 The operators $I-2K$ and $I-2K'$ have trivial nullspaces
 \begin{equation}
  \mathcal{N}(I-2K)=\mathcal{N}(I-2K')=\{0\}.
 \end{equation}
 The nullspaces of the operators $I+2K$ and $I+2K'$ have dimension one and
 \begin{equation}
  \mathcal{N}(I+2K)=\textup{span}\{1\}, \quad \mathcal{N}(I+2K')=\textup{span}\{\psi_0\}, \quad\textup{ with }\int_{\partial D}\psi_0=0.
 \end{equation}
 Both the operators $K,K'$ have spectrum
 \begin{equation}
 \label{eq:K-spectrum}
  -\tfrac{1}{2}\in\sigma(K)=\sigma(K')\subset \bigl[-\tfrac{1}{2}, \tfrac{1}{2}\bigr).
 \end{equation}
\end{theorem}

\section{Direct Problem and Boundary Integrals}
The Direct Problem consists in computing the solution $u(x)$ of the following equation, 
with the inclusion $D$ and the conductivity $k$ known. The boundary condition depends on 
the physical problem we are interested to. 
We consider the Dirichlet boundary condition. The problem reads as follows.
% \begin{mybox}
\begin{problem}
Find $u \in H^1(\Omega)$ such that
\begin{equation}
  \begin{cases}
  \divergence((1+(k-1)\chi_D)\nabla u(x,x_0)) = 0, & \textup{ in }\Omega,\\
  u = f, & \textup{ on } \partial\Omega,
 \end{cases}
\end{equation}
with $f\in H^{1/2}(\partial\Omega)$.
\end{problem}
% \end{mybox}
In concrete applications, the function $u$ is not computed, though it's observed on the 
surface $\partial\Omega$ and the measures $u|_{\partial \Omega}$, 
$\partial_\nu u|_{\partial \Omega}$ are considered for the definition of the reciprocity gap operator. Dirichlet data $f$ are the values of the generic potential which we are able to generate from the exterior: it can be a plane wave in the scattering case, or the potential generated by a point source $\delta_{x_0}$. In the latter case we are referring to the fundamental solution, and by uniqueness, the same $u$ is equal to $u(x)=\Phi_D(x,x_0)$ for $x\in \Omega$.
In the sequel $B$ is the background medium which contains $\Omega\subset B$.
\begin{definition}
\label{def:setU}
We will denote by $\mathcal{U}$ the set of functions
\begin{equation}
 \mathcal{U}\coloneqq\bigl\{\Phi_D(x, x_0): x_0\in \partial B\bigr\},
\end{equation}
where $\Phi_D$ is the fundamental solution, which solves \eqref{eq:fundamental-D-in-dist}.
\end{definition}
% \begin{figure}[tb]
% \begin{center}
%  \begin{tikzpicture}
%   \draw [dashed] (2,2) ellipse (3cm and 2cm);
%   \draw [dashed] (2,2) ellipse (1.5cm and 1cm);
%   \draw (2,2) circle (0.5cm);
%   %\draw (2,2) rectangle (1cm and 3cm);
%   \node at (-0.5,2){$B$};
%   \node at (1,2){$\Omega$};
%   \node at (2,2){$D,k$};
%  \end{tikzpicture}
% \end{center}
% \end{figure}
At this point we have to decide which method to use to compute the solution of \eqref{eq:laplacian-D}--\eqref{eq:transmissionSigma01}. The natural choice, for this differential problem, is the Boundary Integrals Method, 
which expresses the solution in terms of surface integrals, and looks for integral equations for unknown densities. 
\par
The crucial step is to select the most suitable open set and representation formula. It's easy in this case, since the constant valued conductivity $k(x)=k$ implies Laplace equation \eqref{eq:laplacian-D} inside $D$, other than outside, for which the fundamental solution is well known.
\par
In conclusion, it's possible to represent a generic solution of \eqref{eq:variational-F} 
in $\mathbb{R}^m\backslash\partial D$, with prescribed asymptotic behavior at infinity depending on the dimension of $\mathbb{R}^m$, as the sum of a single and a double layer potential with densities equal to the correspondent jumps 
\begin{equation}
 \Sigma(x) = \int_{\partial D}\partial_{\nu(y)}\Phi(x,y)\bigl[\Sigma(y)\bigr]_{\partial D}\,dy-\int_{\partial D}\Phi(x,y)\bigl[\partial_\gamma \Sigma(y)\bigr]_{\partial D}\,dy.
\end{equation}
The condition \eqref{eq:transmissionF0} implies continuity of $\Sigma$. Finally the problem reduces to derive an integral equation from \eqref{eq:transmissionF1} for the density $\psi$, where
\begin{equation}
 \Sigma(x)=\int_{\partial D}\Phi(x,y)\psi(y)\,dy = \mathcal{S}(\partial D, \psi).
\end{equation}
It's sufficient to substitute jump relations \eqref{eq:single-pm-1} of $\partial_\nu\mathcal{S}$ in \eqref{eq:transmissionF1} to derive the necessary \emph{integral equation of the second kind} for the unknown density
\begin{center}
\begin{equation}
 \label{eq:eq-psi-ck}
 \Bigl(K' + \frac{\hat{c}(k)}{2} I\Bigr)\psi = -\partial_\nu \Phi_{x_0}\quad\textup{ on }\partial D,
\end{equation}
\end{center}
with 
\begin{equation}
 \hat{c}(k)\coloneqq\dfrac{k+1}{k-1} > 1 \quad \textup{ for } k>1.
\end{equation}
\begin{lemma}
 The integral equation \eqref{eq:eq-psi-ck} has a unique solution $\psi(y,x_0)=\psi(y) \in C(\partial D) \subset L^2(\partial D)$ for any $x_0 \in \partial B$.
\end{lemma}
\begin{proof}
 Equation \eqref{eq:eq-psi-ck} is an integral equation of the second kind, which involves a compact operator $K'$, 
 as stated in Lemma \ref{lemma:K-K'-compact}. The knowledge of the spectrum $-1/2 \in \sigma(K')=\sigma(K) \subset [-1/2,1/2)$ and the condition $\hat{c}(k)>1$ imply injectivity of the operator in the equation \eqref{eq:eq-psi-ck}. 
 By the Fredholm's alternative, the operator $K'+(\hat{c}(k)/2)I:C(\partial D)\to C(\partial D)$ is continuous and bijective, with bounded inverse.
 Therefore the equation is well-posed and there exists a unique solution $\psi$.
\end{proof}
According with the fact that the charge density on $\partial D$ is induced by the exterior 
potential, we verify that the sum of charge is zero.
\begin{lemma}
 The density $\psi$ has zero mean
 \begin{equation}
  \int_{\partial D} \psi(y)\, dy = 0.
 \end{equation}
\end{lemma}
\begin{proof}
We show two ways, since they are useful in other contexts. By the knowledge of the spectrum,
 \begin{equation*}
  -\frac{\hat{c}}{2} \int_{\partial D} \psi\,dy = -\frac{\hat{c}}{2} \langle \psi,1\rangle = \langle K'\psi,1\rangle + \langle \partial_\nu\Phi_{x_0},1\rangle = \langle \psi,K 1\rangle + 0 = -\frac{1}{2}\int_{\partial D} \psi.
 \end{equation*}
 In alternative, more directly by transmission conditions \eqref{eq:transmissionPhiD1}, with harmonicity of $\Phi_D(\cdot,x_0)$ in $\mathbb{R}^2\backslash(\partial D\cup\{x_0\})$,
 \begin{equation*}
  -\psi=\partial_\nu \Phi_D^+-\partial_\nu \Phi_D^-=(1-\frac{1}{k})\partial_\nu \Phi_D^+ = (k-1)\partial_\nu \Phi_D^-.
 \end{equation*} 
\end{proof}

\section{The Conductor Problem}

\begin{figure}
% \centering
\subfloat[][\emph{An isolated conductor}.]
{
\begin{tikzpicture}
\draw [fill=light-gray, draw=gray] (0,0.2) ellipse (2.5cm and 2cm);
\node at (-1.9,1.9){$\partial B$};
\end{tikzpicture}
}
\subfloat[][\emph{An isolated conductor with inclusion}.]
{
\begin{tikzpicture}
% \draw [help lines] (-4, -1) grid (4, 5);
% \filldraw [show curve controls] (-1, -1) 
%   .. controls ++(165:-1) and ++(270: 1) .. ( 1.5, 1)
\draw [fill=light-gray, draw=gray] (0,0.2) ellipse (2.5cm and 2cm);
\filldraw [fill=gray, draw=gray] (0, -1) 
  .. controls ++(165:-1) and ++(145:-1) .. ( 1, 1)
  .. controls ++(145: 1) and ++(60: 0.7) .. (-1, 1)
  .. controls ++(60:-0.7) and ++(165: 1) .. ( 0, -1);
\node at (-1.9,1.9){$\partial B$};
\node at (-1.2,1.2){$\partial D$};
\end{tikzpicture}
}
\caption{Two different geometries for impedance equation}
\label{fig:subfig}
\end{figure}


In this subsection we describe a common physical experiment to show a particular solution, which will be useful later.
\par
In electrostatics, we define \emph{conductor} a material in which electric charges are 
free to move. In \emph{static} configurations,
charges arrange themselves on the surface of the conductor, in such a way that the \emph{electric potential $u$ is constant inside the conductor}. 
This entails that $\nabla u$ vanishes inside it.
\par
We denote by $\alpha_{c}$ the charge density of the simple layer which describes this specific problem. We adopt the notation from previous geometry and name $\partial B$ the surface of the conductor.
We define
\begin{equation}
 \mathcal{S}_{c}(\partial B, \alpha_c)\coloneqq\int_{\partial B}\Phi(x,x_0)\alpha_{c}(x_0)\,dx_0.
\end{equation}
We compute it, by imposing $\partial_\nu \mathcal{S}_{c}^- = 0$ on $\partial B$, that is
\begin{equation}
 \partial_\nu\mathcal{S}_{c}^-=\Bigl(K'+\dfrac{1}{2}I\Bigr)\alpha_{c}= 0\quad\textup{ on }\partial B. \label{eq:alpha_c-equation}
\end{equation}
The kernel $\mathcal{N}(K' + 1/2 I)=\textup{span}(\{\alpha_{c}\})$ is one dimensional as stated in Theorem \ref{theo:K-nullspace}, and the integral $\alpha_{cm} \cdot|\partial B|$ of any non trivial solution, where $\alpha_{cm}$ is the mean value, is equal to the total amount of electric charge.
\par
Now we imagine the same conductor containing an inclusion with impedance $\gamma(x)=k$ inside $D$. The electric potential $\mathcal{E}$ generated by source charges on $\partial B$ is described by the single layer constructed with the fundamental solution $\Phi_D(x,x_0)$, which solves \eqref{eq:fundamental-D-in-dist}
\begin{equation}
 \Phi_D(x,x_0)\coloneqq\Phi(x,x_0)+\mathcal{S}(\partial D,\psi_{x_0}).\label{eq:decomposition-Phi-D}
\end{equation}
We plug it in the integral of the electric potential and we get
\begin{align}
 \mathcal{E}(x)&\coloneqq\int_{\partial B}\Phi_D(x,x_0)\alpha(x_0)\,dx_0= \label{eq:definition-E-c}\\
  &=\mathcal{S}(\partial B, \alpha)(x) + \int_{\partial D} \Big(\int_{\partial B}\psi(y,x_0)\alpha(x_0)\,dx_0\Big)\Phi(x,y)\,dy = \\
  &=\mathcal{S}(\partial B, \alpha)(x) + \mathcal{S}(\partial D, \psi_{\alpha})(x). \label{eq:decomposition-E-c}
\end{align}
Now we state a proposition which explain the interest of $\alpha_{c}$.
\begin{proposition}
\label{prop:alpha_c-both-problems}
 We denote by $\alpha_{c}$ the density which makes the single layer $\mathcal{S}(\partial B, \alpha_{c})$ constant inside $\overline{B}$.
 Than the electric potential $\mathcal{E}_{c}$ \eqref{eq:definition-E-c}, constructed with the same $\alpha_{c}$, is constant inside $\overline{B}$.
\end{proposition}
\begin{proof}
We will prove that the unknown density $\psi_{\alpha_c}$ in the decomposition \eqref{eq:decomposition-E-c} is zero. 
To show this, we take advantage of transmission conditions on $\partial D$. 
Indeed from the definition we can derive two weak formulations for 
$\mathcal{S}(\partial B, \alpha_c)$ and $\mathcal{E}_c$ 
as in section \ref{subsection:fundamental-solution}
\begin{align}
 -\Delta\mathcal{S}(\partial B,\alpha_c) &= 0,\quad\textup{ in }B,\\
 -\divergence\bigl(\gamma\nabla\mathcal{E}_c\bigr) &= 0,\quad\textup{ in }B.
\end{align}
Taking the transmission conditions of the two equations on $\partial D$, we note that it's sufficient to change the forcing term equal to $(k-1)\,\partial_\nu\mathcal{S}(\partial B, \alpha_{c})$ in \eqref{eq:transmissionF1} to obtain the desired equation
\begin{equation}
 \bigl[\partial_\gamma \mathcal{S}(\partial D,\psi_{\alpha_{c}})\bigr]^+_-\bigl(y\bigr) = (k - 1)\partial_\nu \mathcal{S}(\partial B,\alpha_{c})=0 \quad y \in\partial D,
\end{equation}
which vanishes, since $\alpha_{c}$ generates constant potential $\mathcal{S}(\partial B,\alpha_{c})$ in $B$. The last transmission condition, can be rewritten, by substitution of integral boundary operators,
\begin{equation}
 \Bigl(K' + \frac{\hat{c}(k)}{2} I\Bigr)\psi_{\alpha_c} = -\partial_\nu \mathcal{S}(\partial B, \alpha_c) = 0,
\end{equation}
which has only the zero solution, since the operator on the left side is injective, as stated in \ref{theo:K-nullspace}.
\end{proof}
\begin{remark}
 The $\alpha_c$ is the electric density which is measured on the surface of the conductor $\partial B$ in both geometries. Indeed the potential is constant in both cases.
\end{remark}
\section{Reciprocity Gap Operator}
From now, we work in $\mathbb{R}^2$ to develop numerical discretization. 
For our purposes, we need to define a set of test functions $\mathcal{V}$, such that 
they describe the physical problem without the inclusion. The idea is to construct from the available 
data the \emph{reciprocity gap} operator, defined on $\mathcal{V}$, to measure the \emph{discrepancy}, or the \emph{gap} 
between the domain with the inclusion and without the inclusion 
(see \cite{colton-haddar:rg}, \cite{dicristo-sun:2006}, \cite{dicristo-sun:2007} 
for the corresponding case in inverse scattering).
\begin{definition}
\label{def:setV}
Let $u\in\mathcal{U}$, the set in Definition \ref{def:setU}. In our case $u(x,x_0)=\Phi_D(x,x_0)$, with $x_0 \in \partial B$, then
\begin{enumerate}
 \item we denote by $\mathcal{V}(\overline{B})$ the set of harmonic function, continuously defined on $\overline{B}$,
 \item by $\mathcal{V}_0(\overline{B})$ the subspace of vanishing mean functions, that is
 \begin{equation}
  \mathcal{V}_0(\overline{B})\coloneqq\Bigl\{v\in\mathcal{V}(\overline{B}):\int_{\partial B} v = 0\Bigr\}=\mathcal{V}(\overline{B})/\textup{span}\bigl(\{1\}\bigr),
 \end{equation}
 \item by $\textup{R} : \mathcal{V}(\overline{B})\to L^2(\partial B)$ the \emph{reciprocity gap} operator defined by
\begin{equation}
 \textup{R}(v)(x_0)\coloneqq \mathcal{R}_{\partial\Omega}\bigl(u(\cdot,x_0),v(\cdot)\bigr)\coloneqq \int_{\partial \Omega}\bigl(u(y,x_0)v_\nu (y) - u_\nu(y,x_0)v(y)\bigr)dy.
\end{equation}
\end{enumerate}
\end{definition}


\begin{figure}[]
\begin{center}
 \begin{tikzpicture}
  \draw [dashed] (2,2) ellipse (3cm and 2cm);
  \draw [dashed] (2,2) ellipse (1.5cm and 1cm);
  \draw (2,2) circle (0.5cm);
  %\draw (2,2) rectangle (1cm and 3cm);
  \node at (-0.5,2){$B$};
  \node at (1,2){$\Omega$};
  \node at (2,2){$D,k$};
 \end{tikzpicture}
\end{center}
\caption{Geometry of the problem}
\end{figure}


\begin{remark}
 \label{rem:kernel-R}
 Observe, by simple substitution, that for any constant function, $\textup{R}(v_c)=0$, where $v_c(x)\coloneqq c$, $c\in\mathbb{C}$, $x\in\overline{B}$.
\end{remark}
\begin{proposition}[Injectivity]
\label{prop:injectivity}
 The operator $\textup{R}$ is injective in $\mathcal{V}_0(\overline{B})$. The kernel of $\textup{R}$ is the one dimensional vector space $\mathcal{N}(\textup{R})=\textup{span}(\{1\})$, spanned by the constant.
\end{proposition}
\begin{proof}
By Lemma \ref{rem:kernel-R}, we just need to show that the only harmonic functions such that $\textup{R}(v)(x_0)=0$ for $x_0\in\partial B$, are constant functions.
\par
Let $v\in\mathcal{V}(\overline{B})$ and assume $\textup{R}(v)=0$. Applying the Green's representation formula in the open set $\Omega\backslash\overline{D}$ to $u\in\mathcal{U}$ and $v$, 
where they are both harmonic, with continuous extension up to the boundary, we get
\begin{equation}
  \text{R}(v)(x_0)\coloneqq\mathcal{R}_{\partial\Omega}\bigl(u(\cdot,x_0),v(\cdot)\bigr) = \mathcal{R}_{\partial D}\bigl(u^+(\cdot,x_0),v(\cdot)\bigr) = 0.
 \end{equation}
 By transmission conditions \eqref{eq:transmissionPhiD0}--\eqref{eq:transmissionPhiD1} of $u$ and by Green's identity in $D$, we have
 \begin{align*}
  \mathcal{R}_{\partial D}\bigl(u^+(\cdot,x_0),v(\cdot)\bigr) &= \int_{\partial D}\bigl(u^-(y,x_0)v_\nu (y) - k \cdot u^-_\nu(y,x_0)v(y)\bigr)dy = \\
  &= \int_{\partial D}u^-(y,x_0)v_\nu (y)\,dy - k\int_{\partial D}u^-(y,x_0)v_\nu (y)\,dy = \\
  &= (1-k)\int_{\partial D}u^-(y,x_0)v_\nu (y)\,dy = 0.
 \end{align*}
 Now define
 \begin{equation}
  f(x_0)\coloneqq \int_{\partial D} u(y,x_0)v_\nu(y)dy\quad x_0 \in \mathbb{R}^2\backslash\partial D.
 \end{equation}
 We note that $f(x_0)=0$ on $\partial B$ and 
 that $f(x_0)$ is harmonic in $\mathbb{R}^2\backslash\overline{D}$, by reciprocity relation Proposition \ref{prop:reciprocity}.
 Note that the density $v_\nu(y)$ has vanishing mean, since $v$ is harmonic. This implies that in $\mathbb{R}^2$, $f(x_0)$ is bounded at infinity, while in $\mathbb{R}^3$ boundedness of $D$ prevents any kind of this bad growth.
 \par
 By uniqueness of exterior boundary value problem in $\mathbb{R}^2\backslash\overline{B}$, and by continuation 
 principle of analytic functions from the open $\mathbb{R}^2\backslash\overline{B}$ to the 
 open $\mathbb{R}^2\backslash\overline{D}$, we conclude $f=0$ in $\mathbb{R}^2\backslash\overline{D}$.
 At the end, by continuity on $\partial D$, and by uniqueness in $D$, we conclude that $f(x_0)=0$ in $\mathbb{R}^2$.
 \par
 By jump relations of the derivatives of $f(x_0)$, $v_\nu = 0$. Finally, imposing homogeneous Neumann condition to interior problem in $D$, 
 we conclude that $v$ is constant in $D$ and in $\overline{B}$.
\end{proof}

\begin{lemma}[Density]
\label{lemma:density-V-0}
 The set $\{v|_{\partial D}: v\in \mathcal{V}(\overline{B})\}$ is dense in $L^2(\partial D)$.
\end{lemma}
\begin{proof}
 We fix a generic $\beta \in L^2(\partial D)$ and we assume that the product, with all the harmonic
 functions $v$ of the form $v=\mathcal{S}(\partial B,\sigma) + \mathcal{D}(\partial B, \mu)$, vanishes. Our aim is to show that $\beta=0$.
 \begin{enumerate}
  \item First, integrate with a single layer
 \begin{align*}
  0=\langle\mathcal{S}({\partial B},\sigma), \beta\rangle_{L^2(\partial D)} &= \int_{\partial D} \int_{\partial B} \sigma(y) \Phi(x,y)\,dy\,\beta(x)\,dx \\ 
  &= \langle\sigma, \mathcal{S}({\partial D},\beta)\rangle_{L^2(\partial B)}\quad\forall\sigma\in C(\partial B),
 \end{align*}
 which implies $\mathcal{S}(\partial D,\beta) = 0$ on $\partial B$ (this is not enough, as example \ref{example:van-s-lay} shows).
 \item Then, we test the product with a double layer
 \begin{align*}
  0=\langle\mathcal{D}({\partial B},\mu), \beta\rangle_{L^2(\partial D)} &= \int_{\partial D} \int_{\partial B} \mu(y) \partial_{\nu(y)}\Phi(x,y)\,dy\,\beta(x)\,dx \\
  &= \int_{\partial B} \partial_\nu \mathcal{S}(\partial D, \beta)(y) \mu(y)\, dy\quad \forall \mu\in C(\partial B),
 \end{align*}
 which implies $\partial_\nu \mathcal{S}(\partial D, \beta) = 0$ on $\partial B$, and it vanishes the total flux, that is
 \end{enumerate}
 \begin{equation*}
  0=\int_{\partial B} \partial_\nu \mathcal{S}(\partial D,\beta)(y)\,dy =\int_{\partial D} \int_{\partial B} \partial_{\nu(y)} \Phi(x,y)\, dy \, \beta(x) dx = - \int_{\partial D} \beta(x) \, dx.
 \end{equation*}
 Any single-layer $\mathcal{S}(\partial D, \beta)$ with vanishing total flux has vanishing total charge $\beta_m\cdot |\partial D|$, and therefore it's bounded. 
 We note that $\mathcal{S}(\partial D, \beta)$ is harmonic in $\mathbb{R}^2\backslash\overline{B}$, and it has homogeneous Cauchy boundary conditions on $\partial B$.
 By uniqueness result for exterior problem, $\mathcal{S}(\partial D,\beta) = 0$ in $\mathbb{R}^2\backslash\overline{B}$. 
 \par
 Then, by continuation principle, $\mathcal{S}(\partial D,\beta) = 0$ in $\mathbb{R}^2\backslash\overline{D}$,
 by maximum principle in $D$ we have $\mathcal{S}(\partial D,\beta) = 0$ in $\mathbb{R}^2$ 
 and finally by jump relation we conclude $\beta = 0$.
\end{proof}
\begin{lemma}[Density]
\label{lemma:density-V-1}
 The set $\{(\partial_\nu v )|_{\partial D}:v\in \mathcal{V}(\overline{B})\}$ is dense in $L^2_0(\partial D)\coloneqq L^2(\partial D)/\textup{span}(\{1\})$ (closure of vanishing mean smooth functions).
\end{lemma}
\begin{proof}
 First of all, we observe that any constant function defined on $\partial D$, is orthogonal 
 to $\partial_\nu v$ with $v\in\mathcal{V}(\overline{B})$, indeed
 \begin{equation*}
  \langle \partial_\nu v, 1\rangle_{L^2(\partial D)} = \int_{\partial D}\partial_\nu v\,dy=0
 \end{equation*}
 Now we fix a generic $\beta\in L^2(\partial D)$ such that the product of $\beta$ with all test functions in $\mathcal{V}(\overline{B})$ is zero. 
 Consider the set
 \begin{equation}
  \Bigl\{\mathcal{S}(\partial B, \sigma)(x) = \int_{\partial B} \sigma(y)\Phi(x,y)\,dy\,:\, \sigma \in C(\partial B)\Bigr\} \subset \mathcal{V}(\overline{B}).
 \end{equation}
 Then $\forall\sigma\in C(\partial B)$ we exchange the order of integration in this way $0=\langle\mathcal{A}\sigma,\beta\rangle_{L^2(\partial D)} =\langle\sigma,\mathcal{A}^*\beta\rangle_{L^2(\partial B)}$, explicitly $\forall\sigma\in C(\partial B)$
 \begin{align*}
  0 = \int_{\partial D}\partial_\nu \mathcal{S}(\partial B, \sigma)(x) \beta(x) \, dx &= \int_{\partial D}\Big( \int_{\partial B}\nabla_x \Phi(x,y) \sigma(y)\,dy\Big)\cdot\nu(x)\beta(x) \, dx = \\
   &= \int_{\partial B}\Big( \int_{\partial D}\partial_{\nu(x)} \Phi(x,y) \beta(x)\,dx\Big)\sigma(y) \, dy,
 \end{align*}
 and now we define the double layer potential
 \begin{equation}
  f(y)\coloneqq \mathcal{D}(\partial D, \beta)(y)=\int_{\partial D}\partial_{\nu(x)} \Phi(x,y) \beta(x)\,dx,
 \end{equation}
 which vanishes $f(y)=0$ on $y\in\partial B$, as we have previously shown.
 It is harmonic in $\mathbb{R}^2\backslash\partial D$ and bounded, as any double layer potential. 
 By uniqueness of bounded harmonic functions for exterior Dirichlet problem and by continuation principle, we obtain $f=0$ in $\mathbb{R}^2\backslash\overline{D}$. At this point, the double layer potential $f$ vanishes outside $D$, and the boundary integral operator has $\mathcal{N}(K+1/2\,I)=\textup{span}(\{1\})$. This force $\beta$ to be a generic constant. 
 We have just shown that $\{(\partial_\nu v )|_{\partial D}\}^\perp = \textup{span}(\{1\})$, 
 which concludes the proof.
\end{proof}
\begin{remark}
 If we consider $v\in\mathcal{V}_0(\overline{B})$ instead of $\mathcal{V}(\overline{B})$, since the set $\{(\partial_\nu v )|_{\partial D}\}$ is the same in both cases, then the previous density result is still valid.
\end{remark}
\begin{proposition}[Surjectivity]
\label{prop:surjectivity}
 The range of the operator $\textup{R} : \mathcal{V}(\overline{B})\to L^2(\partial B)$  has codimension one, indeed $\mathcal{R}(R)^\perp=\textup{span}(\{\alpha_c\})$, where $\alpha_c$ is the solution of \eqref{eq:alpha_c-equation}.
\end{proposition}
\begin{proof}
 We consider $\alpha\in L^2(\partial B)$ and assume the product with $\textup{R}(v)$ to be equal to zero for all $\forall v\in\mathcal{V}(\overline{B})$
 \begin{equation*}
  0 =\langle\,\textup{R}(v), \alpha\rangle_{L^2(\partial B)} = \langle \mathcal{R}_{\partial\Omega}\bigl(u(\cdot,x_0),v(\cdot)\bigr), \alpha(x_0)\rangle_{L^2(\partial B)}.
 \end{equation*}
 Switching the order of integration between the sources' boundary $\partial B$ and
 the observations' boundary $\partial \Omega$ and defining a new source layer with density $\alpha$, 
 we have
 \begin{equation}
  0 = \mathcal{R}_{\partial \Omega}(\mathcal{E},v),\quad\textup{ where }\quad\mathcal{E}(x):=\int_{\partial B}u(x,x_0)\alpha(x_0)\, dx_0,
 \end{equation}
 By Green's identity and the transmission conditions \eqref{eq:transmissionPhiD0}--\eqref{eq:transmissionPhiD1} for $\mathcal{E}$, as in the proof of Proposition \ref{prop:injectivity}, we have
 \begin{equation}
  0 = \mathcal{R}_{\partial \Omega}(\mathcal{E},v)=(1-k)\int_{\partial D} \partial_\nu\mathcal{E}^-(y)v(y)\,dx\quad \forall v \in \mathcal{V}(\overline{B}).
 \end{equation}
 By density Lemma \ref{lemma:density-V-1}, we obtain $\partial_\nu\mathcal{E}^- = k\,\partial_\nu\mathcal{E}^+= 0$ on $\partial D$. 
 Now since $u(x,x_0)=\Phi(x,x_0)+\mathcal{S}(\partial D, \psi_{x_0})$, and we get
 \begin{align}
  \mathcal{E}(x)&=\mathcal{S}(\partial B, \alpha) + \int_{\partial D} \Big(\int_{\partial B}\psi(y,x_0)\alpha(x_0)\,dx_0\Big)\Phi(x,y)\,dy = \\
  &=\mathcal{S}(\partial B, \alpha) + \mathcal{S}(\partial D, \psi_\alpha).
 \end{align}
 By uniqueness of the interior homogeneous Neumann problem $\mathcal{E} = c$ in $D$, a constant which theoretically can be computed 
 from the definition of $\mathcal{E}$. And by the previous jump relation on $\partial D$, 
 we get that $\psi_\alpha=0$ on $\partial D$.
 Now we reformulating the expression for $\mathcal{E}$
 \begin{equation}
  \mathcal{E}(x)= \mathcal{S}(\partial B, \alpha) = \int_{\partial B}\Phi(x,x_0)\alpha(x_0)\, dx_0,
 \end{equation}
 by continuation principle from $D$ to $B$, $\mathcal{E}(x)=c$ in $B$. So, we are forced to looking for, if there exists, a single layer potential constant in $\overline{B}$. 
 Actually $\alpha$ solves the boundary integral equation, which we obtain by imposing the equivalent condition $\partial_\nu\mathcal{E}^-|_{\partial B}=0$
 \begin{equation}
  \partial_\nu\mathcal{E}_{c}^-=\Bigl(K'+\dfrac{1}{2}I\Bigr)\alpha_{c}= 0\quad\textup{ on }\partial B.
 \end{equation}
 We know that the kernel $\mathcal{N}(K' + 1/2 I)=\textup{span}(\{\alpha_{c}\})$ is one dimensional, where we have denoted by $\alpha_{c}$ the physical charge layer of total amount $\alpha_m |\partial B|$  which can be measured
 on the surface of a \emph{conductor}, with the property of a constant potential inside it.
Actually in Proposition \ref{prop:alpha_c-both-problems} we showed that if $\mathcal{S}(\partial B, \alpha_{c})$ is constant in $\overline{B}$, then
\begin{equation}
 \mathcal{E}_{c}(x)\coloneqq\int_{\partial B}u(x,x_0)\alpha_{c}(x_0)\,dx_0\label{eq:definition-E-pc}
\end{equation}
is constant itself in $\overline{B}$ and testing the initial product with every $v\in\mathcal{V}(\overline{B})$, we conclude that $\alpha_{c}$ is orthogonal to all of them, that is
\begin{equation}
 \langle \, \textup{R}(v) ,\alpha_{c}\rangle_{L^2(\partial B)}=\mathcal{R}_{\partial \Omega}(\mathcal{E}_{c}, v)=\int_{\partial\Omega}\bigl(\mathcal{E}_{c}\,\partial_\nu v - \partial_\nu\mathcal{E}_{c}\, v\bigr)\,dy=0,
\end{equation}
because $\mathcal{E}_{c}=c$, $\partial_\nu\mathcal{E}_{c}=0$ on $\partial\Omega$, and $\int_{\partial\Omega}\partial_\nu v=0$.
\end{proof}
\begin{remark}
Let us highlight here the essential difference between the two inverse problems: the scattering and the impedance one. 
In our case, the reciprocity gap operator has not dense image in $L^2(\partial B)$, 
whereas it is dense in the scattering case.
\end{remark}
Anyway we will consider the same right hand side term, usually adopted in \cite{colton-haddar:rg}, \cite{dicristo-sun:2006}, \cite{dicristo-sun:2007}.
We will examine the image of the operator $\textup{R}$, constructed from the fundamental solution $\Phi_z(x)\coloneqq\Phi(x,z)$, with fixed $z\in\Omega$:
\begin{equation}
 \tilde{R}(\Phi_z)(x_0) \coloneqq \mathcal{R}_{\partial\Omega}\bigl(u(\cdot,x_0),\Phi_z(\cdot)\bigr)\coloneqq \int_{\partial \Omega}\bigl(u(y,x_0){\Phi_z}_\nu (y) - u_\nu(y,x_0)\Phi_z(y)\bigr)dy.
\end{equation}
Now we evaluate the scalar product of $\tilde{R}(\Phi_z)$ with $\alpha_{c}$, which solves \eqref{eq:alpha_c-equation}, and we have
\begin{equation}
 \langle \, \tilde{\textup{R}}(\Phi_z) ,\alpha_{c}\rangle_{L^2(\partial B)}=\mathcal{R}_{\partial \Omega}(\mathcal{E}_{c}, \Phi_z)=\int_{\partial\Omega}\bigl(\mathcal{E}_{c}\,\partial_\nu \Phi_z - \partial_\nu\mathcal{E}_{c}\, \Phi_z\bigr)\,dy
\end{equation}
and by the properties of $\mathcal{E}_{c}$ defined in \eqref{eq:definition-E-c}, as reported in Proposition \ref{prop:alpha_c-both-problems}
\begin{align}
 &\mathcal{E}_{c}=c, \quad\textup{ on }\partial\Omega,\\
 &\partial_\nu\mathcal{E}_{c}=0,\quad \textup{ on }\partial\Omega,
\end{align}
we obtain
\begin{equation}
 \langle \, \tilde{\textup{R}}(\Phi_z) ,\alpha_{c}\rangle_{L^2(\partial B)} = c\,\int_{\partial\Omega}\partial_\nu\Phi_z\,dy = c\,\textup{Flux}\bigl(\partial\Omega, \Phi_z\bigr) = c\,(-1),
\end{equation}
while in the proof of Proposition \ref{prop:surjectivity}, we concluded 
\begin{equation}
 \langle \, \textup{R}(v) ,\alpha_{c}\rangle_{L^2(\partial B)}=0\quad \forall v\in\mathcal{V}(\overline{B}).
\end{equation}
Now, it's clear that \emph{it is not possible to approximate the right hand term $\tilde{\textup{R}}(\Phi_z)$ with $\textup{R}(v)$ for some $v$}.
\par
We need to modify the right hand side, and so we will look for a scalar function $\Psi_z$ satisfying the following conditions
\begin{enumerate}
 \item it has some kind of \emph{singularity in $z$} and 
 \begin{equation}
  \lim_{x\to z}\Psi_z(x) = \infty,\label{eq:condition-singularity}
 \end{equation}
  which exclude from the approximation all points outside $D$;
 \item \emph{its flux has to vanish}, across any surface outside the domain
 \begin{equation}
  \int_{\partial\Omega}\partial_\nu\Phi_z\,dy = \textup{Flux}\bigl(\partial\Omega, \Phi_z\bigr) = 0.\label{eq:condition-flux}
 \end{equation}
\end{enumerate}
From a physical perspective, Gauss's theorem states that the total flux of the electric potential, across a surface, is equal to the total amount of electric charge contained in it, times some constant.
From a physical viewpoint, \eqref{eq:condition-singularity}--\eqref{eq:condition-flux} represent a unit electric dipole 
with total charge zero which can be approximated as the limit of two charges 
of intensity $q=\pm1/(2\epsilon)$, that can be arbitrary close, located in $\pm\epsilon\vec{d}$ with displacement unit vector $|\vec{d}\,|=1$, with constant electrical momentum.
\begin{equation}
 \vec{\mu}\coloneqq \sum_{j=1}^2 q_jr_j\vec{d}_j=\dfrac{1}{2\epsilon}\epsilon\vec{d} -\dfrac{1}{2\epsilon}(-\epsilon\vec{d})=\vec{d}.
\end{equation}
The distributional description of the electric dipole is constructed, in the same way, by taking the distributional limit of two unit deltas $\pm1/(2\epsilon)\delta_{\pm\epsilon\vec{d}}\,$
\begin{equation}
 \dfrac{\delta_{\epsilon\vec{d}} - \delta_{-\epsilon\vec{d}}}{2\epsilon}=\dfrac{\delta(\vec{x} - \epsilon\vec{d}) - \delta(\vec{x}+\epsilon\vec{d})}{2\epsilon}\to -\nabla\delta(\vec{x})\cdot\vec{d}\, \textup{ for }\epsilon\to0^+.
\end{equation}
In view of these observations, we will consider the electric potential generated by a dipole of momentum $\vec{d}$
\begin{equation}
 -\nabla\delta_{\vec{x_0}}\cdot\vec{d}\, \Longrightarrow\, -\nabla\Phi(x,x_0) \cdot \vec{d}.
\end{equation}
\begin{definition}
\label{def:fund-sol-deriv-Psi}
We define
\begin{align}
 &\vec{\Psi}_z(x) = \vec{\Psi}(x,z) \coloneqq \nabla\Phi(x,z),\\
 &\Psi_z(x,\vec{d})= \Psi(x,z,\vec{d}) \coloneqq \vec{\Psi}(x,z)\cdot \vec{d} = \partial_{\vec{d}\,\,}\Phi(x,z),
\end{align}
where $\Phi$ is the fundamental solution of \eqref{eq:definition-Phi-23}
and $|\vec{d}\,|=1$ is a unit vector.
\end{definition}
Finally we can state the key theorem which provides a binary criterion to discriminate the inclusion from the background.
\begin{theorem}[Reciprocity Gap Approximation Theorem]
 \label{theo:approximation-rg} 
 Let $D\subset\Omega\subset B$  be an inclusion satisfying Assumption \ref{assumption:connected}, let $\{(u|_{\partial \Omega},\partial_\nu u|_{\partial \Omega})\}$ 
 be a set of measured data with $u\in\mathcal{U}$ as in Definition \ref{def:setU} and 
 let consider the class $\mathcal{V}(\overline{B})$ of harmonic test functions 
 in Definition \ref{def:setV}. Then
%  At the right hand side, we consider the directional derivative along some unit vector $\vec{d}$ of the fundamental solution, defined above in \ref{def:fund-sol-deriv-Psi}. Then
 \begin{enumerate}
  \item if $z \in D$ then there exists a sequence $\{v_n\} \subset \mathcal{V}(\overline{B})$ such that
   \begin{equation}
     \lim_{n\to\infty}\mathcal{R}(u,v_n) = \mathcal{R}(u,\Psi_z)\quad\forall u\in\mathcal{U},\label{eq:rg-lim-constructive}
   \end{equation}
   where $\Psi_z$ as in Definition \ref{def:fund-sol-deriv-Psi}, and $v_n|_{\partial D}\to g$ in $L^2(\partial D)$ and consequently  it's bounded in the same norm $\|v_n\|_{L^2(\partial D)}$;
  \item if $z \in \Omega \backslash D$ then any sequence $\{v_n\} \subset \mathcal{V}(\overline{B})$ such that
   \begin{equation}
     \lim_{n\to\infty}\mathcal{R}(u,v_n) = \mathcal{R}(u,\Psi_z)\quad\forall u\in\mathcal{U}\label{eq:rg-lim-counterpart}
   \end{equation}
   is unbounded $\|v_n\|_{L^2(\partial D)}\to\infty$ in $L^2(\partial D)$.
 \end{enumerate}
\end{theorem}
\begin{proof}
We split the proof in two parts.
 \begin{enumerate}
  \item Fixed $z \in D$, and using Neumann--to--Dirichlet operator of Laplace equation in $D$, ${N_0}:H^{\,-1/2}_0(\partial D)\to H^{1/2}(\partial D)$,
    we have
    \begin{align}
    \mathcal{R}_{\partial \Omega}(u,\Psi_z) &= \mathcal{R}_{\partial D}(u,\Psi_z) \\
    &= \int_{\partial D}(u\partial_\nu\Psi_z - \partial_\nu u^+ \Psi_z) \,dy\\
    &= \int_{\partial D}\bigl(\partial_\nu u^- {N_0}(\partial_\nu\Psi_z) - k \partial_\nu u^- \Psi_z\bigr) \,dy \\
    &= \int_{\partial D}\partial_\nu u^-\Big( {N_0}(\partial_\nu\Psi_z) - k \Psi_z)\Big) \,dy.
    \end{align}
  On the other end, for $v\in\mathcal{V}(\overline{B})$ we have
  \begin{equation}
   \mathcal{R}_{\partial \Omega}(u,v) = \mathcal{R}_{\partial D}(u,v) = \int_{\partial D}(1-k)(\partial_\nu u^- )v\,dy.
  \end{equation}
  By density result Lemma \ref{lemma:density-V-0}, there exists a sequence $\{v_n\}\subset \mathcal{V}(\overline{B})$ converging strongly and weakly in $L^2(\partial D)$ to the argument in the right integral $\bigl( {N_0}(\partial_\nu\Psi_z) - k \Psi_z)\bigr)(1-k)^{-1}\in H^{1/2}(\partial D)$.
  Once selected the sequence, the convergence holds for all $u\in\mathcal{U}$, but in general the convergence is not uniform in $x_0\in \partial B$.
  \item Fixed $z \in \Omega\backslash D$ and using Green's representation formula with derivatives \eqref{prop:repr-deriv} in $\Omega\backslash\overline{D}$, on the right hand side
  \begin{equation}
   \mathcal{R}_{\partial \Omega}(u,\Psi_z) = \partial_{\vec{d}}\,u(z,x_0) + \mathcal{R}_{\partial D}(u,\Psi_z) = \partial_{\vec{d}}\,u(z,x_0) + w(x_0),
  \end{equation}
  with $w(x_0)$ harmonic in $x_0 \in \mathbb{R}^2\backslash \overline{D}$ by reciprocity relation (\ref{prop:reciprocity}), while on the left side
  \begin{equation}
   \mathcal{R}_{\partial \Omega}(u,v_n) = \mathcal{R}_{\partial D}(u,v_n) = \int_{\partial D}(1-k)(\partial_\nu u^- )v_n\,dy.
  \end{equation}
  If we assume the existence of a bounded sequence $\{v_n\} \subset H^{1/2}(\partial D)$, then up to subsequences, by weak compactness we can extract $v_n$ converging weakly to some $f$ in $H^{1/2}(\partial D)$, yielding
  \begin{equation}
   \mathcal{R}_{\partial \Omega}(u,v_n) \to \int_{\partial D}(1-k)(\partial_\nu u^- )f\,dy = \widetilde{w}(x_0).
  \end{equation}
 Since both $\partial_{\vec{d}}\,u(z,x_0) + w(x_0)$ and $\widetilde{w}(x_0)$ are bounded harmonic functions
 in $\mathbb{R}^2\backslash\overline{B}$, coincident on $\partial B$, by uniqueness
 and continuation principle, we can conclude that they coincide on $\mathbb{R}^2\backslash (D\cup\{z\})$ arriving at a contradiction, by letting $x_0\to z$.
 \end{enumerate}
\end{proof}
\begin{remark}
 Let us stress here that these norms are equivalent. Indeed in the subspace of harmonics function with zero mean at the boundary $\mathcal{V}_0(\overline{B})$, evaluated on $D\subset B$, by Poincaré inequality, the following norms are equivalent
 \begin{equation}
  \|v\|_{H^1(D)},\quad\|\nabla v\|_{L^2(D;\,\mathbb{R}^2)},\quad \|\partial_\nu v\|_{H^{-1/2}(\partial D)},\quad \|v\|_{H^{1/2}(\partial D)}.
 \end{equation}
\end{remark}
\begin{remark}
 Taking an appropriate set of harmonic functions, like the single layer potentials $\{v=\mathcal{S}(\partial B,\,\sigma): \sigma \in C(\partial B)\}$, we can look for an approximating sequence in this set, 
 and \eqref{eq:rg-lim-constructive} reduces to the approximate equation
 \begin{equation}
  \textup{R}_u \sigma = r_z,\label{eq:rg-approximate-eq}
 \end{equation}
with $\textup{R}_u:\partial B\to \partial B$ and $r_z\in C(\partial B)$ defined as
\begin{align}
 &\textup{R}_u\sigma(x_0) \coloneqq  \textup{R}(v)(x_0)=\mathcal{R}_{\partial\Omega}\bigl(u(\cdot,x_0),v(\cdot)\bigr), \\
 & r_z(x_0)\coloneqq \mathcal{R}_{\partial\Omega}\bigl(u(\cdot,x_0),\Psi_z(\cdot)\bigr).
\end{align}
\end{remark}

\section{Technicalities}
In this section we first present an example which clarifies the dependence of density results 
on the dimension of the ambient space $\mathbb{R}^m$. Then we collect some technical results 
which has been used in the previous proofs.
\begin{example}
 \label{example:van-s-lay}
 In dimension $m=2$, there exists a simple layer potential on $\partial B_R(0)$ for any $R<1$ vanishing on a contour $\Gamma = \partial B_1(0)$:
 \begin{equation}
 s(x) = \mathcal{S}(\partial B_R(0), \sigma)(x) = \frac{1}{2\pi R}\int_{\partial B_R(0)}\frac{1}{2\pi}\log\frac{1}{|x-y|}\,dy.
 \end{equation}
 By symmetry, $s(x)=\tilde{s}(\,|x|\,)$ is a radial function, and by maximum principle, is constant in $B_R(0)$. This implies:
 \begin{equation}
  s(0) = \frac{1}{2\pi}\log\frac{1}{R}=\tilde{s}(R)=\tilde{\Phi}(R),
 \end{equation}
 where $\tilde{\Phi}(\,|x|\,)$ is the radial fundamental solution. Then
 \begin{align}
 & s(x) = \tilde{\Phi}(|x|), && |x| > R, \\
 & s(x) = 0,         && |x| = 1.
 \end{align}
 The consequence is that all single layer potentials $\mathcal{S}(\partial B_1, \sigma)$, evaluated on $\partial B_R$, are orthogonal to the constant function. This singular case depends on the geometry, and doesn't happen in dimension $m=3$.
\end{example}
\begin{remark}
 The asymptotic behavior at infinity of the fundamental solution $\Phi$ defined in \eqref{eq:definition-Phi-23}, can be infinite, depending on the dimension:
 \begin{equation}
 \label{eq:asymptotic-Phi-23}
  \Phi(x,x_0)=
  \left\{
  \begin{aligned}
   &\dfrac{1}{2\pi}\ln\dfrac{1}{|x|} + O\Bigl(\dfrac{1}{|x|}\Bigr), && m=2, \\
   &O\Bigl(\dfrac{1}{|x|}\Bigr), && m=3.
  \end{aligned}
  \right.
\end{equation}
 Furthermore, the asymptotic behavior, of a single layer potential, with continuous density on a compact set $\partial D$, with mean $\psi_m$, is:
  \begin{equation}
 \label{eq:asymptotic-single}
  \mathcal{S}(\partial D,\psi)=
  \left\{
  \begin{aligned}
   &\dfrac{1}{2\pi}\dfrac{\psi_m\cdot|\partial D|}{|x|} + O\Bigl(\dfrac{1}{|x|}\Bigr), \\% && m=2 \\
   &O\Bigl(\dfrac{1}{|x|}\Bigr). %&& m=3
  \end{aligned}
  \right.
\end{equation}
Consequently, the behavior at infinity of the fundamental solution of the inclusion problem $\Phi_D$, 
from the fact that it can be represented as the sum of the fundamental solution $\Phi$ and a single layer with zero mean density, is equal to the previous one \eqref{eq:asymptotic-Phi-23}. 
\end{remark}
\begin{proof} We consider only dimension $m=2$:
 \begin{equation}
  \ln|x-y|=\frac{1}{2}\ln\Big(x^2 + y^2 - 2 (x,y)\Big) = \ln|x| + \ln\Big(1+\frac{y^2}{x^2}-2\frac{1}{|x|}(\frac{x}{|x|},y)\Big)^{1/2}
 \end{equation}
 \begin{equation}
  \ln|x-y|=\ln|x|+O\Bigl(\frac{1}{|x|}\Bigr) \quad x\to\infty\quad \text{uniformly for }y\in\partial B.
 \end{equation}
 Let $\gamma(x)$ be a continuous density with zero mean:
 \begin{equation}
  \int_{\partial B}\gamma(x_0)\Phi(x,x_0)\, dx_0 = O\Bigl(\frac{1}{|x|}\Bigr)\quad x\to\infty.
 \end{equation}
 Instead let $\psi(x)=\psi_0(x)+\psi_m$ be a continuous density with mean $\psi_m$:
 \begin{equation}
  \int_{\partial B}\psi(x_0)\Phi(x,x_0)\, dx_0 = \dfrac{\psi_m\cdot |\partial D|}{2\pi}\ln\dfrac{1}{|x|} + O\Bigl(\frac{1}{|x|}\Bigr)\quad x\to\infty.
 \end{equation}
\end{proof}

\begin{proposition}[Classical Green's Representation]
 Let $D$ be a Lipschitz domain and $u,v \in C^2(D)\cap C^1(\overline{D})$ be regular functions, then integration by parts can be expressed as
  \begin{equation}
  \int_D (u \, \Delta v - \Delta u \, v)\, dx = \int_{\partial D}(u \, \partial_\nu v - \partial_\nu u \, v)\,d\sigma = \mathcal{R}_{\partial D}(u,v).
  \end{equation}
\end{proposition}
\begin{proposition}[Representation of harmonics]
 Let $D$ be a Lipschitz domain $D$, and $u \in C^2(D)\cap C^1(\overline{D})$ be a harmonic function, then it can be represented as sum of integrals, that is
  \begin{equation}
  - u(p_0) = \int_{\partial D}(u(p) \, \partial_{\nu(p)} \Phi(p,p_0) - \partial_\nu u(p) \, \Phi(p,p_0))\,dy.
  \end{equation}
 Indeed formally, for distributions in $\mathbb{R}^m$ which take to account the boundary of $D$, $\langle u,\Delta_p\Phi(p,p_0)\rangle = \langle u,-\delta_{p_0}\rangle = - u(p_0)$.
\end{proposition}
\begin{proposition}[Representation of derivatives]
 \label{prop:repr-deriv}
 Let $D$ be a Lipschitz domain $D$, and $u \in C^2(D)\cap C^1(\overline{D})$ be a harmonic function, and indicate the directional derivative of the fundamental solution as $\Psi$
  \begin{equation}
   \Psi(p,p_0,\vec{d}\,) \coloneqq\nabla\Phi(p,p_0)\cdot\vec{d} \quad |\vec{d}\,|=1,
  \end{equation}
 then
  \begin{equation}
  \partial_{\vec{d}\,}u(p_0) = \int_{\partial D}(u(p) \, \partial_{\nu(p)} \Psi(p,p_0,\vec{d}\,) - \partial_\nu u(p) \, \Psi(p,p_0,\vec{d}\,))\,dy.
  \end{equation}
 Again formally, without considering boundary of $D$, by Schwarz change $\langle u,\Delta_p\partial_{\vec{d}\,}\Phi(p,p_0)\rangle = \langle u,-\partial_{\vec{d}\,}\delta_{p_0}\rangle = \langle \partial_{\vec{d}\,}u,\delta_{p_0}\rangle = \partial_{\vec{d}\,}u(p_0)$.
\end{proposition}
\begin{proof}
 We will consider only the case in two dimension $\mathbb{R}^2$.
 By classical Green's formula for both harmonic functions $u(\cdot)$ and $\Psi(\cdot,p_0)$ in $D\backslash B_r(p_0)$:
 \[\mathcal{R}_{\partial D}(u(\cdot),\Psi(\cdot,p_0)) = \mathcal{R}_{\partial B_r(p_0)}(u(\cdot),\Psi(\cdot,p_0)) = (1) - (2)\]
 \begin{align*}
 (2)&=\int_{\partial B_r(p_0)}(u_x\nu_x+u_y\nu_y)(-1)\frac{1}{2\pi}\frac{1}{r}\frac{x-x_0}{r}\,dy\\
 &= \int_0^{2\pi}(u_x(r,\theta)\cos\theta+u_y(r,\theta)\sin\theta)(-1)\frac{1}{2\pi}\frac{1}{r}\frac{r\cos\theta}{r}r\,d\theta \to -\frac{1}{2\pi}u_x(p_0)\pi,
 \end{align*}
 thanks to uniform convergence in $\theta$ for $r\to0$ of the integrand. And
 \begin{align*}
 (1)&=\int_{\partial B_r(p_0)}u(\Phi_{xx}\nu_x + \Phi_{xy}\nu_y)\,dy\\
 &= \int_0^{2\pi}u(r,\theta)\Big(\frac{1}{\pi r^2}\cos^2\theta\cos\theta - \frac{1}{2\pi r^2}\cos\theta + \frac{1}{\pi r^2}\cos\theta\sin\theta\sin\theta\Big)r\,d\theta\\
 &= \int_0^{2\pi}\frac{u(r,\theta)-u_0}{r}r\Big(\frac{1}{\pi r^2}\cos^2\theta\cos\theta - \frac{1}{2\pi r^2}\cos\theta + \frac{1}{\pi r^2}\cos\theta\sin\theta\sin\theta\Big)r\,d\theta\\
 & \to \int_0^{2\pi}(u_x(p_0)\cos\theta + u_y(p_0)\sin\theta)\Big(\frac{1}{\pi}\cos^2\theta\cos\theta - \frac{1}{2\pi}\cos\theta + \frac{1}{\pi}\cos\theta\sin\theta\sin\theta\Big)\,d\theta\\
 &= \frac{1}{\pi}u_x(p_0)\Big(\frac{3}{4}\pi-\frac{\pi}{2}+\frac{1}{4}\pi\Big) = \frac{1}{2}u_x(p_0),
 \end{align*}
 thanks to uniform convergence in $\theta$ for $r\to0$ of the integrand.
\end{proof}
% \begin{center}
%  \begin{tikzpicture}
% %   \draw [blue,dashed] (2,2) ellipse (4cm and 3cm);
%   \draw [dashed] (2,2) ellipse (3cm and 2cm);
%   \draw [dashed] (2,2) ellipse (1.5cm and 1cm);
%   \draw [thick] (2,2) circle (0.5cm);
% 
%   \node at (-1.5,1.8){$C$};
%   \node at (-0.5,1.8){$B$};
%   \node at (1,1.8){$\Omega$};
%   \node at (2,1.8){$D,k$};
% 
%   \draw [fill] (-1,2) circle [radius=1pt];
%   \draw [fill] (2,2) circle [radius=1pt];
%   \draw [densely dotted, thick] (2,2) circle (0.2cm);
%   \draw [densely dotted, thick] (-1,2) circle (0.2cm);
%   \node [black] at (-1,2.4){$x_0$};
%   \node [black] at (2,2.4){$x_1$};
% 
%   \end{tikzpicture}
% \end{center}


\begin{figure}
\begin{center}
 \begin{tikzpicture}
  \draw [densely dotted] (2,2) ellipse (4cm and 3cm);
  \draw (2,2) [dashed] ellipse (3cm and 2cm);
  \draw (2,2) [dashed] ellipse (2cm and 1.5cm);
  \draw [thick] (2,2) circle (0.8cm);

  \node at (-2.,1.5){$C$};
  \node at (-1.,1.5){$B$};
  \node at (0,1.8){$\Omega$};
  \node at (2,1){$D,k$};

  \draw [fill] (-1,2) circle [radius=1pt];
  \draw [fill] (1.2,2) circle [radius=1pt];
  \draw [fill] (2,2) circle [radius=1pt];
  \draw [thick, densely dotted] (1.2,2) circle (0.2cm);
  \draw [thick, densely dotted] (-1,2) circle (0.2cm);
  \draw [thick, densely dotted] (2,2) circle (0.2cm);
  \node [] at (-1,2.4){$x_0$};
  \node [] at (1,2.4){$x_1$};
  \node [] at (2,2.4){$x_1$};

  \end{tikzpicture}
\end{center}
\caption{Geometry of the domain of integration}
\end{figure}


\begin{proposition}[Reciprocity relations]
 \label{prop:reciprocity}
 Let $u$ indicate the fundamental solution $\Phi_D$ for the inclusion problem \eqref{eq:fundamental-D-in-dist} with constant impedance $k$ in $D$, and let the source $\delta_{x_0}$ move in the open $\mathbb{R}^2\backslash\overline{D}$, then there hold these reciprocity relations
 \begin{equation}
  u(x_0,x_1) = k\, u(x_1,x_0),\quad x_0\in \mathbb{R}^2\backslash\overline{D} \quad x_1\in D,
 \end{equation} 
 \begin{equation}
  u(x_0,x_1) = u(x_1,x_0),\quad x_0, x_1\in \mathbb{R}^2\backslash \overline{D}.
 \end{equation}
 Furthermore, for regular $\partial D$, there holds
 \begin{equation}
 \label{eq:reciprocity-boundary}
  u(x_0,x_1) = \frac{1+k}{2}u(x_1,x_0)\quad x_0\in \mathbb{R}^2\backslash \overline{D} \quad x_1\in \partial D.
 \end{equation}
 In general $u(x_1,\cdot)$ is harmonic in the second argument, for any $x_1$ fixed.
 \end{proposition}
\begin{proof}
 Let $C$ denote an exterior curve, and compute the Green's formula in $C \backslash B(x_0) \backslash \overline{D}$ applied to $u_0\coloneqq u(\cdot,x_0)$ and $u_1\coloneqq u(\cdot,x_1)$:
 \begin{align*}
 0 &= \mathcal{R}_{\partial C}(u_0,u_1)+\mathcal{R}_{-\partial B(x_0)}(u_0,u_1)+\mathcal{R}_{-\partial D}(u_0,u_1) \\
   &= \mathcal{R}_{\partial C}(u_0,u_1)+\mathcal{R}_{-\partial B(x_0)}(u_0,u_1) + k \cdot \mathcal{R}_{-\partial B(x_1)}(u_0,u_1)\\
   &= (a) + (b) + (c).
 \end{align*}
 Using asymptotic behaviors,
 \begin{equation*}
  (b) = \mathcal{R}_{-\partial B(x_0)}(u_0,u_1) = \mathcal{R}_{-\partial B(x_0)}(\frac{1}{2\pi}\frac{1}{| \log(\cdot - x_0) |},u_1(\cdot))\to 0 - u_1(x_0),
 \end{equation*}
 we let balls' radii in $(b)$ and $(c)$ go to zero
 \begin{equation*}
 0 = \int_{\partial C}(u(y,x_0)\partial_\nu u(y,x_1) - \partial_\nu u(y,x_0)u(y,x_1))\, dy - u_1(x_0) + k \cdot u_0(x_1),
 \end{equation*}
 while, the asymptotic approximation of $(a)$ in $\mathbb{R}^2$, letting radius of $C$ diverge, yields
 \begin{equation*}
  \int_{\partial C} u(y,x_0)\partial_\nu u(y,x_1) \, dy = O\Bigl(\frac{\log(|x|)}{|x|}\Bigr)\to 0\quad as \quad x\to \infty.
 \end{equation*}
 Instead, we only sketch the initial formulation  which proves \eqref{eq:reciprocity-boundary}, for $x_1\in\partial D$. Let denote  
 $\gamma := \partial D\backslash B(x_1)$, and two arcs $\beta^+ := \partial B(x_1) \cap (\mathbb{R}^2\backslash\overline{D})$ and $\beta^- := \partial B(x_1) \cap D$
 \begin{align*}
 0 &= \mathcal{R}_{\partial C}(u_0,u_1)+\mathcal{R}_{-\partial B(x_0)}(u_0,u_1)+\mathcal{R}_{- \gamma}(u_0,u_1)+\mathcal{R}_{- \beta^+}(u_0,u_1)\\
 &= \mathcal{R}_{\partial C}(u_0,u_1)+\mathcal{R}_{-\partial B(x_0)}(u_0,u_1)+k\cdot \mathcal{R}_{- \gamma}(u_0,u_1)+\mathcal{R}_{- \beta^+}(u_0,u_1)\\
 &= \mathcal{R}_{\partial C}(u_0,u_1)+\mathcal{R}_{-\partial B(x_0)}(u_0,u_1)+k\cdot \mathcal{R}_{- \beta^-}(u_0,u_1)+\mathcal{R}_{- \beta^+}(u_0,u_1).
 \end{align*}
 Now, it's sufficient to take the limits for infinitesimal balls, and let $C$ go to infinity.
\end{proof}

\chapter{Factorization Method}
\label{ch:factorization}
In this chapter we will review a third method to reconstruct inclusions in a conductor. Known as Factorization Method, 
this technique was introduced by Kirsch (see \cite{kirsch:factorization}) in the framework of inverse scattering theory and later developed by 
several authors in different contexts. We will focus mainly on the reconstruction of inclusions relating this method to 
the previous ones.
\section{Factorization}
The aim is to factorize the relative Neumann--to--Dirichlet map ${N_0} - {N_D}$, in the form
\begin{equation}
 {N_r}\coloneqq{N_0} - {N_D} = A^*TA,
\end{equation}
where $A,T$ are operators suitably chosen and $A^*$ is the adjoint operator of A. 
The choice of the operators is not unique, for instance it can be done as (see \cite{kirsch:book})
\begin{enumerate}
 \item $A:L^2_0(\partial \Omega) \to L^2(D;\,\mathbb{R}^2)$ defined as $Af = \nabla v|_D$ where $v = M_0f$ solves the variational formulation
 \begin{equation}
  \label{eq:def-A}
  \int_\Omega \nabla v\cdot \nabla \psi \, dx = \int_{\partial \Omega} fv\, ds\quad \forall\psi\in H^1_0(\Omega),
 \end{equation}
 \item $T:L^2(D;\,\mathbb{R}^2) \to L^2(D;\,\mathbb{R}^2)$ defined as $Tg = h(g - \nabla w)$ where $w\in H^1_0(\Omega)$ solves the variational formulation
 \begin{equation}
  \label{eq:def-T}
  \int_\Omega \gamma \nabla w\cdot \nabla \psi \, dx = \int_D hg\cdot\nabla\psi\, dx\quad \forall\psi\in H^1_0(\Omega).
 \end{equation}
\end{enumerate}
Throughout all the section we'll use the notation $v$ and $u$, as solutions of \eqref{eq:NtoD-laplace} and \eqref{eq:NtoD-inclusion}, respectively.
The difference $w = v - u$ solves the equation
\begin{equation}
 \int_\Omega(1+h)\nabla w\cdot\nabla\psi\, dx = \int_D h\nabla v \cdot \nabla \psi\, dx\quad \forall\psi\in H^1_0(\Omega),
\end{equation}
where $\gamma = 1 + h$.
We compose operators to simplify the expression of $TA$
\begin{equation}
 TAf = h (\nabla v - \nabla w) = h \nabla u.
\end{equation}
Actually, firstly given the definition of $A$, we accurately define $T$ such that it makes the factorization true.
We refer to \cite{kirsch:book} for a detailed proof of the next proposition.
\begin{theorem}[Factorization]
 Let $A$ and $T$ be defined by \eqref{eq:def-A} and \eqref{eq:def-T}. Then there holds the factorization
\begin{equation}
 {N_0} - {N_D} = A^*TA.
\end{equation}
\end{theorem}
The scheme below shows the general framework to choose the space $L^2(D;\,\mathbb{R}^2)$ and the operators.
\begin{center}
\begin{tikzpicture}
    % set up the nodes
    \node (n11) at (0,0) {$L^2_0(\partial\Omega)$};
    \node[right=of n11] (n12) {$L^2(D;\,\mathbb{R}^2)$};
    \node[below=of n12] (n22) {$L^2(D;\,\mathbb{R}^2)$};
    \node[below=of n11] (n21) {$L^2_0(\partial\Omega)$};
    \node (n112) at ([xshift=0.1]n11) {$ $};
    \node (n212) at ([xshift=0.1]n21) {$ $};
    % draw arrows and text between them
    \draw[->] (n11) to node [midway,right] {${N_r}$} (n21);
    \draw[->] (n11) to node [midway,above] {$A$} (n12);
    \draw[->] (n12) to node [midway,right] {$T$} (n22);
    \draw[->] (n22) to node [midway,above] {$A^*$} (n21);
%     \draw[->] (n21.south) [out=-60, in=-120]to node [midway,below] {$R_\alpha$} (n22.south);
%     \draw[->] (n21.west) [out=170, in=-170]to node [midway,left] {$\tilde{R}_\alpha$} (n11.west);
\end{tikzpicture}
\end{center}
In the following proposition we emphasize the benefits of such a factorization.
\begin{proposition}
The following properties of the operators hold
 \begin{enumerate}
  \item $A$ is compact,
  \item $T$ is self-adjoint and coercive
  \begin{equation}
   (\phi,T\phi)\geq c\|\phi\|^2\quad \forall \phi \in L^2(D;\,\mathbb{R}^2),
  \end{equation}
  where $c = h_0\Big(1-h_0/(1+h_0)\Big)>0$,
  \item as a consequence of previous items, ${N_0} - {N_D}: L^2_0(\partial \Omega) \to L^2_0(\partial \Omega)$ is self-adjoint, nonnegative, and compact and
  \begin{equation}
   (f,A^*TAf)\geq c\|Af\|^2\geq 0\quad \forall f \in L^2_0(\partial \Omega).
  \end{equation}  
 \end{enumerate}
\end{proposition}
Actually we can strengthen conclusions for ${N_r} = {N_0} - {N_D}$.
\begin{proposition}
For the same operators, there hold
\begin{enumerate}
 \item $A$ is injective,
 \item as a consequence of point 1. ${N_0} -{N_D}$ is positive and
  \begin{equation}
   (f,A^*TAf)\geq c\|Af\|^2 > 0\quad \forall f \in L^2_0(\partial \Omega)\quad f\neq 0.
  \end{equation}
\end{enumerate}
\end{proposition}
\begin{proof}
It's sufficient to prove injectivity of operator $A$. We suppose that $Af=\nabla v_f = 0$ in $D$.
Since $v_f$ is harmonic in $\Omega$, all the derivatives $\nabla v_f$ are harmonic in $\Omega$.
By analytic extension, $\nabla v_f = 0$ in $\Omega$, entailing $v_f=0$, since $v_f\in H^1_0(\Omega)$.
\end{proof}

\section{Equivalent Characterization}
At this point, it's clear that the linear sampling method determines the support of $D$, according 
with approximation results in the image space. We recall a first result, common to the
scattering case, whose proof can be found in \cite{somersalo:preprint}.
\begin{proposition}
\label{prop:underestimated-range}
 Let $\psi_{0z}$ be defined by \ref{def:lsm-psi}. If $\psi_{0z}\in\mathcal{R}({N_0}-{N_D})$, then $z\in D$.
\end{proposition}
\begin{remark}
 The inverse of the Proposition \ref{prop:underestimated-range} doesn't hold. This means that the range $\mathcal{R}({N_0} - {N_D})$ underestimates the inclusion $D$.
\end{remark}
For this reason, one of the advantages of the factorization, is the following equivalent condition, which can be found in \cite{kirsch:book}, along with its proof.
\begin{theorem}
\label{theo:equivalence}
 Let Assumption \ref{assumption:connected} for inclusion $D$ hold, let $\psi_{0z}$ 
 be defined by \ref{def:lsm-psi}, the potential of a dipole with homogeneous 
 Neumann data on $\partial \Omega$ and let $A^*$ be the adjoint of the operator $A$ defined by \eqref{eq:def-A}.
 Then there holds the equivalence 
 \begin{equation}
  z \in D \,\Longleftrightarrow \,\psi_{0z} \in \mathcal{R}(A^*).
 \end{equation}
\end{theorem}
This strong result refers to operator $A^*$, which cannot be defined in our inverse problem, since 
the domain $D$ is unknown. Consequently, it would be desirable to test the equivalence in terms of a different operator, which preserves properties of $A^*$. To do this, we follow the approach in \cite{kirsch:book}, passing through this analytic intermediate result.
\begin{theorem}[Range Characterization]
\label{theo:range-characterization}
 Let $X,Y$ be Hilbert spaces, and 
 \begin{enumerate}
  \item $A:X\to Y$, $T:Y\to Y, K=A^*TA:X\to X$ be linear and bounded,
  \item $T$ be self-adjoint and coercive,
 \end{enumerate}
 then for any $\psi \in X$, $\psi\neq 0$
 \begin{equation}
 \psi \in \mathcal{R}(A^*) \Leftrightarrow \inf\Big\{(Kf,f)_X   : f\in X, (f,\psi)_X=1\Big\}>0.\\
 \end{equation}
\end{theorem}
Now, inspired  by the factorization structure, and multiplicity of the operator $A$, 
we construct a parallel factorization, which preserve the structure, without any intermediate space.
We take advantage of the fact that from any compact, self-adjoint and positive operator 
it is possible to compute the square root, starting from spectral decomposition.
\begin{align}
({N_0} - {N_D}) f &= \sum_{j\in \mathbb{N}}^\infty \lambda_j(f,\psi_j)_{L^2(\partial\Omega)} \psi_j ,\\
({N_0} - {N_D})^{1/2} f &= \sum_{j\in \mathbb{N}}^\infty \sqrt{\lambda_j}(f,\psi_j)_{L^2(\partial\Omega)} \psi_j.
\end{align}
Furthermore, both the following factorizations hold
\begin{equation}
\label{eq:factorization-two}
 {N_0} - {N_D}=({N_0} - {N_D})^{1/2}I({N_0} - {N_D})^{1/2} = A^*TA.
\end{equation}
Then, there holds the following result, by immediate application of Theorem \ref{theo:range-characterization} to \eqref{eq:factorization-two}.
\begin{theorem}
 The range of two operators is the same, that is
 \begin{equation}
  \mathcal{R}(A^*) = \mathcal{R}(({N_0} - {N_D})^{1/2}),
 \end{equation}
so an equivalent criterion can be stated as
 \begin{equation}
  z \in D \,\Longleftrightarrow \,\psi_{0z} \in \mathcal{R}(({N_0} - {N_D})^{1/2}).
 \end{equation}
\end{theorem}
The great advantage is that now the square root operator can be theoretically computed by ${N_0} - {N_D}$, while $A^*$ stays unknown.
\begin{remark}
 We limit to observe the simple fact that
 \begin{equation}
  \mathcal{R}({N_r}) \subset \mathcal{R}({N_r}^{1/2}).
 \end{equation}
\end{remark}
\section{Range criterion}
\label{section:range-criterion}
We take advantage of the representation of ${N_r}:L^2_0(\partial \Omega)\to L^2_0(\partial \Omega)$ with the orthonormal eigensystem $\bigl\{(\lambda_j, \psi_j)\bigr\}_{j\in\mathbb{N}}$, or alternatively,
\begin{center}
the singular system for ${N_r}^{1/2}$: $\bigl\{(\sqrt{\lambda_j}, \psi_j, \psi_j)\bigr\}_{j\in\mathbb{N}}$.
\end{center}
From the application of the Picard's theorem, there follows the range criterion.
\begin{proposition}
 In the previous framework, there holds
 \begin{equation}
  z \in D \, \Longleftrightarrow \, \sum_{j \in \mathbb{N}}^{\infty}\frac{(\psi_{0z}, \psi_j)^2}{\lambda_j} < \infty,
 \end{equation}
 or equivalently
 \begin{equation}
  z \in D \, \Longleftrightarrow \, W(z):=\Bigg[\sum_{j \in \mathbb{N}}^{\infty}\frac{(\psi_{0z}, \psi_j)^2}{\lambda_j}\Bigg]^{-1} > 0.
 \end{equation}
Observe that $\chi(z):=\textup{sign}\,W(z)$ approximates the characteristic function of $D$.
\end{proposition}
Hanke and Br\"{u}hl suggested in \cite{hanke-bruhl:recent} a test to establish the convergence of the previous sum, with finitely many terms, after discretization. In most of geometries, the decay of singular values $\bigl\{\lambda_j\bigr\}_j$ is typically exponential, as it can be easily plotted. 
Let's assume an exponential behavior for the components $(\psi_{0z},\psi_j )^2$, parametrized as
\begin{align}
 \lambda_j &\sim a_j (r_j) ^j,  & \log\lambda_j &\sim c_j + j\log r_j,\label{eq:straightline-eig}\\
 (\psi_{0z}, \psi_j)^2 &\sim A_j(R_j)^j, & \log(\psi_{0z}, \psi_j)^2 &\sim C_j + j\log R_j\label{eq:straightline-data},
\end{align}
then the range criterion leads to comparing the slopes of the straight lines interpolating 
eigenvalues \eqref{eq:straightline-eig} and computed data \eqref{eq:straightline-data}
\begin{equation}
 z\in D \,\Longleftrightarrow\, \dfrac{R_j}{r_j} < 1 \,\Longleftrightarrow\, \log R_j < \log r_j.
\end{equation}

\chapter{Validation of the methods}
\label{ch:link}
This chapter is devoted to emphasize some features of the reconstruction methods we have analyzed 
up to now. We will first show what is the connection between the reciprocity gap method and the linear 
sampling method. We will then proceed by studying the existence of a converging sequence as predicted 
by the general Theorem \ref{prop:lsm-constructive} of the linear sampling method.
\section{Link between two methods}
We have seen that the reciprocity gap method is formulated as an integral equation 
of the form
\begin{equation}
 \mathcal{R}(u, v) = \mathcal{R}(u, \vec{\Psi}_z\cdot\vec{d})\quad \forall u \in \mathcal{U},
\end{equation}
whereas the linear sampling method deals with the following equation
\begin{equation}
\label{eq:eq-lsm-link}
 ({N_D} - {N_0})f = \psi_{0z} \quad \text{ on }\partial \Omega.
\end{equation}
The number of players suggest to compute the duality of \eqref{eq:eq-lsm-link}, with a generic 
${g \in \bigl(H^{1/2}_0(\partial \Omega)\bigr)^* = H^{\,-1/2}_0(\partial \Omega)}$, by self-adjoint properties (denoting $u,v$ solutions of 
\eqref{eq:NtoD-inclusion}), \eqref{eq:NtoD-laplace}, we have
\begin{align}
 \label{eq:link-duality-left}
 \langle({N_D} - {N_0})f,g\rangle & =  \langle f,{N_D} g\rangle - \langle {N_0} f,g\rangle \\
                                        & = \langle \partial_\nu v,u\rangle - \langle v,\partial_\nu u\rangle \\
                                        & = \mathcal{R}(u,v).
\end{align}
\begin{proposition}
 The \textit{reciprocity gap functional method} correspond to the weak formulation of the \textit{linear sampling method} with a modified right term. Consequently, provided the choice of $\psi_z$ as right side in \eqref{eq:eq-lsm-link}
 instead of $\psi_{0z}$, the two methods are equivalent.
\end{proposition}
\begin{proof} We prove the equivalence.
\begin{enumerate}
 \item The r.g. formulation can be obtained from the duality with a generic test function $g\in H^{\, -1/2}_0(\partial \Omega)$, with $\psi_{0z}$ substituted by $\psi_z$ defined in \ref{def:lsm-psi}, resulting in \eqref{eq:link-duality-left} and in
\begin{align}
 \langle \psi_z , g \rangle  & = \langle \vec{\Psi}(x,z)\cdot\vec{d} - m_z - {N_D}(\partial_\nu \vec{\Psi}(x,z) \cdot \vec{d}) , g \rangle \\
                             & = \langle \vec{\Psi}(x,z)\cdot\vec{d},\partial_\nu u\rangle - 0 - \langle\partial_\nu \vec{\Psi}(x,z) \cdot \vec{d},u\rangle.
\end{align}
 \item The l.s. formulation can be recovered from the weak one, thanks to density of $\{\partial_\nu u|_{\partial \Omega}\}=\{g\}$ in $L_0^2(\partial \Omega)$.
\qedhere
\end{enumerate}
\end{proof}
The approximation result for linear sampling method can be restated, exactly the same, as we could expect after approximation theorem for reciprocity gap method.
\begin{remark}
 The approximation result Theorem \ref{prop:lsm-constructive} holds for the modified case with $\psi_z$ as right term (instead of $\psi_{0z}$).
\end{remark}
\begin{proof}
 The proof can be obtained from Theorem \ref{prop:lsm-constructive} with some modifications. 
 Since $\psi_z$ is \emph{no more harmonic} in $\Omega$, in the ITP formulation, the correct choice for boundary data is $u_z = v_z + \psi_z$ and
 \begin{equation}
 \partial_\gamma u_z = \partial_\nu v_z + \partial_\nu\psi_z^+ \quad \textup{ on }\partial D,
 \end{equation}
 with derivative $\partial_\nu\psi_z^+|_{\partial D}$ from the exterior of $D$. Since $\partial_\nu\psi_z = 0$ on $\partial \Omega$, even in this case $\partial_\nu\mathcal{S}(\partial B, \omega^\epsilon_z) = \partial_\nu u^\epsilon_z = \partial_\nu v^\epsilon_z$ on $\partial \Omega$, 
 where
 \begin{equation}
   u^\epsilon_z\coloneqq\chi_Du_z + (1-\chi_D)(\psi_{z} + v^\epsilon_z),
 \end{equation}
  and after defining $w^\epsilon_z, r^\epsilon_z$ as before, the transmission conditions are
  \begin{align}
   [r^\epsilon_z]^+_- = [w^\epsilon_z]^+_- -[u^\epsilon_z]^+_- &=0 - (v^\epsilon_z - v_z), && \textup{ on }\partial D, \\
   [\partial_\gamma r^\epsilon_z]^+_- = [\partial_\gamma w^\epsilon_z]^+_- -[\partial_\gamma u^\epsilon_z]^+_-&= 0 - (\partial_\nu v^\epsilon_z - \partial_\nu v_z), && \textup{ on }\partial D, 
  \end{align}
  where $\partial_\nu\psi_z^+$ cancels itself. The same previous estimates conclude the proof.
\end{proof}


\section{Validation of the methods}
\label{section:validation}
The linear sampling method deals with the resolution of a linear equation of the first kind, namely
\begin{equation}
\label{eq:NtoD_firstkind}
 ({N_0} - {N_D}) f = \psi_{0z},\quad \textup{ on }\partial \Omega.
\end{equation}
The first great question is how regularization of the equation in $L^2_0(\partial \Omega)$
allows to construct a sequence converging in $L^2(D;\,\mathbb{R}^2)$, which exists 
as predicted by approximation Theorem \ref{prop:lsm-constructive}.
In \cite{arens:why} it's well explained the key role of the factorization 
of the relative Neumann--to--Dirichlet operator ${N_0} - {N_D}$
\begin{equation}
 {N_0} - {N_D} = A^*TA.
\end{equation}
We introduce the following notation for the intermediate space.
\begin{definition}
We define the closed subspace
\begin{equation}
 Z\coloneqq\bigl\{\phi\in L^2(D;\,\mathbb{R}^2):\divergence\phi=0 \textup{ and } \curl\phi=0\bigr\}
%  H_{\divergence}(D)\coloneqq\bigl\{\bm{w}\in L^2(D;\,\mathbb{R}^3):\divergence\bm{w} \in L^2(D),\, \curl\bm{w}=0 \bigr\}
\end{equation}
in the weak sense, equipped with the $L^2(D;\,\mathbb{R}^2)$ norm. Indeed, any sequence $\phi_n$ converging to $\phi$ in $L^2(D;\,\mathbb{R}^2)$, converges even in the distributional sense
\begin{equation}
 |\langle\phi-\phi_n, \psi\rangle|=\Bigl|\int_D(\phi-\phi_n)\psi\,dy\Bigr|\leq\|\phi - \phi_n\|_{L^2}\|\psi\|_{L^2}\, \forall\psi\in C^\infty_c(D;\,\mathbb{R}^2)
\end{equation}
and continuity of differential operators $L=\divergence$, $L=\curl$, with respect to distributional convergence, by uniqueness, implies $0=L\phi_n\to L\phi$.
\par 
Furthermore, we change the functional spaces of definition of previous operators $A:L^2_0(\partial \Omega)\to Z$ and $T:Z \to Z$. 
Note that both operators have well defined values in the image spaces.
\end{definition}
Let $v_f$ be an harmonic function with Neumann data $f$, and consider $Af=\nabla v|_{D}$ and $\phi\in Z$. Then, integrating by parts,
\begin{equation}
 \int_D\nabla v\cdot \phi\,dy=\int_{\partial D}v \phi\cdot\nu\,dy.
\end{equation}
By density result for $\mathcal{V}(\overline{\Omega})$ analogous to \ref{lemma:density-V-0}, $\phi\cdot \nu=0$ on $\partial D$ yields $\phi=0$ for any $\phi\in Z$.
This computation leads to the next density result.
\begin{lemma}
 The operator $A$ has dense image in $Z$. And by injectivity and self-adjointness, the operator $T$ has dense image too, that is
 \begin{equation}
  \forall\alpha\in Z: 0=(T\alpha,\beta)=(\alpha,T\beta)\,\Rightarrow \, T\beta = 0 \, \Rightarrow \beta=0.
 \end{equation}
 Furthermore $A^*$ is injective, by the fact that $\mathcal{N}(A^*)=\mathcal{R}(A)^\perp$.
\end{lemma}
We remind all properties of Neumann--to--Dirichlet operator in \eqref{eq:NtoD_firstkind}.
\begin{remark}
 The operator ${N_0} - {N_D}: L^2_0(\partial \Omega) \to L^2_0(\partial \Omega)$ is injective, with dense image, self-adjoint, compact and positive
 \begin{equation}
  (({N_D} - {N_0})f,f) = ( Af,TAf) \geq c\|Af\|^2_{L^2(D;\,\mathbb{R}^2)} > 0 \quad \forall f\in L^2_0(\partial \Omega) \quad f\neq0.
 \end{equation} 
\end{remark}
\begin{lemma}
 In the previous framework, let the operator $A^*$ be defined only on $Z$, then Theorem \ref{theo:equivalence} remains valid:
  \begin{equation}
  z \in D \,\Longleftrightarrow \,\psi_{0z} \in \mathcal{R}(A^*).
 \end{equation}
\end{lemma}
% \begin{center}
% \begin{tikzpicture}
%     % set up the nodes
%     \node (n11) at (0,0) {$L^2_0(\partial\Omega)$};
%     \node[right=of n11] (n12) {$L^2(D;\,\mathbb{R}^2)$};
%     \node[below=of n12] (n22) {$L^2(D;\,\mathbb{R}^2)$};
%     \node[below=of n11] (n21) {$L^2_0(\partial\Omega)$};
%     \node (n112) at ([xshift=0.1]n11) {$ $};
%     \node (n212) at ([xshift=0.1]n21) {$ $};
%     % draw arrows and text between them
%     \draw[->] (n11) to node [midway,right] {${N_r}$} (n21);
%     \draw[->] (n11) to node [midway,above] {$A$} (n12);
%     \draw[->] (n12) to node [midway,right] {$T$} (n22);
%     \draw[->] (n22) to node [midway,above] {$A^*$} (n21);
%     \draw[->] (n21.south) [out=-60, in=-120]to node [midway,below] {$R_\alpha$} (n22.south);
%     \draw[->] (n21.west) [out=170, in=-170]to node [midway,left] {$\tilde{R}_\alpha$} (n11.west);
% \end{tikzpicture}
% \end{center}
% 
% \begin{center}
% \begin{tikzpicture}
%     % set up the nodes
%     \node (n11) at (0,0) {$L^2_0(\partial\Omega)$};
%     \node[right=of n11] (n12) {$H^{-1/2}(\partial D)$};
%     \node[below=of n12] (n22) {$H^{+1/2}(\partial D)$};
%     \node[below=of n11] (n21) {$L^2_0(\partial\Omega)$};
%     \node (n112) at ([xshift=0.1]n11) {$ $};
%     \node (n212) at ([xshift=0.1]n21) {$ $};
%     % draw arrows and text between them
%     \draw[->] (n11) to node [midway,right] {${N_r}$} (n21);
%     \draw[->] (n11) to node [midway,above] {$A$} (n12);
%     \draw[->] (n12) to node [midway,right] {$T$} (n22);
%     \draw[->] (n22) to node [midway,above] {$A^*$} (n21);
%     \draw[->] (n21.south) [out=-60, in=-120]to node [midway,below] {$R_\alpha$} (n22.south);
%     \draw[->] (n21.west) [out=170, in=-170]to node [midway,left] {$\tilde{R}_\alpha$} (n11.west);
% \end{tikzpicture}
% \begin{gather}
%  \bigg(L^2_0(\partial\Omega), \lambda_j, g_j, h_j\bigg) \\
%  \bigg(H^{-1/2}(\partial D),\{\psi_j\}_{j\in\mathbb{N}}=\Big\{\dfrac{1}{\lambda_j}A^{**}h_j\Big\}_{j \in \mathbb{N}}\bigg)\\
%  \bigg(H^{+1/2}(\partial D),\{\phi_j\}_{j\in\mathbb{N}}=\Big\{\dfrac{1}{\lambda_j}TAg_j\Big\}_{j \in \mathbb{N}}\bigg)
% \end{gather}
% 
% \end{center}
By spectral theory applied on the self-adjoint and compact operator ${N_0}- {N_D}$, we obtain that there exists
an orthogonal eigensystem $\{(\lambda_j, \psi_j)\}_{j\in\mathbb{N}}$ for ${N_0} - {N_D}$,
with all $\lambda_j>0$, by injectivity.
We introduce the following sets of vectors, with the aim of using them as bases for the intermediate space $Z$.
\begin{definition}
Let $\lambda_j$ and $\psi_j$ be the eigenvalues and eigenvectors of ${N_r}$, we define
\begin{equation}
 \phi_j\coloneqq \frac{1}{\sqrt{\lambda_j}}A\psi_j, \quad \tilde{\phi}_j\coloneqq T\phi_j,\quad j\in\mathbb{N}. 
\end{equation}
\end{definition}
We remark that we have the following orthogonality relation
\begin{equation}
 (\phi_j, T\phi_k) =  ( \frac{1}{\sqrt{\lambda_j}} A\psi_j, \frac{1}{\sqrt{\lambda_k}} TA\psi_k) = \frac{1}{\sqrt{\lambda_j}\sqrt{\lambda_k}}( \psi_j, A^*TA\psi_k) = \delta_{jk}.
\end{equation}
\begin{remark}
 The sequences $\{\phi_j\}_{j\in\mathbb{N}}$ and $\{\tilde{\phi}_j\}_{j\in\mathbb{N}}$ are biorthogonal.
\end{remark}
Inspired by an analogous approach in \cite{kirsch:shape-1998} for the scattering problem, the aim is to represent functions of the intermediate space $Z$ through a Riesz's basis.
In general, this conclusion can be reached by several intermediate results. Assumptions for the structured formulation are very similar: the operator $I+K$ with $K$ compact, is replaced by a stronger coercive operator $T$.
\begin{proposition}
 Let $\{\phi_j\}_{j\in\mathbb{N}}$ be the sequence just defined and denote the new scalar product in $Z$:
 \begin{equation}
   ( \alpha, \beta )_T \coloneqq ( \alpha , T\beta),
 \end{equation}
 such that the norm induced $\|\cdot\|_T$ is equivalent to the original $\|\cdot\|_{L^2(D;\,\mathbb{R}^2)}$, by coercivity of $T$,
  \begin{equation}
   c\|\alpha\|_{L^2(D;\,\mathbb{R}^2)}^2\leq \|\alpha\|_T^2 \leq \|T\|\|\alpha\|_{L^2(D;\,\mathbb{R}^2)}^2\quad \forall \alpha\in Z.
  \end{equation}
 Then the sequence is a complete orthonormal set in $Z$, and by Parseval's theorem, it's a so called Riesz's basis for $Z$ with respect to the $L^2(D;\,\mathbb{R}^2)$ convergence, namely both conditions are satisfied
 \begin{align}
 &\{\lambda_j\}_{j \in \mathbb{N}} \subset \ell^2 \,\Leftrightarrow \,\alpha \in Z:\,\alpha = \sum_{j \in \mathbb{N}}\lambda_j \phi_j, \\
 & \exists c>0, \forall \alpha \in Z: \quad \frac{1}{c}\|\alpha\|^2 \leq \sum_{j\in\mathbb{N}}^\infty|\lambda_j|^2  \leq c \|\alpha\|^2,
 \end{align}
 and the following decompositions hold
 \begin{align}
  & \alpha = \sum_{j \in \mathbb{N}}(\alpha,\phi_j)_T \phi_j,\\
  & \alpha = \sum_{j \in \mathbb{N}}(\alpha,\phi_j) T\phi_j. 
 \end{align}
\end{proposition}
% \begin{proof}
% We split the proof in several steps:
% \begin{enumerate}
%  \item the sequence $\{\phi_j\}$ is bounded. Supposing the contrary, we could set $\hat{\phi}_j = \phi_j / \|\phi_j\|$
%   \begin{align}
%     & \langle\hat{\phi}_j, T\hat{\phi}_j\rangle = \frac{1}{\|\phi_j\|^2}\to0 \\ 
%     & \langle\hat{\phi}_j, T\hat{\phi}_j\rangle \geq c \|\hat{\phi}_j\|^2 = c
%   \end{align}
%  \item we define a new scalar product in $L^2(D;\,\mathbb{R}^2)$:
%   \begin{equation}
%    \langle \alpha, \beta \rangle_T := \langle \alpha , T\beta\rangle   
%   \end{equation}
%   and we observe that
%   \begin{enumerate}
%    \item the norm induced $\|\cdot\|_T$ is equivalent to the original $\|\cdot\|_{L^2(D;\,\mathbb{R}^2)}$, thanks to coercivity of $T$, 
%      \begin{equation}
%       \forall \alpha \in \mathcal{R}(A):\quad c\|\alpha\|_{L^2(D;\,\mathbb{R}^2)}^2\leq \|\alpha\|_T^2 \leq \|T\|\|\alpha\|_{L^2(D;\,\mathbb{R}^2)}^2
%      \end{equation}
%    \item the set $\{\phi_j\}_{j \in \mathbb{N}}$ is an orthonormal set with respect to the new scalar product $\langle\cdot,\cdot\rangle_T$, it's dense in $\mathcal{R}(A)$, and thanks to Parseval theorem the representation holds
%      \begin{equation}
%       \{\lambda_j\}_{j \in \mathbb{N}} \subset \ell^2 \quad \Leftrightarrow \quad \alpha = \alpha_0 + \sum_{j \in \mathbb{N}}\lambda_j\phi_j\, \text{for some $\alpha_0 \in \mathcal{R}(A)^\perp$}
%      \end{equation}
%      with $\lambda_j = \langle\alpha,\phi_j\rangle_T$, and there exist some constant $c$
%      \begin{equation}
%       \forall \alpha \in \mathcal{R}(A):\quad \frac{1}{c}\|\alpha\|_T^2 \leq \|\alpha\|^2 \leq c \|\alpha\|_T^2
%      \end{equation}
%   \end{enumerate}
% \end{enumerate} 
% \end{proof}
The general purpose is to construct a regularization scheme  $R_\alpha$ from the image space $L^2_0(\partial\Omega)$ to the intermediate space $Z$, whenever there is given a regularization $\tilde{R}_\alpha$ for the relative Neumann--to--Dirichlet operator ${N_0}-{N_D}$, as represented graphically. Indeed the range $\mathcal{R}(A^*)$ approximates data for source $z\in D$ sharper than the corresponding $\mathcal{R}({N_0} -{N_D})$.
Further notions about regularization theory can be found in Chapter \ref{ch:implementation}.
\begin{center}
\begin{tikzpicture}
 \node at (0,0) {$ L^2_0(\partial \Omega) \xrightarrow{A} Z \xrightarrow{T} Z\xrightarrow{A^*} L^2_0(\partial\Omega)$};
%  \node[label=below:$x_1$]  (x1) at (-5,0)  {$\bullet$};
%  \node[label=above:$x_0$]  (x0) at (5,0)  {$\bullet$};  
 \node (x1) at (1.8, 0.1) {$ $};
 \node (x0) at (-1.8, 0.1) {$ $};  
 \node (x1_2) at (1.8, -0.2) {$ $};
 \node (x0_2) at (0.5, -0.2) {$ $};  
%  \node (x1) at (3.5, 0.1) {$ $};
%  \node (x0) at (-3.5, 0.1) {$ $};  
%  \node (x1_2) at (3.5, -0.2) {$ $};
%  \node (x0_2) at (1, -0.2) {$ $};  
 
%  \draw[->] ($(R.east)+(20pt,0)$)  to [out=0,in=140] node[right,midway]{$F(1,t_2)$}(x1);
 \draw[->] (x1) to [out=130,in=50] node[above,midway]{$\tilde{R}_\alpha$}(x0);
 \draw[->] (x1_2) to [out=-130,in=-50] node[below,midway]{$R_\alpha$}(x0_2);
\end{tikzpicture}
\end{center}
We try to express the generic vector, resulting from the regularization, in terms of an appropriate Riesz's basis of $Z$:
\begin{align}
  R_\alpha A^*\phi :=& TA\tilde{R}_\alpha A^*\Big(\sum_{j=1}^\infty(\phi,\phi_j)T\phi_j\Big) \\
  =& TA\tilde{R}_\alpha A^*\Big(\sum_{j=1}^\infty(\phi,\phi_j)\frac{1}{\sqrt{\lambda_j}}TA\psi_j\Big) \\
  =& TA\tilde{R}_\alpha \Big(\sum_{j=1}^\infty(\phi,\phi_j)\sqrt{\lambda_j}\psi_j\Big) \\
  =& TA\Big(\sum_{j=1}^\infty\frac{q(\alpha,\lambda_j)}{\sqrt{\lambda_j}}(\phi,\phi_j)\psi_j\Big) \\
  =&\sum_{j=1}^\infty q(\alpha,\lambda_j)(\phi,\phi_j)T\phi_j.
\end{align}
% \begin{align}
%   R_\alpha A^*T\phi :=& A\tilde{R}_\alpha A^*T\Big(\sum_{j=1}^\infty(\phi,\phi_j)_T\phi_j\Big) \\
%   =& A\tilde{R}_\alpha A^*T\Big(\sum_{j=1}^\infty(\phi,\phi_j)_T\frac{1}{\sqrt{\lambda_j}}A\psi_j\Big) \\
%   =& A\tilde{R}_\alpha \Big(\sum_{j=1}^\infty(\phi,\phi_j)_T\sqrt{\lambda_j}\psi_j\Big) \\
%   =& A\Big(\sum_{j=1}^\infty\frac{q(\alpha,\lambda_j)}{\sqrt{\lambda_j}}(\phi,\phi_j)_T\psi_j\Big) \\
%   =&\sum_{j=1}^\infty q(\alpha,\lambda_j)(\phi,\phi_j)_T\phi_j
% \end{align}
The rest of computations is unchanged, and depends only on the general scheme. It can be found in \cite{arens:why} and aims to prove the regularization's definition:
\begin{equation}
 \|\phi - R_\alpha A^*\phi\|\to 0 \quad \textup{ for }\alpha\to 0.
\end{equation}
\begin{theorem}
 Suppose $q$ is a regularization filter for ${N_r} = {N_0}- {N_D}$, which defines the following regularization method $\tilde{R}_\alpha : L^2_0(\partial \Omega) \to L^2_0(\partial\Omega)$ for ${N_r}$
 \begin{equation}
  \tilde{R}_\alpha g := \sum_{j=1}^\infty\frac{q(\alpha,\lambda_j)}{\lambda_j}(g,\psi_j)\psi_j,
 \end{equation}
 then $R_\alpha : L^2_0(\partial\Omega) \to Z$  given by $R_\alpha:=TA\tilde{R}_\alpha$ is a regularization method for $A^*$.
\end{theorem}
We recall the binary criterion
\begin{equation}
 z\in D \,\Longleftrightarrow \, \psi_{0z}\in\mathcal{R}({N_r}^{1/2})\, \Longleftarrow \,\psi_{0z}\in\mathcal{R}({N_r}).
\end{equation}

\begin{corollary}
 Let $\tilde{R}_\alpha$ and $R_\alpha$ regularizations for some admissible strategy $\alpha_n\to 0$, defined previously and set
 \begin{equation}
  f_z^{\alpha_n}:=\tilde{R}_{\alpha_n}\psi_{0z},\quad \phi_z^{\alpha_n}:=R_{\alpha_n}\psi_{0z},\quad\textup{ for }\alpha_n \to 0.
 \end{equation}
 In addition, there holds the direct relation
 \begin{equation}
  \phi_z^{\alpha_n} = TAf_z^{\alpha_n}.
 \end{equation}
Then
\begin{enumerate}
%  \item if $z\in D$, then $\phi_z^{\alpha_n}$ is a converging sequence, and $f_z^{\alpha_n}$ cannot diverge, it's bounded
 \item if $z\notin D$, $A^*\phi_z^{\alpha_n} = {N_r}f_z^{\alpha_n}$ is an 
 approximating sequence, and by Theorem \ref{prop:lsm-counterpart} we have $\|\phi_z^{\alpha_n}\|\to\infty$. Furthermore boundedness of $TA$ implies $\|f_z^{\alpha_n}\|\to\infty$;
 \item if $z \in D$, $\phi_z^{\alpha_n}\to \phi$ for some $\phi\in Z$, such that $A^*\phi = \psi_{0z}$. If the corresponding $f_z^{\alpha_n}$ would be bounded, by compactness with respect of weak convergence in $L^2_0(\partial\Omega)$, and by compactness of $A$, up to renaming some subsequence,
 \begin{equation}
  f_z^{\alpha_n}\rightharpoonup f \,\Rightarrow \phi_z^{\alpha_n} \to TA f = \phi.
 \end{equation}
Consequently, as necessary condition, $\psi_{0z}=A^*TAf$ and $\psi_{0z}\in\mathcal{R}({N_r})$, which is not always verified by all points $z\in D$.
This last observation implies boundedness of the sequence $f_z^{\alpha_n}$ only for $\psi_{0z}\in\mathcal{R}({N_r})$.
\end{enumerate}
\end{corollary}
\chapter{Numerical Implementation}
\label{ch:implementation}
In the reconstruction methods we have seen, we always end up with a linear integral equation of the 
first kind (see \eqref{eq:lsm-approximate-lin-eq} and \eqref{eq:rg-approximate-eq}) of the form
\begin{equation}
 Kx = y,\label{eq:first-to-inv}
\end{equation}
where $K$ is a compact operator.
Typically these equations are ill-posed in the sense of Hadamard (see Definition \ref{def:well-posed-lineareq} below) 
and this represents a big difficulty for the numerical reconstruction. It is necessary therefore a regularization 
theory. In this chapter we will show a possible strategy to prevent this difficulty and provide some numerical examples.
\begin{definition}
\label{def:well-posed-lineareq}
 Let $K:X\to Y$ be a linear bounded operator. The equation $Kx=y$ is \emph{well-posed}, in the sense that
 \begin{enumerate}
  \item there exists a solution (\emph{existence});
  \item there is at most one solution (\emph{uniqueness});
  \item the solution $x$ depends continuously on data $y$ (\emph{stability}).
 \end{enumerate}
In practice, these properties correspond to surjectivity, injectivity and existence 
of a bounded inverse operator of $K$.
\end{definition}
\begin{proposition}
\label{prop:ill-posed}
 Let $K:X\to Y$ be a linear compact operator between two Banach spaces (compactness with linearity implies continuity). Then 
 the equation $Kx=y$ is ill-posed if $X$ is of infinite dimension.
\end{proposition}
\begin{proof}
 Assuming the existence of a bounded inverse $K^{-1}$, then the bounded unit ball $B_1(0)\subset X$ would be mapped to 
 a compact $K(B_1(0))\subset Y$ and to a compact $K^{-1}K(B_1(0))=B_1(0)$ coincident with itself, yielding to a contradiction if $X$ is not of finite dimension.
\end{proof}     
\begin{remark}
 Since we are dealing with an approximate equation $Kx=y$, it's not guaranteed that $y\in \mathcal{R}(K)$. 
 Then we will limit to observe the behavior of the approximating sequence $x^{\alpha_n}$, computed from the regularization.
 Consequently
 \begin{enumerate}
  \item if the equation $Kx=y$ has a (unique) solution, then $x^{\alpha_n}\to x$,
  \item if the equation $Kx=y$ is not solvable for some $y$, then $x^{\alpha_n}\to \infty$ in $X$.
 \end{enumerate}
\end{remark}
In the last part of this chapter, we'll describe the steps followed in the code, and we'll report some error estimates.
\section{Introduction to Inverse Problems}
In this section, we sketch main notions of the inverse formulation of a given problem. All results 
can be found in \cite{kirsch:book}.
\begin{definition}
 Let $X,Y$ be Banach spaces, $K:X\to Y$ a linear and bounded operator, $X_1\subset X$ a subspace with a stronger norm, that is
 \begin{equation}
  \exists \, c>0:\quad \|x\|\leq c\|x\|_1\quad\forall x\in X_1.
 \end{equation}
 We define $\mathcal{F}(\delta, E, \|\cdot\|_1)$ the \emph{worst-case error} for an error $\delta$ in the data and a priori information $\|x\|_1\leq E$ as
 \begin{equation}
  \mathcal{F}(\delta, E, \|\cdot\|_1):= \sup\Big\{\|x\|:x\in X_1, \|x\|_1 \leq E, \|Kx\|\leq\delta\Big\}.
 \end{equation}
\end{definition}
Some a priori information on regularity of solutions can be used to obtain sharper convergence estimates of the worst-case error. 
In this context, the roles of $\mathcal{R}(K^*)$ and $\mathcal{R}({K^*K)}$ are played by spaces of smooth functions with graph norm as stronger norm.
\begin{theorem}
 In the previous framework,
 \begin{enumerate}
  \item choose $X_1=\mathcal{R}(K^*)$ with $\|x\|_1=\|(K^*)^{-1}x\|_Y$, then
  \begin{equation}
   \mathcal{F}(\delta, E, \|\cdot\|_1)\leq \sqrt{\delta E},
  \end{equation}
  furthermore, for every $E>0$ there exists a sequence $\delta_n\to 0$ such that $\mathcal{F}(\delta_n, E, \|\cdot\|_1) = \sqrt{\delta_n E}$, that is, the estimate is asymptotically sharp;
  \item choose $X_1=\mathcal{R}(K^*K)$ with $\|x\|_1=\|(K^*K)^{-1}x\|_X$, then
  \begin{equation}
   \mathcal{F}(\delta, E, \|\cdot\|_1)\leq \delta^{2/3} E^{1/3},
  \end{equation}
  furthermore, for every $E>0$ there exists a sequence $\delta_n\to 0$ such that $\mathcal{F}(\delta_n, E, \|\cdot\|_1) = \delta_n^{2/3} E^{1/3}$.
 \end{enumerate}
\end{theorem}
In general we attempt to solve the perturbed equation
\begin{equation}
 Kx^\delta = y^\delta,
\end{equation}
where it's not guaranteed that $y^\delta$ belongs to the range $\mathcal{R}(K)$.
Then we can hope that the error bound for $x^\delta$ is not much worse than the 
worst-case error $\mathcal{F}$
% An approximate solution $x^\alpha$, for a fixed error level $\delta$ and a priori information $E$, computed with a regularization method dependent on a parameter $\alpha$, has a generic error
\begin{equation}
 \|x^\delta -x\| \leq \mathcal{E}(\delta, E, \|\cdot\|_1), \quad \mathcal{F}(\delta, E, \|\cdot\|_1)\leq\mathcal{E}(\delta, E, \|\cdot\|_1).
\end{equation}
Since $\mathcal{F}$ is the best we can obtain, we can not improve the worst-case error (the error of the worst approximating sequence).
\begin{definition}
A regularization method is \emph{asymptotically optimal} if 
\begin{equation}
 \|x^\delta - x\|_X \leq c\,\mathcal{F}(\delta, E, \|\cdot\|_1).
\end{equation}
\end{definition}
\section{Regularization Theory}
For simplicity, given a linear and bounded operator $K:X\to Y$ between two Banach spaces, we will assume that
\begin{center}
 $K$ is injective, with dense range.
\end{center}
This is not restrictive, since it's always possible the substitution with the quotient space $X/ \mathcal{N}(K)$.
Therefore regularization of the equation $Kx=y$ for $y\in\mathcal{R}(K)$ consists in constructing a linear bounded operator $R_\alpha$ which approximates the linear unbounded operator $K^{-1}$.
\begin{definition}
 A \emph{regularization strategy} is a family of linear and bounded operators $R_\alpha : Y \to X$  for $\alpha> 0$ such that
 \begin{equation}
  \lim_{\alpha\to 0}R_\alpha Kx = x\quad \forall x \in X.
 \end{equation}
\end{definition}
\begin{definition}
\label{def:admissibility-reg-strategy}
 A regularization strategy is called \emph{admissible} if there is a function $\alpha(\delta)$ such that for $\delta \to 0$ there hold
 \begin{equation}
 \left\{
 \begin{aligned}
  &\alpha(\delta) \to 0, \\
  &\forall x \in X: \,\sup\bigl\{\bigl\|R_{\alpha(\delta)} y^\delta - x\bigr\|:y^\delta \in Y, \|Kx - y^\delta\|\leq\delta\bigr\} \to 0.
 \end{aligned}
 \right.
 \end{equation}
\end{definition}
In the sequel we'll denote $x^{\alpha}\coloneqq R_\alpha y$ and 
$x^{\alpha,\delta}=x^{\alpha(\delta)}\coloneqq R_\alpha y^\delta$ respectively the solutions of the regularized equation with unperturbed and perturbed data.  
\begin{remark}
The fundamental error estimate for any regularized solution is
\begin{align}
\label{eq:fundamental-error-estimate}
 \|x^{\alpha, \delta} - x\| &\leq \|R_\alpha y^\delta - R_\alpha y\| + \|R_\alpha y - x\| \\
                            &\leq \|R_\alpha\| \|y^\delta - y\| + \|R_\alpha Kx - x\|.
\end{align}
\end{remark}
The above estimate represents the decomposition of the approximation error, for a fixed error 
level $\delta$ in the data $\|y^\delta - y\|\leq \delta$. By the ill-posed nature of the problem, the norm 
$\|R_\alpha\|$ diverges as $\alpha\to 0$, while the regularization implies a converging regularized 
solution $x^{\alpha} = R_\alpha y$ to $x=K^{-1}y$, equivalent to $\|R_\alpha Kx -x\|\to 0$, as $\alpha\to0$.
Hence, \emph{we have to accept a compromise for the choice of the parameter $\alpha$, between 
the accuracy $\|R_\alpha Kx -x\|$ and the stability $\|R_\alpha\|$}, and we have to elaborate a 
strategy $\alpha(\delta)$ which guarantees convergence of the error $\|x^{\alpha,\delta} - x\|$.
\par
\begin{figure}[]
\begin{center}
\begin{tikzpicture}
  \begin{axis}[
  xmin=0,
  xmax=4,
  ymin=0,
  ymax=20,
  xticklabels={},
  yticklabels={},
  xlabel=$\alpha$,
  ylabel=error,
  ylabel style={rotate=-90}]

  \addplot[domain=0.1:4, samples=300, thick, densely dotted] {2/x};
  \addplot[domain=0.001:4, samples=300, thick, densely dotted] {2*x};
  \addplot[domain=0.1:4, samples=300, thick] {2/x + 2*x};
%   \addplot[mark=*] coordinates {(1, 0)};
  \end{axis}
  \node at (1.8,-0.2) {$\alpha^*$};
  \node at (7.5, 0.2) {$\delta\|R_\alpha\|$};
  \node at (8, 2.2) {$\|R_\alpha K x-x\|$};
\end{tikzpicture}
\end{center}
\caption{Behavior of the total error}
\end{figure}
To construct an admissible regularization strategy, it's convenient to begin from the 
singular system $\{(\mu_j, x_j, y_j)\}_{j\in\mathbb{N}}$ of a linear and compact operator, 
whose details are stated by the Picard's theorem.
\begin{theorem}
\label{theo:regularization-filter}
 Let $K:X\to Y$ be a linear and compact operator with singular system $\{(\mu_j, x_j, y_j)\}_{j\in\mathbb{N}}$ and
 $q:(0, \infty)\times(0, \|K\|]\to \mathbb{R}$
 be a function called \emph{regularizing filter} such that
 \begin{enumerate}
  \item $|q(\alpha,\mu)|\leq 1$ for values in its domain;
  \item for every $\alpha$ there exists $c(\alpha)$ such that $ |q(\alpha, \mu)| \leq c(\alpha)\mu$ for all $\mu$;
  \item[3a.] for every $\mu$ the limit $ \lim_{\alpha\to0}q(\alpha,\mu) = 1$.
 \end{enumerate}
 We define the operator $R_\alpha:Y\to X$ as
 \begin{equation}
  R_\alpha y:=\sum_{j=1}^\infty \dfrac{q(\alpha,\mu_j)}{\mu_j}(y, y_j)x_j,
 \end{equation}
 then
 \begin{enumerate}
  \item $R_\alpha$ is a regularization strategy with $\|R_\alpha\|\leq c(\alpha)$;
  \item $R_\alpha$ is an admissible strategy for any choice of $\alpha(\delta)$, such that for $\delta\to 0$ there hold
  \begin{equation}
   \left\{
   \begin{aligned}
    \alpha(\delta) \to 0,\\
    \delta \cdot c(\alpha(\delta)) \to 0.
   \end{aligned}
   \right.
  \end{equation}
 \end{enumerate}
\end{theorem}
\begin{theorem}
 Under stronger assumptions on convergence, it's possible to obtain estimates for the regularization error.
 Assume (1) and (2) of the previous theorem, and let (3a) be replaced by (3b) or (3c):
 \begin{enumerate}
  \item[3b.] if $x\in\mathcal{R}(K^*)$ and exists $c_1>0$ such that $|q(\alpha,\mu) - 1|\leq c_1\dfrac{\sqrt{\alpha}}{\mu}$
  then
  \begin{equation}
   \|R_\alpha Kx - x\|\leq c_1\sqrt{\alpha}\|z\|,\quad \textup{ where }x=K^*z,
  \end{equation}
  \item[3c.] if $x\in\mathcal{R}(K^*K)$ and exists $c_2>0$ such that $|q(\alpha,\mu) - 1|\leq c_2\dfrac{\alpha}{\mu^2}$
  then
  \begin{equation}
   \|R_\alpha Kx - x\|\leq c_2\,\alpha\|z\|,\quad \textup{ where }x=K^*Kz.
  \end{equation}
 \end{enumerate}
\end{theorem}
\section{Tikhonov Regularization}
Let us introduce the following functional.
\begin{definition}
 Let $K:X\to Y$ be a linear bounded operator, we define the \emph{Tikhonov functional} $J_\alpha:X\to \mathbb{R}$ as
 \begin{equation}
  J_\alpha(x)\coloneqq\|Kx - y\|^2 + \alpha\|x\|^2\quad x\in X.\label{eq:def-tikhonov-func}
 \end{equation}
 We can interpret the minimization of $J_\alpha$, as the minimization of the residual $\|Kx^{\alpha} - y\|$ penalized by the norm of the solution $\|x^\alpha\|$.
\end{definition}
\begin{theorem}
 Let $K:X\to Y$ be a linear bounded operator between Hilbert spaces and $\alpha>0$. Then the Tikhonov functional $J_\alpha$ 
 has a unique minimum $x^\alpha\in X$. Moreover this minimum $x^\alpha$ is the unique solution of the \emph{normal equation}
 \begin{equation}
  \alpha x^\alpha + K^*Kx^\alpha = K^*y.\label{eq:normal-equation}
 \end{equation}
\end{theorem}
This is a classical result in Optimization Theory. It's sufficient to apply Direct Method of calculus of variations
to the bilinear coercive form $J_\alpha$.  
Necessary equation \eqref{eq:normal-equation}, which in general provides a candidate, actually is solved by the minimizer.
\begin{remark}
 The Tikhonov regularization $R_\alpha\coloneqq (\alpha I + K^*K)^{-1}K^*$ is equivalent 
 to the regularization constructed in Theorem \ref{theo:regularization-filter} with filter 
 $q(\alpha,\mu) = \mu^2/(\alpha + \mu^2)$.
\end{remark}
Details of the proof are contained in \cite{kirsch:book}.
The choice of $\alpha$ is usually made \emph{a priori}, before the computation of $x^\alpha$. In the next section 
we'll present a criterion such that it will be made an \emph{a posteriori} choice of $\alpha$, based on the residual $Kx^\alpha - y$, which leads to better approximations.
\section{Discrepancy Principle of Morozov}
The Tikhonov regularization for the equation with perturbed data $y^\delta$ yields to solve
\begin{equation}
\label{eq:tikh-equation-2}
 \alpha x^{\alpha, \delta} + K^*Kx^{\alpha, \delta} = K^*y^\delta.
\end{equation}
A possible approach would be to establish the optimal regularization parameter $\alpha$ for the fixed error level $\delta$. 
Instead, our aim is to construct a full strategy $\alpha(\delta)$ which guarantees the diminishing 
of the error. 
\par
The most used criterion is the so-called Morozov discrepancy principle. 
It's \emph{a posteriori} criterion, based on the residual $Kx^{\alpha,\delta} - y^\delta$. 
It fixes an upper bound proportional to $\delta$ for the residual, avoiding to require excessively small values 
of $\alpha$, which would carry on only further instability. 
It consists in computing $\alpha$ which satisfies
\begin{equation}
\label{eq:discrepancy-zero}
 \|Kx^{\alpha, \delta} - y ^\delta \|= \delta.
\end{equation}
A variant of this criterion, according to \cite{kirsch:shape-1998}, fixes the normalized residual proportional to $\delta$ and the computation of $\alpha$ consists in
\begin{equation}
\label{eq:discrepancy-relative-zero}
 \|Kx^{\alpha, \delta} - y ^\delta \|= \delta\|x^{\alpha,\delta}\|.
\end{equation}
This expression is much more similar to the Tikhonov functional $J_\alpha$.
Indeed it distinguishes much better different values of $\alpha$, according to the diverging quantity $\|x^{\alpha,\delta}\|$.
\begin{remark}
 The error parameter $\delta$ is chosen such that $0<\delta<\|y^\delta\|$, in order to avoid the trivial approximating solution $x^{\alpha,\delta}= 0$.
\end{remark}
We introduce the discrepancy function to reformulate Morozov principle.
\begin{definition}
 We denote by $\Delta(\alpha)$ the \emph{discrepancy} function and its variants. The mostly used 
 are the classical and the normalized discrepancy:
 \begin{align}
  \Delta(\alpha)&\coloneqq\|Kx^{\alpha,\delta} - y^\delta\| - \delta, \label{eq:def-disc}\\
  \Delta_N(\alpha)&\coloneqq\|Kx^{\alpha,\delta} - y^\delta\| - \delta\|x^{\alpha,\delta}\|.\label{eq:def-disc-N}
 \end{align}
\end{definition}
In the next proposition, we state the main properties of the discrepancy function.
\begin{proposition}
\label{prop:properties-disc}
 Let $x^{\alpha,\delta}$ be the solution of \eqref{eq:tikh-equation-2}, then 
 it depends continuously from $y^\delta$ and $\alpha$. Furthermore
 \begin{enumerate}
  \item the map $\alpha\mapsto \|x^{\alpha, \delta}\|$ is nonincreasing
  \begin{equation}
   \lim_{\alpha\to\infty} x^{\alpha, \delta} = 0,
  \end{equation}
  \item the map $\alpha\mapsto \|Kx^{\alpha, \delta} - y^\delta\|$ is nondecreasing
  \begin{align}
   \lim_{\alpha\to0} Kx^{\alpha, \delta} = y^\delta \Rightarrow &\lim_{\alpha\to0}\|Kx^{\alpha, \delta} - y^\delta\| = 0,\\
   &\lim_{\alpha\to\infty}\|Kx^{\alpha, \delta} - y^\delta\| = \|y^\delta\|>\delta.
  \end{align}
 \end{enumerate}
\end{proposition}
Therefore the determination of $\alpha(\delta)$ is equivalent to the computation 
of the unique zero of the function $\Delta(\alpha)$.
\begin{proposition}
\label{prop:strategy-disc}
 By previous Proposition \ref{prop:properties-disc}, let $\delta$ be fixed, then there 
 exists unique zero $\alpha^*(\delta)$ of the discrepancy function, 
 such that $\Delta\bigl(\alpha^*\bigr)=0$. The same is still true for $\Delta_N(\alpha)$ 
 (see \cite{kirsch:shape-1998}).
 Therefore, let $\delta$ be fixed, then there exists a unique 
 couple $(\alpha(\delta), x^{\alpha(\delta)})$ such that
 \begin{equation}
  \left\{
  \begin{split}
   & \alpha(\delta) x^{\alpha(\delta)} + K^*Kx^{\alpha(\delta)} = K^*y^\delta, \\
   & \Delta(\alpha(\delta))=0, \quad\textup{ or }\quad \Delta_N(\alpha(\delta))=0.
  \end{split}
  \right.
 \end{equation}
\end{proposition}
The computation of the zero of the discrepancy $\Delta(\alpha)$ can be implemented 
with any method; for instance the Newton's method, or the bisection one.
\par
We briefly sketch the Newton's method, which requires the expression of the first derivative.
Differentiation of \eqref{eq:def-disc} with respect to $\alpha$ gives
\begin{equation}
 \Delta'(\alpha) = \dfrac{2 \langle  Kx^{\delta, \alpha} - y^\delta, K\frac{d}{d\alpha}x^{\alpha, \delta}\rangle}{2\|Kx^{\alpha,\delta} - y^\delta\|}.
\end{equation}
The equation for the gradient $dx^{\alpha,\delta}/d\alpha$ is obtained by differentiation of \eqref{eq:tikh-equation-2}
\begin{equation}
 \alpha\frac{d}{d\alpha}x^{\alpha, \delta} + K^*K\frac{d}{d\alpha}x^{\alpha, \delta} = -x^{\delta, \alpha},
\end{equation}
and the iteration of the Newton's method is
\begin{equation}
 \alpha^{k+1} = \alpha^k - \frac{\Delta(\alpha^k)}{\Delta'(\alpha^k)}.
\end{equation}
% \begin{align}
%  &\Delta(\alpha) = \|Kx^{\alpha,\delta} - y^\delta\|^2 - \delta^2 && \Delta'(\alpha) = 2 \langle  Kx^{\delta, \alpha} - y^\delta, K\frac{d}{d\alpha}x^{\alpha, \delta}\rangle  \\
%  &\Delta_1(\alpha) = \|Kx^{\alpha,\delta} - y^\delta\| - \delta && \Delta_1'(\alpha) = \frac{1}{\|Kx^{\alpha,\delta} - y^\delta\|} \langle  Kx^{\delta, \alpha} - y^\delta, K\frac{d}{d\alpha}x^{\alpha, \delta}\rangle  \\
%  &\Delta_3(\alpha) = \|Kx^{\alpha,\delta} - y^\delta\| - \delta \|x^{\alpha,\delta}\| && \Delta_3'(\alpha) = \frac{1}{\|Kx^{\alpha,\delta} - y^\delta\|} \langle  Kx^{\delta, \alpha} - y^\delta, K\frac{d}{d\alpha}x^{\alpha, \delta}\rangle -\delta\frac{1}{\|x^{\alpha,\delta}\|}\langle x^{\alpha, \delta}, \frac{d}{d\alpha}x^{\alpha, \delta}\rangle
% \end{align}
In the numerical approximations reported in the following sections, we used the normalized discrepancy function $\Delta_N(\alpha)$, and the bisection method, to avoid negative, and therefore non admissible, values for $\alpha$.
\par
Finally we state the result which validates the admissibility of 
the strategy $\alpha(\delta)$ of Proposition \ref{prop:strategy-disc}, according with Definition \ref{def:admissibility-reg-strategy}.
\begin{proposition}
 Let $\alpha(\delta)$ be the strategy constructed according with the discrepancy principle in Proposition \ref{prop:strategy-disc}. Then it's an admissible strategy, that is
 \begin{equation}
  x^{\alpha(\delta)}\to x \textup{ as }\delta\to0.
 \end{equation}
\end{proposition}
 The result for the classical definition of discrepancy $\Delta(\alpha)$ can be found in \cite{kirsch:book}. The same author proves the result for $\Delta_N(\alpha)$ in \cite{kirsch:shape-1998}.
\section{Numerical Discretization}
We now report the details of the numerical discretization of the linear sampling method. The main 
steps are:
\begin{enumerate}
 \item the choice of a basis of functions for the space $L^2_0(\partial \Omega)$;
 \item the solution of the direct Laplace problem and the direct inclusion problem, 
 which will be done by the use of the Nystr\"om method;
 \item the construction of the discrete relative Neumann--to--Dirichlet map;
 \item the regularization and the computation of the solution of the linear system related 
 to the inverse problem.
\end{enumerate}
Our choice is to solve the Laplace and the inclusion direct problems  
through \emph{boundary integrals}. Their numerical approximation requires the definition of discrete 
functional spaces defined on a boundary. 
For instance, discretization can be done with a finite basis of smooth functions defined globally 
on $\partial \Omega$, or with a finite basis of functions defined each one on a single element of 
the discretized boundary. Indeed, this last method is called the Boundary Element Method (BEM). 
We will used this method every time that we will interpolate the integrand function with a piecewise 
linear basis.

Furthermore, all the methods which define the regularized discrete integral operator, 
for an equation of the first kind,
can be classified, under the definition of Projection methods 
(see \cite{kirsch:book}), in Galerkin methods, Least Squares methods, or 
Collocation methods. We will adopt the Nystr\"{o}m method for an equation 
of the second kind, which can be interpreted as a 
collocation method with quadrature nodes coincident with collocation nodes. 
We are advantaged by the reduced amount of computation, since Nystr\"{o}m method requires only 
one integration, while two integrations are needed for the Galerkin method, and three 
integrations for the Least Squares method.
We list main advantages of the formulation of the problem through boundary integrals, 
instead of using for instance the discretization of the variational formulation with the FEM.
\begin{enumerate}
 \item The expression of the solution reduces to a boundary integral,
 and allows not to consider the full domain. The discretization of a curve, instead of an area 
 in two dimension (or a surface instead of a volume in three dimension), is less expensive.
 \item We can deal with unbounded regions in exterior problems, as easily as we do with bounded regions.
 \item Most of the times, for smooth boundaries and smooth data, the rate of convergence is very high, even exponential.
\end{enumerate}
On the other end, we present the main disadvantages.
\begin{enumerate}
 \item The boundary integrals formulation requires the knowledge of the fundamental solution. 
 This problem depends on the nature of the differential equation. 
 We used the fundamental solution of the Laplace problem to construct boundary layers 
 for the inclusion problem, but this fact couldn't be circumvented for 
 differential problem with non constant parameters.
 \item Main difficulties comes from singularities of the integral kernels, 
 which requires a convergent quadrature method.
 \item Some attention must be payed to boundaries with corners, 
 where the unknown densities are singular. The quadrature rule requires a more 
 careful collocation of the nodes.
\end{enumerate}

\section{Numerical Integration of Layer Potentials}
Let us consider $D$ and $\Omega$
satisfying Assumption \ref{assumption:connected}. 
Moreover we assume $\partial D$ and $\partial \Omega$ of class $C^2$.
This last assumption on the boundary affects the methods and their convergence.
\par
We will make wide use of integral potentials, with integral kernel $K(x,y)$, and density $\phi(y)$, defined on a compact boundary $\partial \Omega$
\begin{equation}
\label{eq:quad-def-operator}
 A\phi(x)\coloneqq \int_{\partial \Omega} K(x,y)\phi(y)\,dy \quad x\in\mathbb{R}^2.
\end{equation}
Most of the times, for $x\in\mathbb{R}^2\backslash\partial \Omega$, the kernel $K(x,y)$ is 
continuous. We concentrate our 
attention to the case with $x\in\partial\Omega$.
In the sequel, $\partial\Omega$ will be a curve in $\mathbb{R}^2$ of class $C^2$ parametrized by
\begin{equation}
c(t):[0,2\pi]\to\mathbb{R}^2.
\end{equation}
The quadrature rule implemented depends on the integral kernel. 
\begin{lemma}
The operator $S$ defined in \eqref{def:operator-S} has a weakly singular kernel of logarithmic type. 
Instead, the operators $K$ and $K'$ in 
\eqref{def:operator-K} and \eqref{def:operator-K'} have a weakly singular kernel, which it's proved to 
be continuous for a boundary $\partial \Omega$ of class $C^2$. Indeed for $K$ (analogously for $K'$) defined as
\begin{equation*}
K\phi(x)\coloneqq\int_{\partial D} \phi(y) \partial_{\nu(y)} \Phi(x, y) \,dy,
=\int_{\partial D} \phi(y)\frac{1}{2\pi}\frac{1}{|x - y|}\frac{x-y}{|x-y|}\cdot\nu(y)\, dy,
\end{equation*}
and more explicitly in two dimension
\begin{equation}
K\phi(c(t)) =\int_0^{2\pi} \phi(c(\tau))\frac{1}{2\pi}\frac{1}{|c(t) - c(\tau)|}\frac{c(t)-c(\tau)}{|c(t) - c(\tau)|}\cdot\nu(c(\tau))|c'(\tau)|\, d\tau,
\end{equation}
it's well defined the diagonal term (with $\xi,\zeta \in [t,\tau]$)
\begin{align}
 &\lim_{\tau \to t}\frac{1}{2\pi}\frac{c(t)-c(\tau)}{|c(t) - c(\tau)|^2}\cdot\nu(c(\tau))|c'(\tau)| \\
 =&\lim_{\tau \to t}\frac{1}{2\pi}\frac{-\frac{1}{2}c''(\xi)|t-\tau|^2\cdot\nu(c(\tau))|c'(\tau)|}{|c'(\zeta)|^2|t-\tau|^2}
 = -\frac{1}{4\pi}\frac{c''(t)\cdot\nu(t)}{|c'(t)|} = -\frac{1}{4\pi}\kappa(t)|c'(t)|,
\end{align}
by $c''(\tau)=v(\tau)T(\tau) + \kappa(\tau)v^2(\tau)N(\tau)$ (denoting $v(\tau)=|c'(\tau)|$). Note that the integral kernel of $K'$ has the same diagonal value.
\end{lemma}
The quadrature rule substitutes the integral
\begin{equation}
 A\phi(c(t))=\int_0^{2\pi} K(c(t),c(\tau))\phi(c(\tau))|c'(\tau)|\,d\tau=\int_0^{2\pi}g(t,\tau)d\tau \quad t\in[0,2\pi]
\end{equation}
with its discretization, which makes use of values of the density $\phi(c(t))$ in quadrature 
nodes $\tau_k^{(n)}$, that is
\begin{equation}
\label{eq:quad-rule-generic}
 A_n\phi(c(t)) = \sum_{k=1}^n\alpha_k^{(n)}(t)\phi(c(\tau_k^{(n)})).
\end{equation}
\begin{definition}
\label{def:convergent-quadrature-rule}
We say $A_n$ is a sequence of \emph{convergent} quadrature rules if $A_n\phi$ converges to $A\phi$ for any continuous $\phi$.
\end{definition}
For a continuous kernel $K(x,y)$, it's sufficient to apply a convergent quadrature rule according with Definition 
\ref{def:convergent-quadrature-rule}, like the trapezoidal rule, 
and \eqref{eq:quad-rule-generic} becomes
\begin{equation}
\label{eq:quad-rule-continuous}
 A_n\phi(c(t)) = \sum_{k=1}^n\alpha_k^{(n)}K(c(t),c(\tau_k^{(n)}))\phi(c(\tau_k^{(n)})).
\end{equation}
Further details about interpolation and numerical integration can be founded in \cite{QSS:book}, and in 
\cite{kress:book} relative to layer potentials.
% -------------------------------------------------------------------------------------
% \begin{enumerate}
%  \item the integral operator $S:\partial\Omega\to \partial\Omega$ has with a weakly singular kernel of logarithmic type, we rewrite in terms of a periodic parametrization:
% \begin{equation}
%  -\frac{1}{2\pi}\ln|x(t)-x(\tau)|=M_1\ln\Big(4\sin^2\frac{t-\tau}{2}\Big)+M_2(t,\tau) \quad M_1 = -\frac{1}{4\pi}
% \end{equation}
% with $M_2$ continuous and bounded.
% \begin{align}
%  S\phi(c(t)) =  &\int_0^{2\pi} M_1\ln\Big(4\sin^2\frac{t-\tau}{2}\Big)\phi(c(\tau))|w'(\tau)|\,d\tau + \\ 
%                 &\int_0^{2\pi} M_2(t,\tau)\phi(c(\tau))|w'(\tau)|\,d\tau 
% \end{align}
% \end{enumerate}
% A quadrature rule $S_n\phi$, uniformly bounded in $x(t)$, is composed by the Discrete Fourier Transform (DFT) (obtained by the trigonometric interpolation based on an equidistant subdivision) for the first integral, and a generic convergent quadrature rule for the second one (for example the trapezoidal rule based on lagrangian interpolation with equidistant nodes) 
\subsection{Double Layer Potentials and Composite Polynomial Interpolation}
In the case of double layer potentials, we will use the trapezoidal rule 
corresponding to the linear piecewise interpolation of the integrand function, 
since they have a continuous kernel.
\begin{proposition}
 Let $g:\mathbb{R}\to\mathbb{R}$ be analytic and $2\pi$-periodic, then there exists a strip $D_S=\mathbb{R}\times(-s, s)\subset\mathbb{C}$ with $s>0$, such that
 $g$ can be extended to a holomorphic and $2\pi$-periodic bounded function $g:D_S\to\mathbb{C}$.
\end{proposition}
In \cite{kress:book} is demonstrated, in Theorem 12.6, the exponential 
convergence for analytic integrands, which we'll verify numerically.
\begin{proposition}
 Let $g$ be as above, then the error of the composite trapezoidal rule
 \begin{equation}
  E_T(g)\coloneqq \frac{1}{2\pi}\int_0^{2\pi}g\,dy - \frac{1}{2n}\sum_{j=0}^{2n-1}g\Bigl(\frac{j\pi}{n}\Bigr)
 \end{equation}
 can be estimated by 
 \begin{equation}
  |E_T(g)|\leq M(g)(\coth ns -1), \text{ or equivalently }  |E_T(g)|\leq C(g) e^{-2ns}.
 \end{equation}
\end{proposition}
\subsection{Single Layer Potentials and Trigonometric Interpolation}
In the case of a single layer potential we can not directly implement the trapezoidal rule.
Let $\partial \Omega$ be of class $C^2$, the integral operator $S:\partial\Omega\to \partial\Omega$ has a \emph{weakly singular kernel with a logarithmic singularity}. We rewrite it in terms of a periodic parametrization
\begin{equation}
\label{eq:def-kernel-M}
 M(t,\tau)\coloneqq-\frac{1}{2\pi}\ln|c(t)-c(\tau)|=M_1(t,\tau)\ln\Big(4\sin^2\frac{t-\tau}{2}\Big)+M_2(t,\tau),
\end{equation}
resulting in
\begin{equation}
\begin{cases}
 M_1(t,\tau)= -1/(4\pi), \\
 M_2(t,\tau)=M(t,\tau) - M_1(t,\tau)\ln\Big(4\sin^2\dfrac{t-\tau}{2}\Big), & t\neq \tau,
\end{cases}
\end{equation}
with a diagonal term
\begin{align}
 M_2(\tau,\tau)&=\lim_{t\to\tau} \Big(M(t,\tau) - M_1(t,\tau)\ln\Big(4\sin^2\frac{t-\tau}{2}\Big)\Big) \\
 &=2M_1(\tau,\tau)\ln\big(|c'(\tau)|\big)=-1/(2\pi)\ln\big(|c'(\tau)|\big),
\end{align}
with $M_2(t,\tau)$ continuous and bounded (actually both kernels $M_1, M_2$ are analytic). It's convenient to separate the two integrals as the sum
\begin{align}
 S\phi(c(t)) =  &\int_0^{2\pi} M_1\ln\Big(4\sin^2\frac{t-\tau}{2}\Big)\phi(c(\tau))|c'(\tau)|\,d\tau + \label{eq:single-integral-M1}\\ 
                &\int_0^{2\pi} M_2(t,\tau)\phi(c(\tau))|c'(\tau)|\,d\tau \label{eq:single-integral-M2}.
\end{align}
We focus on the integral \eqref{eq:single-integral-M1}, containing the singularity, expressed as
\begin{equation}
 Qg(t)\coloneqq\frac{1}{2\pi}\int_0^{2\pi}\ln\Bigl(4\sin^2\frac{t-\tau}{2}\Bigr)g(\tau)d\tau
\end{equation}
with $g(t)$ continuous and $2\pi$-periodic. The quadrature rule 
$Q_ng\coloneqq Qg_n$ consists in replacing $g$ with its 
trigonometric interpolation 
\begin{equation}
 g_n(t)=\frac{\alpha_0}{2} + \sum_{k=1}^{n-1}\{\alpha_k\cos kt + \beta_k\sin kt\} + \frac{\alpha_n}{2}\cos nt,
\end{equation}
such that $g_n(\tau_j) = g(\tau_j)$ for $j=0,\dots,2n-1$, based on equidistant quadrature nodes $\tau_j\coloneqq j\pi/n$. 
The quadrature rule gives
\begin{equation}
 Q_ng(t)\coloneqq \sum_{j=0}^{2n-1}R_j^{(n)}(t)g(\tau_j),\quad j=0,\dots, 2n-1.
\end{equation}
The weights $R_j^{(n)}(t)=QL_j(\tau)$ are the integrals of the Lagrange basis's functions $L_j(\tau)$ of the trigonometric interpolation, that are
\begin{equation}
 L_j(t)=\frac{1}{2n}\Big\{1+2\sum_{k=1}^{n-1}\cos k(t- \tau_j) + \cos n(t - \tau_j)\Big\},\quad j=0,\dots,2n-1,
\end{equation}
\begin{equation}
 R_j^{(n)}(t)=\frac{1}{2\pi}\int_0^{2\pi}\ln\Bigl(4\sin^2\frac{t-\tau}{2}\Bigr)L_j(\tau)d\tau, \quad j=0,\dots,2n-1,
\end{equation}
\begin{equation}
 R_j^{(n)}(t)=-\frac{1}{n}\Bigl\{\sum_{m=1}^{n-1}\frac{1}{m}\cos m(t-\tau_j) + \frac{1}{2n}\cos n(t-\tau_j)\Bigr\}, \quad j=0,\dots,2n-1.
\end{equation}
We report Lemma 8.21 contained in \cite{kress:book}.
\begin{lemma}
For the trigonometric monomials, we have the integrals
\begin{equation}
 \frac{1}{2\pi}\int_0^{2\pi}\ln\Bigl(4\sin^2\frac{t}{2}\Bigr)e^{imt}\,dt=
 \begin{cases}
  0, & m=0, \\
  -1/|m|, & m=\pm1,\pm2,\dots
 \end{cases}
\end{equation}
\end{lemma}
We compute the estimate of the quadrature error $E_ng\coloneqq Qg - Q_ng$, directly from the interpolation error
\begin{align}
 |E_ng|(t)=|Qg-Q_ng|(t)&\leq\frac{1}{2\pi}\int_0^{2\pi}\Big|\ln\Bigl(4\sin^2\frac{t-\tau}{2}\Bigr)\Big||g(\tau)-g_n(\tau)|\,d\tau \\
 &\leq \frac{1}{2\pi} \int_0^{2\pi}\Big|\ln\Bigl(4\sin^2\frac{t-\tau}{2}\Bigr)\Big|\,d\tau\|g(\tau) - g_n(\tau)\|_{\infty}.
\end{align}
The trigonometric interpolation operators are not uniformly bounded.
Provided additional regularity of the integrand $g$, we have uniform convergence of the integrals. 
The following propositions are Theorems 11.6 and 11.7 contained in \cite{kress:book}, which give 
a result in this direction.
\begin{proposition}
 Let $g\in C^{m,\alpha}_{2\pi}$ be a H\"{o}lder--continuous $2\pi$-periodic function with $n\in\mathbb{N}$ and $\alpha\in(0,1]$. Then there holds the estimate for the trigonometric interpolation error
 \begin{equation}
  \|P_ng - g\|_{\infty}\leq C(m,\alpha)\frac{\ln n}{n^{m+\alpha}}\|g\|_{m,\alpha}.
 \end{equation}
\end{proposition}
\begin{proposition}
 Let $g$ be an analytic $2\pi$-periodic function, then there exists an holomorphic extension and the estimate for the trigonometric interpolation error decrease exponentially with $n$
 \begin{equation}
  \|P_ng - g\|_{\infty}\leq M(g)\frac{\coth\frac{s}{2}}{\sinh ns} \leq C(g)e^{-ns}.
 \end{equation}
\end{proposition}

\subsection{Domains with Corners}
Let $\partial \Omega$ be the boundary of a domain with corners, therefore the parametrization $c(t)$ has jumps in the first derivative.
We will refer to a smooth portion of $\partial \Omega$, and we parametrize it between $[0,2\pi]$. 
Therefore, in the case of the operators $K,K'$, the integrand function, for fixed $t$, is smooth in $(0,2\pi)$ and presents 
singularities at the end--points, that we write as
\begin{equation}
\label{eq:corners-double}
 K\phi(t)=\int_0^{2\pi}K(c(t),c(\tau))\phi(c(\tau))|c'(\tau)|\,d\tau=\int_0^{2\pi}g(t,\tau)\,d\tau.
\end{equation}
The idea is to adapt the quadrature nodes in a such a way that we can neglect the end--points.
We substitute the variable $\tau=w(\sigma)$ (it's convenient to evaluate $K\phi$ in $t=w(s)$)
\begin{equation}
\label{eq:corners-generic}
 K\phi(w(s))=\int_0^{2\pi}g(w(s),w(\sigma))|w'(\sigma)|\,d\sigma.
\end{equation}
The function $w$ is required to be a bijection of $[0,2\pi]$ to itself, with vanishing derivatives at the end--points. In \cite{kress:bie-scattering} is cited the choice of Sag and Szekeres in \cite{Sa-Sz64}, that is
\begin{equation}
 w(s)=\frac{e^{-2\pi/s}}{e^{-2\pi/s} + e^{-2\pi/(2\pi - s)}}.
\end{equation}
To avoid overgrading, since high convergence order is effective only for large $n$, a possible substitution is suggested in \cite{kress:bie-corners}, that is
\begin{equation}
 w(s)=2\pi\frac{[v(s)]^q}{[v(s)]^q + [v(2\pi - s)]^q},\label{eq:graded-parametrization-power}
\end{equation}
where the cubic is defined such that grid points are equally distributed on two sides
\begin{equation}
 v(s)=\Bigl(\frac{1}{q} - \frac{1}{2}\Bigr)\Bigl(\frac{\pi - s}{\pi}\Bigr)^3 + \frac{1}{q}\frac{s-\pi}{\pi} + \frac{1}{2}.
\end{equation}
By applying trapezoidal rule on equidistant nodes, the quadrature rule for the approximate integral \eqref{eq:corners-generic} based on the graded mesh $\tau_j=w(\sigma_j)$ 
with equidistant nodes $\sigma_j=j\pi/n$ is 
\begin{equation}
 K_n\phi(w(s))=\frac{\pi}{n}\sum_{j=1}^{2n-1}a_jg(w(s), w(\sigma_j)),\quad a_j=w'(j\pi/n),\quad j=1,\dots,2n-1.
\end{equation}
We proceed in the same way for the single layer operator $S$ defined on a boundary $\partial \Omega$ with corners. 
We consider a smooth portion of the boundary and we substitute its parametrization in the integral kernel $M(t,\tau)$ defined in \eqref{eq:def-kernel-M}
\begin{equation}
 S\phi(w(s))=\int_0^{2\pi}M(w(s),w(\sigma))\phi(c(w(\sigma)))|c'(w(\sigma))|w'(\sigma)\,d\sigma.
\end{equation}
After the variable change, we need to solve the logarithmic singularity of the kernel by a suitable quadrature rule.
We define
\begin{equation}
\label{eq:def-kernel-tildeM}
 \tilde{M}(s,\sigma)\coloneqq-\frac{1}{2\pi}\ln|c(w(s))-c(w(\sigma))|=\tilde{M}_1(s,\sigma)\ln\Big(4\sin^2\frac{s - \sigma}{2}\Big)+\tilde{M}_2(s,\sigma),
\end{equation}
where
\begin{equation}
\begin{cases}
 \tilde{M}_1(s,\sigma) = M_1(w(s),w(\sigma))= -1/(4\pi), \\
 \tilde{M}_2(s,\sigma) = \tilde{M}(s,\sigma) - \tilde{M}_1(s,\sigma)\ln\Big(4\sin^2\dfrac{s - \sigma}{2}\Big), & s\neq \sigma, \\
\end{cases}
\end{equation}
with a diagonal term
\begin{align}
 \tilde{M}_2(\sigma,\sigma)&=\lim_{s\to\sigma} \Big(\tilde{M}(s,\sigma) - \tilde{M}_1(s,\sigma)\ln\Big(4\sin^2\dfrac{s - \sigma}{2}\Big)\Big) \\
 &=M_2(w(\sigma),w(\sigma)) + 2M_1(w(\sigma),w(\sigma))\ln\big(w'(\sigma)\big)= \\
 &=-1/(2\pi)\ln\big(|c'(w(\sigma))|w'(\sigma)\big),
\end{align}
with $\tilde{M}_2(t,\tau)$ continuous and bounded (both kernels $\tilde{M}_1, \tilde{M}_2$ turn out to be analytic). 
Then we can apply respectively quadrature rule generated by trigonometric interpolation on equidistant nodes, and trapezoidal rule on equidistant nodes $\sigma_j = j\pi/n$ for $j=1,\dots,2n-1$, neglecting end--points with vanishing $w'(0)=w'(2\pi)=0$.
\section{Neumann--to--Dirichlet maps' Discretization}
In this section, we describe how we discretize Neumann--to--Dirichlet maps defined in 
\eqref{eq:NtoD-laplace} and in \eqref{eq:NtoD-inclusion}. We take advantage of the 
structure of natural representation formulas of the solutions. Indeed, they entail two 
integral equations of the second kind, which are well-posed, meaning that the 
operators are bijective and have continuous inverse.
Respectively
\begin{enumerate}
 \item we represent the solution $v$ of the Laplace problem \eqref{eq:NtoD-laplace}, with 
 Neumann data $f$ on $\partial \Omega$, as a simple layer potential with density on $\partial \Omega$, such 
 that we can impose boundary values for derivatives
 \begin{equation}
 \label{eq:def-v-representation}
  v(x)\coloneqq \int_{\partial\Omega}\Phi(x,x_0)\phi(x_0)\,dx_0,
 \end{equation}
 \begin{equation}
 \label{eq:2kind-laplace}
  \partial_\nu v=\Bigl(K'+\tfrac{1}{2}I\Bigr)\phi = f,
 \end{equation}
 \item we represent the solution $u$ of the inclusion problem \eqref{eq:NtoD-inclusion}, 
 with Neumann data $f$, as the sum of two simple layer potentials, to force 
 at the same time boundary data $\partial_\nu u = f$ on $\partial \Omega$ and transmission conditions 
 $\partial_\nu u^+-k\partial_\nu u^-=0$ on $\partial D$
 \begin{equation}
 \label{eq:def-u-representation}
  u(x)\coloneqq \int_{\partial\Omega}\Phi(x,x_0)\phi_\Omega(x_0)\,dx_0 + \int_{\partial D}\Phi(x,x_0)\phi_D(x_0)\,dx_0,
 \end{equation}
 \begin{align}
  &\Bigl(K' + \tfrac{1}{2} I\Bigr)\phi_\Omega + K^\diamond(\partial D;\,\partial \Omega)\phi_D = f,\\
  & K^\diamond(\partial \Omega;\,\partial D)\phi_\Omega + \Bigl(K' + \tfrac{\hat{c}}{2} I\Bigr)\phi_D = 0,
 \end{align}
 or equivalently 
 \begin{equation}
 \label{eq:2kind-inclusion}
 \tfrac{1}{2}
 \begin{bmatrix}
  \phi_\Omega\\ \hat{c}\,\phi_D
 \end{bmatrix}
 + 
 \begin{bmatrix}
 K'(\partial \Omega) & K^\diamond(\partial D;\,\partial \Omega)\\
 K^\diamond(\partial \Omega;\,\partial D) & K'(\partial D)
 \end{bmatrix}
 \begin{bmatrix}
  \phi_\Omega\\ \phi_D
 \end{bmatrix}
 =
 \begin{bmatrix}
 f\\ 0
 \end{bmatrix}
 ,
 \end{equation}
\end{enumerate}
where the operators $K^\diamond(\partial A;\partial B):\partial A\to\partial B$ are the normal derivatives 
on $\partial B$ of a single layer defined on $\partial A$, that is
\begin{equation}
 K^\diamond(\partial A;\partial B)\phi\coloneqq \partial_\nu \mathcal{S}(x)\textup{ on }\partial B\,\textup{ with }
 \mathcal{S}(x)\coloneqq \int_{\partial A}\Phi(x,x_0)\phi(x_0)\,dx_0,
\end{equation}
and they have a smooth integral kernel (we can compute derivation under integral's sign).
\subsection{Nystr\"om Method}
Both equations \eqref{eq:2kind-laplace} and \eqref{eq:2kind-inclusion} can be expressed as 
a \emph{second kind} equation of the form
\begin{equation}
\label{eq:nystrom-full}
 \phi-A\phi = f,
\end{equation}
where $A$ is a \emph{compact} linear operator (and therefore continuous) and $I-A:X\to Y$ is \emph{injective}. 
In the first case \eqref{eq:2kind-laplace}, $X=X_0=\{\phi_0\}^\perp \subset L^2(\partial \Omega)$, 
while in the second case \eqref{eq:2kind-inclusion}, $X=X_0\times L^2(\partial D)$, where $\phi_0$ is the only non trivial eigenvector in $\mathcal{N}(K' + 1/2I)$ on $\partial\Omega$.
\par
The \emph{Nystr\"om method} consists in substituting $A$ with a convergent (according to Definition \ref{def:convergent-quadrature-rule}) 
quadrature rule $A_n$ in the previous equation \eqref{eq:nystrom-full}. 
This first discretization yields to the \emph{semi--discretized equation} finite dimensional
\begin{equation}
\label{eq:nystrom-semi}
 \phi_n - A_n\phi_n = f.
\end{equation}
\par
We will consider only the case of $\partial \Omega$ of class $C^2$, such that the 
integral kernel of $A$, in the next equation, is continuous 
(for boundaries with corners the integral kernel is weakly singular and we need to integrate separately on each smooth piece through a graded mesh).
Therefore in the sequel, the quadrature operator $A_n\phi$ reduces to \eqref{eq:quad-rule-continuous} 
(we neglect the curve's parametrization $c$ and use quadrature nodes $x_k=c(\tau_k^{(n)})$), that is
\begin{equation}
\label{eq:quad-rule-continuous-synt}
 A_n\phi(x) = \sum_{k=1}^n\alpha_k K(x,x_k)\phi(x_k).
\end{equation}
We report Theorem 12.7 in \cite{kress:book}, which expresses the solution of \eqref{eq:nystrom-semi} as a finite sum.
\begin{theorem}
 Let $A$ be an integral operator with a continuous integral kernel $K(x,y)$, 
 and consider the semi--discretized equation \eqref{eq:nystrom-semi}, more explicitly
 \begin{equation}
  \label{eq:nystrom-semi-continuous}
  \phi_n(x) -\sum_{k=1}^n\alpha_k K(x,x_k)\phi_n(x_k)=f(x), \quad x\in \partial \Omega,
 \end{equation}
 then
 \begin{enumerate}
  \item if $\phi_n$ is a solution of \eqref{eq:nystrom-semi-continuous}, then its values $\phi_j^{(n)} = \phi_n(x_j)$ 
  at nodes $x_j$ satisfy the following linear system
  \begin{equation}
    \label{eq:nystrom-system}
    \phi_j^{(n)} - \sum_{k=1}^n\alpha_k K(x_j,x_k)\phi_k^{(n)} = f(x_j),\quad j=1,...,n,
  \end{equation}
  \item conversely, if values $\phi_j^{(n)}$ satisfy the linear system \eqref{eq:nystrom-system}, then $\phi_n$ such constructed solves the approximate equation
  \begin{equation}
   \phi_n(x)\coloneqq f(x) + \sum_{k=1}^n\alpha_k K(x,x_k)\phi_k^{(n)}, \quad x\in \partial\Omega.
  \end{equation}
 \end{enumerate}
\end{theorem}
This fast way for solving \eqref{eq:nystrom-semi}, can be interpreted as a collocation method on the subdivision coincident with quadrature nodes.
\par
Finally the result which compares the two solutions of \eqref{eq:nystrom-full} and of 
\eqref{eq:nystrom-semi}, guarantees us for the convergence of Nystr\"om's method.
The error analysis for the equation of the second kind is based on Theorem 10.9 contained \cite{kress:book}, where all details can be found.
\begin{definition}
\label{def:collectively-compact}
 Let $\mathcal{A}=\{A:X\to Y\}$ be a set of linear operators between two normed spaces. It's called a \emph{collectively compact} set if for each bounded set $U\subset X$ the set of images $\mathcal{A}(U)=\{A(U):A\in\mathcal{A}\}$ is relatively compact.
\end{definition}
\begin{theorem}[Pointwise Convergence]
 Let $X$ be a Banach space, let $I-A:X\to X$ be injective, 
 where $A$ is linear compact, 
 and let $A_n$ be a sequence \emph{pointwise convergent}, of \emph{collectively compact} operators 
 (see Definition \ref{def:collectively-compact}), 
 then there holds the error estimate for the solution of the second kind equation $\phi-A\phi=f$, and its approximation $\phi_n - A_n\phi_n=f_n$
 \begin{equation}
  \|\phi_n - \phi \| \leq \frac{1 + \|(I-A)^{-1}A_n\|}{1-\|(I-A)^{-1}(A_n-A)A_n\|}\{\|(A_n - A)\phi\| + \| f_n - f\|\}.
 \end{equation}
 Moreover for sufficiently large $n$ (such that the denominator in the coefficient is positive), thanks to uniform boundedness with respect to $n$, there holds      
 \begin{equation}
  \|\phi_n - \phi \| \leq C\{\|(A_n - A)\phi\| + \| f_n - f\|\}.
 \end{equation}
\end{theorem}
\begin{corollary}
 Let $K(x,y)$ be a continuous integral kernel of $A$, let $I-A$ be injective and $A_n$ be a sequence of convergent quadrature rules. 
 If $f$ is continuous, then $\phi,\phi_n$ are continuous. 
\end{corollary}
% For an integral operator with continuous kernel, the trapezoidal rule gives
% \begin{equation}
%  |(A - A_n)\phi|(x) \leq \frac{1}{12}h^2(b-a)\max_{y\in G}|\partial_{yy}K(x,y)\phi(y)|
% \end{equation}\begin{figure}
Since in our case we use directly $f_n=f$, there holds the a priori error estimate
 \begin{equation}
  \|\phi_n - \phi \| \leq C\|(A_n - A)\phi\|.
 \end{equation}
Let $-N_r=N_D - N_0$ be the relative Neumann--to--Dirichlet map. In the previous section, we described
how we computed the approximation of $-{N_r}f$, which we denote by $-{N_{rn}}f$, that is the difference 
of the two discretized maps $N_{0n}$ and $N_{Dn}$ valued on $f$
\begin{equation}
\label{eq:N0n-Ndn}
 {N_{0n}}f = S_n\phi_n = SP_n\phi_n\quad \textup{and} \quad{N_{Dn}}f = S_n\phi_{\Omega n} + S_n\phi_{D n},
\end{equation}
where $S_n$ is the quadrature rule of the single layer operator $S$, and 
$\phi_n, \phi_{\Omega n}, \phi_{Dn}$ 
are the approximate solution of the semi-discretized equation, computed with the Nystr\"{o}m method.
\par
The error estimate of the relative map is
\begin{equation}
 \|{N_r}f - {N_{rn}}f\|\leq\|S\|\|\phi-\phi_n\| + \|S\phi_n - S_n\phi_n\| = err_{Nystr\textit{\"{o}}m} + err_{Num\,Int}.
\end{equation}
% Convergence results of quadrature rules for the integration of a double or a single layer potential 
% contained in the previous sections, lead us to expect an exponential convergence both for the Nystr\"{o}m method and 
% for the numerical integration of $S$. 
In Figure \ref{fig:contourplots_direct} we can compare the implementation of the two 
direct maps which discretize the Laplace problem and the inclusion problem.

\begin{center}
\begin{figure}
% \subfloat[][\emph{Computed solution for direct Laplace problem}.]
{
\includegraphics[width=.5\textwidth]{fig/contourplots_direct_0}
}
% \subfloat[][\emph{Computed solution for direct problem with an elliptic inclusion}.]
{
\includegraphics[width=.5\textwidth]{fig/contourplots_direct_D}
}
\caption{Numerical discretization of the direct Laplace problem and the inclusion problem respectively,
with Neumann boundary data given by the harmonic function $(x-2)^2-y^2$.}
\label{fig:contourplots_direct}
\end{figure}
\end{center}

\par
% In Figures \ref{fig:convergence-N_0-smooth} and \ref{fig:convergence-N_0-Lipschitz}
We tested the convergence order of $N_0$, for which we can easily compute the exact solution, 
from the knowledge of the explicit expression of a harmonic function. 
We started from an elliptic boundary $\partial\Omega$ and we imposed Neumann boundary data from 
$v(x,y)=x^3 - 3 xy^2$.
In Figure \ref{fig:convergence-ellipse-L2}, with logarithmic scale for both axes,
we reported the convergence order of the error of the trace $\|N_{0n}f - v|_{\partial\Omega}\|$ in the $L^2(\partial\Omega)$ norm.
We obtained the same behavior for the error in the $L^\infty(\partial\Omega)$ norm, 
according with a power law $n^{-2}$, with the exponent estimated from the loglog plot, 
in according with the convergence of the trapezoidal quadrature.
This can be explained from the fact that the approximate density $\phi_n$ 
in the trapezoidal integration \eqref{eq:N0n-Ndn} is not analytic.
In Figure \ref{fig:convergence-ellipse-LinfOmega}, with logarithmic scale only for 
the error axis, we measured a convergence order of the error in the norm $L^\infty(\Omega)$
in according with an exponential law $e^{-\sigma n}$, by the fact that the integral kernel of $S$, valued in $\Omega$,
is now smooth.
\par
In Figure \ref{fig:convergence-N_0-Lipschitz} we considered 
different domains and we estimated the convergence order of the error
in the $L^2(\partial\Omega)$ norm in according with a power law $n^\alpha$, 
with $\alpha\approx-1.10$ for a kite shaped domain, and $\alpha\approx-0.85$ 
for a drop shaped domain, containing a vertex.
\par
Furthermore, in Figure \ref{fig:convergence-N_D-kite} we can observe the order of convergence of 
the $L^2(\partial \Omega)$ norm of $N_Df$, the solution of the direct inclusion problem (with a kite
shaped inclusion), where we used, as exact values, the numerical solution computed with 
a large number of quadrature nodes. This procedure called \emph{mesh over-refinement} is adopted whenever
we haven't an explicit expression. We want underline the fact that to compute a good
approximation of $N_0f$ or $N_Df$ at a certain point on the boundary $p\in\partial\Omega$, it's fundamental
to include it from the beginning, to exactly integrate the singularity contained in the kernel of the single layer 
which represents
the solution. Furthermore we validated the numerical solution of the map $N_D$
computed by the Nystr\"{o}m method with the solution computed by another method, the Finite Element
Method through the software FreeFem++ \cite{FreeFem}. We remark that in Figure \ref{fig:convergence-N_D-fem}, 
the order of convergence seems to flatten because the Nystr\"{o}m method reaches convergence faster
than FEM.

\begin{center}
\begin{figure}[]
\subfloat[][\emph{Convergence order of $N_0$ in the $L^2(\partial \Omega)$ norm, 
according with a power law $n^{-2}$}.]
{
\includegraphics[width=.50\textwidth]{fig/convergence_laplace_one_ellipse}
\label{fig:convergence-ellipse-L2}
}
\subfloat[][\emph{Convergence order of $N_0$ in the $L^\infty(\Omega)$ norm,
according with an exponential law $e^{-\sigma n}$}.]
{
\includegraphics[width=.50\textwidth]{fig/convergence_laplace_one_ellipse_inf}
\label{fig:convergence-ellipse-LinfOmega}
}
% \caption{Loglog plot of the convergence order of $N_0$, in the case of a smooth boundary $\partial\Omega$, 
% and in the Lipschitz regular case (a drop shaped domain with one vertex, and a triangle), compared
% with the exact solution imposed $x^3- 3xy^2$.}
\caption{Convergence order of $N_0$ for an elliptic boundary $\partial\Omega$.}
\label{fig:convergence-N_0-ellipse-inf}
\end{figure}
\end{center}

\begin{center}
\begin{figure}[]
{
\includegraphics[width=.50\textwidth]{fig/convergence_laplace_one_kite}
}
% \subfloat[][\emph{Convergence order of $N_0$ with $\partial \Omega$ triangular}.]
{
\includegraphics[width=.50\textwidth]{fig/convergence_laplace_one_drop}
}
\caption{Loglog plot of the error of $N_0$ in the $L^2(\partial\Omega)$ norm, for the case of a smooth boundary $\partial\Omega$
kite shaped, 
and for a Lipschitz regular boundary, a drop shaped domain with one vertex, 
with the imposed solution $x^3- 3xy^2$.}
\label{fig:convergence-N_0-Lipschitz}
\end{figure}
\end{center}


\begin{center}
\begin{figure}[]
% \centering
\subfloat[][\emph{Convergence order of $N_D$ with a kite shaped inclusion, and $n=500$ 
quadrature nodes on the boundary $\partial\Omega$ for the exact solution (mesh over-refinement)}.]
{
\includegraphics[width=.50\textwidth]{fig/convergence_inclusion_onekite_bemfem_bem_bemerr}
}
\subfloat[][\emph{Convergence order of $N_D$ for the same problem, validated with the solution 
computed with the Finite Element Method}.]
{
\includegraphics[width=.50\textwidth]{fig/convergence_inclusion_onekite_bemfem_bem}
\label{fig:convergence-N_D-fem}
}
\caption{Convergence order of $N_D$.}
\label{fig:convergence-N_D-kite}
\end{figure}
\end{center}

Since the map $-N_{rn}$ uses only the values of $f$ in the quadrature nodes $x_j$, we can easily 
construct a map defined on the finite dimensional vector subspace of $\mathbb{R}^{2n}$ spanned by 
$\{f(x_j)\}$, the values on $2n$ quadrature nodes. This subspace has dimension $2n-1$, 
since $f$ is subjected to the constrain of zero mean. Therefore we can compute $-N_{rn}b_k$ 
only for a finite basis $b_k$ of $\mathbb{R}^{2n}$, to construct the discrete map 
$-N_{rn}:\mathbb{R}^{2n-1}\to \mathbb{R}^{2n-1}$.
% Our intention is to construct an \emph{approximate map} $-{N_r^{(n)}}$ to generalize and speed up 
% the computation for any $f$. Therefore, our aim is to express $-{N_r^{(n)}}$ in terms of 
% a basis $\{b_k\}_{k\in\mathbb{N}}$ of a $n$-dimensional subspace $X_n\subset X=L^2_0(\partial\Omega)$.
% Consequently, our first step will be the projection of $f$ on the subspace $X_n$, through the interpolation $P_nf$,
% and we will take in account this error, by an accurate choice of $P_n$ such that the convergence of the global error will be not affected 
% (we'll denote $\phi(f)$ the solution of the second kind equation with right term $f$).
% \begin{equation}
%  P_nf = \sum_{k=1}^nf_kb_k \Rightarrow \phi_n(P_nf)=\sum_{k=1}^nf_k\phi_n(b_k)
% \end{equation}
% 
% \begin{align*}
%  -e_n &= -{N_r}f + {N_r}_nP_nf =S\phi(f) - S_n\phi_n(P_nf) \\
%  &=\Big[S\phi_n(P_nf) - S_n \phi_n(P_nf) \Big] 
%  + \Big[S\phi(f) - S\phi(P_nf)\Big] \\
%   &\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad
%   + \Big[S\phi(P_nf)- S\phi_n(P_nf)\Big] \\ 
%  &=\Big(S\psi_n - S_n\psi_n \Big) 
%  -N_r(I-P_n)f
%  + S\Big(\phi(P_nf)-\phi_n(P_nf)\Big) \\
%  &= e_{Num\,Int} + e_{Interp} + e_{Nystr\textit{\"{o}}m}
% %  + &\Big[S\phi(f) - S\sum\phi(e_k)f_k\Big] 
% %  + \Big[S\sum\phi(e_k)f_k - S\sum\phi_n(e_k)f_k\Big] \\
% % &= N_0(I-P_n)f + \sum_kf_k[S(\phi-\phi_n)(e_k)]
% \end{align*}
\par
After we have computed the map $-N_{rn}$, 
the approximate equation to regularize is
\begin{equation}
 N_r f = \psi_{0z},
\end{equation}
while its regularized correspondent, and its discretization, according to Tikhonov method, are
\begin{align}
 &\alpha_n f^{\alpha_n} + N_r^TN_rf^{\alpha_n} = \psi_{0z}\label{eq:tikh-reg-lsm}, \\
 &\alpha_n f_n^{\alpha_n} + N_{rn}^TN_{rn}f_n^{\alpha_n} = \psi_{0zn}\label{eq:tikh-reg-lsm-discrete}.
\end{align}
In the next section, we will compare the plots of the norm of the computed $f$, according to Propositions
\ref{prop:lsm-constructive} and \ref{prop:lsm-counterpart}. To take in account the norm of right term 
$\psi_{0z}$, we will plot the inverse of the ratio of the two norms, namely
\begin{equation}
 r_n(z)\coloneqq\frac{\|\psi_{0zn}\|_{L^2(\partial \Omega)}}{\|f_n\|_{L^2(\partial \Omega)}},
\end{equation}
such that $\|r_n(z)\|\to 0$ as $\|f_n\|\to \infty$.
In Figure \ref{fig:contourplots_rhs}, we can see the numerical discretization of the right hand side $\psi_{z0}$, 
compared with $\psi_{z}$.


\begin{center}
\begin{figure}[]
% \subfloat[][\emph{Computed solution for direct Laplace problem}.]
{
\includegraphics[width=.50\textwidth]{fig/contourplots_rhs_0}
}
% \subfloat[][\emph{Computed solution for direct problem with an elliptic inclusion}.]
{
\includegraphics[width=.50\textwidth]{fig/contourplots_rhs_D}
}
\caption{Numerical test functions $\psi_{z0}$ and $\psi_z$ respectively, computed from
the maps $N_0$ and $N_D$, used as right side in the linear equation.}
\label{fig:contourplots_rhs}
\end{figure}
\end{center}


% \input{thesis_section_numres_old}
\section{Numerical Results}
This section is dedicated to the discussion of the numerical approximations 
implemented in the Python code.
We consider first a smooth inclusion, elliptic shaped. Then we compare the results obtained by 
the two different methods
\begin{enumerate}
 \item the Tikhonov regularization of the Neumann--to--Dirichlet map, described by the linear
 sampling method, corresponding to equation \eqref{eq:tikh-reg-lsm},
 \item the factorization method, by the criterion described in section \ref{section:range-criterion}.
\end{enumerate}
The conductivity $k$ has been taken constant $k=2$, as its value doesn't 
affect the outcome in a relevant way. The number of quadrature nodes 
on $\partial D$ and on $\partial \Omega$ has been chosen high enough to obtain a good approximation 
of the map $N_r$.
In the sequel, we will use the abbreviations FM for the Factorization Method, LSM for the regularized 
Linear Sampling Method.
\par
We can observe in Figures 
\ref{fig:one_ellipse0}, \ref{fig:one_ellipse1}, and \ref{fig:one_ellipse2} the 
reconstruction of the inclusion through the LSM, with a uniform fixed value of 
the regularization parameter $\alpha$, and $m$ eigenvalues considered in the FM. We see that for small and sharp shapes, 
we need to be more accurate with smaller values for $\alpha$. Furthermore in Figure \ref{fig:one_ellipse1}
it's clear that the vicinity of the observation boundary doesn't affect the reconstruction in a relevant
way, as in other methods does.
\par
In Table \ref{tab:ellipse-parameters} we can compare the approximate inclusions
computed through the FM with the exact shapes.
The main difference between two methods is that the LSM reconstructs well the position and the shape 
of the inclusion. Moreover, the FM computes with a good accuracy also its size. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \input{notes_thesis/fig_one_ellipse}
\begin{table}
\caption{\emph{Elliptic inclusion's parameters computed with the FM, with $m=30$ eigenvalues}.}
\label{tab:ellipse-parameters}
\begin{center}
\vspace*{-0.5cm}
\begin{tabular}{ccccc}
\toprule
 & exact && exact &\\
 fig & center & center & axes  & axes \\
\midrule
\ref{fig:one_ellipse0} & (0, 0) &  (-0.0668, 0.0004) & (2,1) & (1.9083, 0.6086) \\
\ref{fig:one_ellipse1} & (1, 0) &  (1.0556, 0.0348) & (1.8, 1.2) & (1.8257, 1.0236) \\
\ref{fig:one_ellipse2} & (-1, 0) &  (-1.0360, -0.0450) & (0.1, 1.2) & (0.2023, 1.2705) \\
% -0.0668242916965 0.000355875514924 1.90826456156 0.608634939824
% 1.05556916983 0.034813918014 1.82566291632 1.02363612082
% -1.03601136802 -0.0449939008369 1.2705145551 0.202343494509
\bottomrule
\end{tabular}
\end{center}
\end{table}

\begin{center}
\begin{figure}
{
\includegraphics[width=.50\textwidth]{fig/one_ellipse_lsm_ellipse0_alpha1e-10_no100nd80}
}
{
\includegraphics[width=.50\textwidth]{fig/one_ellipse_fm_ellipse0_m30_no100nd80}
}
\caption{Shape and size approximations for an elliptic inclusion, with $\alpha=\mathrm{1e}{-10}$ in LSM, 
and $m=30$ in FM.}
\label{fig:one_ellipse0}
\end{figure}
\end{center}


\begin{center}
\begin{figure}
{
\includegraphics[width=.50\textwidth]{fig/one_ellipse_lsm_ellipse1_alpha1e-10_no100nd80}
}
{
\includegraphics[width=.50\textwidth]{fig/one_ellipse_fm_ellipse1_m30_no100nd80}
}
\caption{Shape and size approximations for an elliptic inclusion close to $\partial\Omega$, with $\alpha=\mathrm{1e}{-10}$ in LSM, 
and $m=30$ in FM.}
\label{fig:one_ellipse1}
\end{figure}
\end{center}

\begin{center}
\begin{figure}
{
\includegraphics[width=.50\textwidth]{fig/one_ellipse_lsm_ellipse2_alpha1e-06_no100nd80}
}
{
\includegraphics[width=.50\textwidth]{fig/one_ellipse_lsm_ellipse2_alpha1e-10_no100nd80}
}
\\
{
\includegraphics[width=.50\textwidth]{fig/one_ellipse_lsm_ellipse2_alpha1e-13_no100nd80}
}
{
\includegraphics[width=.50\textwidth]{fig/one_ellipse_fm_ellipse2_m30_no100nd80}
}
\caption{Shape and size approximations for an elliptic sharp inclusion, with $\alpha=\mathrm{1e}{-6}$, 
$\alpha=\mathrm{1e}{-10}$, $\alpha=\mathrm{1e}{-13}$ respectively, and $m=30$ in FM.}
\label{fig:one_ellipse2}
\end{figure}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\noindent
Now we consider different geometries, like the kite shape (smoothly parametrized), 
and the drop shape or any polygonal inclusion, for which must be 
used a graded quadrature mesh 
(we used the parametrization \eqref{eq:graded-parametrization-power}), which excludes the 
values in the vertexes. 
The results are reported in Figures \ref{fig:first_compare_kite}, \ref{fig:first_compare_drop} 
and \ref{fig:first_compare_triangle}, which show a good approximation of the shapes and 
of the position of the different inclusions. 

% \input{notes_thesis/fig_one_shape}
\begin{center}
\begin{figure}%[tb]
{
\includegraphics[width=.31\textwidth]{fig/first_compare_lsm_kite0_alpha1e-10_no100nd80}
}
{
\includegraphics[width=.31\textwidth]{fig/first_compare_fm_kite0_m10_no100nd80}
}
{
\includegraphics[width=.31\textwidth]{fig/first_compare_fm_kite0_m40_no100nd80}
}
\caption{Comparison between two methods for a kite shaped inclusion, with $\alpha=\mathrm{1e}{-10}$ 
in LSM, and $m=10$, $m=40$, in the FM.}
\label{fig:first_compare_kite}
\end{figure}
\end{center}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}
\begin{figure}[]
{
\includegraphics[width=.31\textwidth]{fig/first_compare_lsm_drop0_alpha1e-10_no100nd80}
}
{
\includegraphics[width=.31\textwidth]{fig/first_compare_fm_drop0_m10_no100nd80}
}
{
\includegraphics[width=.31\textwidth]{fig/first_compare_fm_drop0_m40_no100nd80}
}
\caption{Comparison between two methods for a drop shaped inclusion, with $\alpha=\mathrm{1e}{-10}$ 
in LSM, and $m=10$, $m=40$, in the FM.}
\label{fig:first_compare_drop}
\end{figure}
\end{center}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}
\begin{figure}[]
{
\includegraphics[width=.31\textwidth]{fig/first_compare_lsm_triangle0_alpha1e-10_no100nd80}
}
{
\includegraphics[width=.31\textwidth]{fig/first_compare_fm_triangle0_m10_no100nd80}
}
{
\includegraphics[width=.31\textwidth]{fig/first_compare_fm_triangle0_m40_no100nd80}
}
\caption{Comparison between two methods for a triangle shaped inclusion, with $\alpha=\mathrm{1e}{-10}$ 
in LSM, and $m=10$, $m=40$, in the FM.}
\label{fig:first_compare_triangle}
\end{figure}
\end{center}
% reciprocity comments
We compare these two methods with the results obtained by the implementation
of the Reciprocity Gap Method, referring to the discretization of equation 
\eqref{eq:rg-approximate-eq}, as the same way we did for the Linear Sampling Method.
In Figure \ref{fig:rg_ellipse} we reported the approximations of the inclusion
computed for different choices of boundaries $\partial \Omega$ and $\partial B$.
The poor quality of the reconstruction, compared with the LSM, is 
due to the presence of two integration contours, instead of one, which origins
symmetries between two sets of quadrature nodes.
Furthermore, in this method with far boundaries, like circles with large radius,
is much more strong the dependence from the angle $\theta$ of the unit vector 
$\vec{d}=(\cos\theta, \sin\theta)$ in the right term $\Psi_z$ (see Definition \ref{def:lsm-psi}).
\begin{center}
\begin{figure}
{
\includegraphics[width=.50\textwidth]{fig/first_compare_rg_kite0_alpha1e-10_no120nd100nb120_radius4}
}
{
\includegraphics[width=.50\textwidth]{fig/first_compare_rg_kite0_alpha1e-10_no120nd100nb120_radius6}
}
\caption{Reconstruction of a kite shaped inclusion by the Reciprocity Gap Method, 
with $\partial\Omega=\partial B(0; 3)$, and two different test functions' domains,
$\partial B=\partial B(0;4)$, $\partial B=\partial B(0;6)$, respectively.}
\label{fig:rg_ellipse}
\end{figure}
\end{center}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% factorization comments
% \begin{center}
% \begin{figure}[]
% {
% \includegraphics[width=.5\textwidth]{fig/first_compare_fm_two_ellipse_m040_eig}
% }
% {
% \includegraphics[width=.5\textwidth]{fig/first_compare_fm_three_ellipse_m030_eig}
% }
% \caption{.}
% \label{fig:first_compare_fm_eig}
% \end{figure}
% \end{center}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\par
In the Factorization Method the eigenvalues $\lambda_j$ considered for the linear regression
in equation \eqref{eq:straightline-eig} are only a small number, 
representing the principal modes. 
To avoid including eigenvalues too small in absolute value, 
which would depend from numerical noise, a good criterion
is to establish this number from their plot, such to truncate the plateau beyond the 
optimal value (other useful criteria can be found in \cite{hanke-bruhl:recent}).
In Figure \ref{fig:first_compare_twothree_ellipse_eig} 
we established $m=30$ and $m=40$ for two different geometries and we obtained
a more accurate reconstruction in Figures \ref{fig:first_compare_two_ellipse}, \ref{fig:first_compare_three_ellipse}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{center}
% \begin{figure}[]
% {
% \includegraphics[width=.31\textwidth, height = 0.31\textwidth]{fig/first_compare_fm_two_ellipse_m040_eig}
% }
% {
% \includegraphics[width=.31\textwidth]{fig/first_compare_fm_two_ellipse0_m030}
% }
% {
% \includegraphics[width=.31\textwidth]{fig/first_compare_fm_two_ellipse0_m040}
% }
% \caption{Factorization Method for $m=30$, $m=40$, respectively. On the left, the linear regression of the
% eigenvalues of the map $N_r$, suggesting $m=40$ as the best choice.}
% \label{fig:first_compare_two_ellipse}
% \end{figure}
% \end{center}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{center}
% \begin{figure}[]
% {
% \includegraphics[width=.31\textwidth, height = 0.31\textwidth]{fig/first_compare_fm_three_ellipse_m030_eig}
% }
% {
% \includegraphics[width=.31\textwidth]{fig/first_compare_fm_three_ellipse0_m030}
% }
% {
% \includegraphics[width=.31\textwidth]{fig/first_compare_fm_three_ellipse0_m040}
% }
% \caption{Factorization Method for $m=30$, $m=40$, respectively. On the left, the linear regression of the
% eigenvalues of the map $N_r$, suggesting $m=30$ as the best choice.}
% \label{fig:first_compare_three_ellipse}
% \end{figure}
% \end{center}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}
\begin{figure}[]
\subfloat[][\emph{ }]
{
\includegraphics[width=.50\textwidth, height = 0.50\textwidth]{fig/first_compare_fm_two_ellipse_m040_eig}
\label{subfig:eig_two_ellipse}
}
\subfloat[][\emph{ }]
{
\includegraphics[width=.50\textwidth, height = 0.50\textwidth]{fig/first_compare_fm_three_ellipse_m030_eig}
\label{subfig:eig_three_ellipse}
}
\caption{Plot of the eigenvalues $\log\lambda_j$ of the relative map $N_r$ for the 
geometry of two ellipses in Figure \ref{fig:first_compare_two_ellipse}, and three ellipses in 
Figure \ref{fig:first_compare_three_ellipse}, respectively, with levels $m=30$, $m=40$.
}
\label{fig:first_compare_twothree_ellipse_eig}
\end{figure}
\end{center}

\begin{center}
\begin{figure}[]
{
\includegraphics[width=.50\textwidth]{fig/first_compare_fm_two_ellipse0_m030}
}
{
\includegraphics[width=.50\textwidth]{fig/first_compare_fm_two_ellipse0_m040}
}
\caption{Factorization Method for $m=30$, $m=40$, respectively. The linear regression of the
eigenvalues $\log\lambda_j$ of the map $N_r$ in Figure \ref{subfig:eig_two_ellipse} suggests $m=40$ as the best choice.}
\label{fig:first_compare_two_ellipse}
\end{figure}
\end{center}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}
\begin{figure}[]
{
\includegraphics[width=.50\textwidth]{fig/first_compare_fm_three_ellipse0_m030}
}
{
\includegraphics[width=.50\textwidth]{fig/first_compare_fm_three_ellipse0_m040}
}
\caption{Factorization Method for $m=30$, $m=40$, respectively. The linear regression of the
eigenvalues $\log\lambda_j$ of the map $N_r$ in Figure \ref{subfig:eig_three_ellipse} suggests  $m=30$ as the best choice.}
\label{fig:first_compare_three_ellipse}
\end{figure}
\end{center}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\par
Now we compare the previous results with the approximations obtained, for the same geometries, by the 
combination of the Tikhonov regularization with the Morozov discrepancy principle, which fixes the 
error level $\delta$, and computes the norm of the regularized solutions for different values of 
$\alpha(\delta)$. In our results we used the \emph{normalized discrepancy} $\Delta_N(\alpha)$ 
\eqref{eq:def-disc-N}, to take in account small norm of the density solving the linear system.
\par
For connected inclusions, we cannot observe a significant improvement. 
Instead, for a non connected domain, composed by two or three components, Figures \ref{fig:discrepancy_two_ellipse} 
and \ref{fig:discrepancy_three_ellipse}
show that after about 15 iterations on $\alpha$, contour plot fills better the unknown shape.
For more fitted mesh with higher $n$ nodes, 
some difficulties occur, since the root $\alpha(\delta)$ of the discrepancy 
function $\Delta_N(\alpha)$ is too close to the machine epsilon. 
Furthermore, the Morozov discrepancy principle provide a criterion to establish 
$\alpha$, for a fixed accuracy $n$. Indeed in Figures \ref{fig:discrepancy_two_ellipse} 
and \ref{fig:discrepancy_three_ellipse} we can see that the approximate reconstruction
reaches a convergence after a certain number of iterations, suggesting that we have
found the optimal function $\alpha$.

\begin{center}
\begin{figure}
{
\includegraphics[width=.50\textwidth]{fig/discrepancy_lsm_two_ellipse_delta1e-60_it_alpha_0}
}
{
\includegraphics[width=.50\textwidth]{fig/discrepancy_lsm_two_ellipse_delta1e-60_it_alpha_14}
}
\\ 
{
\includegraphics[width=.50\textwidth]{fig/discrepancy_lsm_two_ellipse_delta1e-60_it_alpha_19}
}
{
\includegraphics[width=.50\textwidth]{fig/discrepancy_lsm_two_ellipse_delta1e-60_alpha_it_alpha_19}
}
\caption{Discrepancy principle applied to LSM for a domain with two components, 
with $\delta=\mathrm{1e}{-6}$. 
The figures represent the reconstruction after $k=0$, $k=14$, $k=19$ iterations. In the
last figure the plot of the parameter $\alpha$ after $19$ iterations, proving different values
of the optimal $\alpha$.}
\label{fig:discrepancy_two_ellipse}
\end{figure}
\end{center}

\begin{center}
\begin{figure}%[tb]
{
\includegraphics[width=.50\textwidth]{fig/discrepancy_lsm_three_ellipse_delta1e-60_it_alpha_0}
}
{
\includegraphics[width=.50\textwidth]{fig/discrepancy_lsm_three_ellipse_delta1e-60_it_alpha_14}
}
\\
{
\includegraphics[width=.50\textwidth]{fig/discrepancy_lsm_three_ellipse_delta1e-60_it_alpha_19}
}
{
\includegraphics[width=.50\textwidth]{fig/discrepancy_lsm_three_ellipse_delta1e-60_alpha_it_alpha_19}
}
\caption{Discrepancy principle applied to LSM for a domain with three components, 
with $\delta=\mathrm{1e}{-6}$. 
The figures represent the reconstruction after $k=0$, $k=14$, $k=19$ iterations. In the
last figure the plot of the parameter $\alpha$ after $19$ iterations, proving different values
of the optimal $\alpha$.}
\label{fig:discrepancy_three_ellipse}
\end{figure}
\end{center}

% \begin{center}
% \begin{figure}%[tb]
% \subfloat[][\emph{Plot of $\alpha$ computed by the Morozov principle after $15$ iterations}.]
% {
% \includegraphics[width=.48\textwidth]{fig/discrepancy_lsm_two_ellipse_delta1e-60_alpha_it_alpha_15}
% }
% \subfloat[][\emph{Plot of $\alpha$ computed by the Morozov principle after $15$ iterations}.]
% {
% \includegraphics[width=.48\textwidth]{fig/discrepancy_lsm_three_ellipse_delta1e-60_alpha_it_alpha_15}
% }
% \caption{Check on values of $\alpha$ computed by the Morozov discrepancy principle}
% \label{fig:discrepancy_alpha}
% \end{figure}
% \end{center}

The \emph{Inverse Crime} effect appears every time we solve the inverse problem with data computed 
by the discretization of the direct map. It's well known in literature how this aspect leads to 
better estimates than which we should expect. 
% Indeed, in our case, the right term $\psi_{z0}$ 
% has been corrected by the direct Neumann--to--Dirichlet map (see \eqref{def:lsm-psi}). 
Therefore, it's advisable to 
introduce some noise in the data.
% , such that $\|y - y^\delta\|\propto\delta$ is more realistic.
Since measured data are contained in the computation of the map $N_r$, we decided to add 
some normal distributed noise $N_r^{\delta_N}$ proportional to the maximum of the modulus of 
the relative map $N_r$, that is
\begin{equation}
 N_r + N_r^{\delta_N}, \quad N_r^{\delta_N}=\delta_N\|N_r\|_{\infty}
 \cdot \mathcal{N}_{n^2}(0_n,\mathbb{I}_{n^2}),
\end{equation}
where the error level $\delta_N$ has been fixed before.
In Figure \ref{fig:noise_lsm} we can see the reconstruction computed by the Linear 
Sampling Method for different values of the error level $\delta_N$. 
Instead in Figure \ref{fig:noise_fm} we implemented the Factorization Method 
for different choices of the truncation parameter $m$, suggested by the plot of the eigenvalues
$\log\lambda_j$, letting the error level $\delta_N$ be fixed.
\par
We can deduce that the FM is more sensible to noise, while the regularized LSM is more stable, 
and it works for error level up to $\delta_N=\delta_N=\mathrm{1e}{-3}$.

\begin{center}
\begin{figure}
{
\includegraphics[width=.50\textwidth]{fig/noise_lsm_ellipse_noisel0e+00_noiselK1e-02.eps}
}
{
\includegraphics[width=.50\textwidth]{fig/noise_lsm_ellipse_noisel0e+00_noiselK1e-03.eps}
}
\caption{Linear Sampling Method applied to the relative map $N_r$ containing random noise 
$N_r^{\delta_N}$, with $\delta_N=\mathrm{1e}{-2}$, $\delta_N=\mathrm{1e}{-3}$ respectively.}
\label{fig:noise_lsm}
\end{figure}
\end{center}

\begin{center}
\begin{figure}
{
\includegraphics[width=.50\textwidth, height=0.50\textwidth]{fig/noise_fm_ellipse_m012_eig_noiselK1e-03}
}
{
\includegraphics[width=.50\textwidth]{fig/noise_fm_ellipse_m010_noisel0e+00_noiselK1e-03}
}
\\ 
{
\includegraphics[width=.50\textwidth]{fig/noise_fm_ellipse_m012_noisel0e+00_noiselK1e-03}
}
{
\includegraphics[width=.50\textwidth]{fig/noise_fm_ellipse_m014_noisel0e+00_noiselK1e-03}
}
\caption{Factorization Method for different values of the truncation parameter $m=10$, $m=12$,
$m=14$ for the eigenvalues of the relative map $N_r$ containing noise $N_r^{\delta_N}$ 
with $\delta_N=\mathrm{1e}{-3}$. In the first figure the plot of $\log\lambda_j$ from
the map $N_r$ with noise in \`{}o\'{}, without noise in \`{}x\'{}, respectively.}
\label{fig:noise_fm}
\end{figure}
\end{center}


% while FM does not work for 
% values of $\delta$ greater than $\mathrm{1e}{-05}$.

% \begin{center}
% \begin{figure}%[tb]
% \subfloat[][\emph{Linear sampling method for $\alpha=\mathrm{1e}{-10}$ and $\delta=\mathrm{1e}{-05}$}.]
% {
% \includegraphics[width=.30\textwidth]{fig/noise_lsm_ellipse0_noiselevel1e-05}
% }
% \subfloat[][\emph{Linear sampling method for $\alpha=\mathrm{1e}{-10}$ and $\delta=\mathrm{1e}{-02}$}.]
% {
% \includegraphics[width=.30\textwidth]{fig/noise_lsm_ellipse0_noiselevel1e-02}
% }
% \subfloat[][\emph{Factorization method for $\delta=\mathrm{1e}{-02}$}.]
% {
% \includegraphics[width=.30\textwidth]{fig/noise_fm_ellipse0_noiselevel1e-05}
% }
% \caption{Stability of the methods with respect to normal noise of amplitude $\delta$ in the data.}
% \label{fig:noise}
% \end{figure}
% \end{center}
Finally we tested the Morozov discrepancy principle in presence of noise and 
we obtained promising results in Figure 
\ref{fig:discrepancy_noise_three_ellipse}, but it would be hazardous to consider them accurate.
Indeed the reconstruction is affected by some evident error modes, but identifies
the components of the inclusion.
\begin{center}
\begin{figure}
{
\includegraphics[width=.50\textwidth]{fig/discrepancy_noiseK1e-3_lsm_three_ellipse_delta1e-60_it_alpha_0}
}
{
\includegraphics[width=.50\textwidth]{fig/discrepancy_noiseK1e-3_lsm_three_ellipse_delta1e-60_it_alpha_14}
}
\\ 
{
\includegraphics[width=.50\textwidth]{fig/discrepancy_noiseK1e-3_lsm_three_ellipse_delta1e-60_it_alpha_19}
}
{
\includegraphics[width=.50\textwidth]{fig/discrepancy_noiseK1e-3_lsm_three_ellipse_delta1e-60_alpha_it_alpha_19}
}
\caption{Discrepancy principle applied to LSM for a domain with three components and 
 a relative map $N_r$ containing noise $N_r^{\delta_N}$, with $\delta_N=\mathrm{1e}{-3}$. 
The figures represent the reconstruction after $k=0$, $k=14$, $k=19$ iterations. In the
last figure the plot of the parameter $\alpha$ after $19$ iterations, proving different values
of the optimal $\alpha$.}
\label{fig:discrepancy_noise_three_ellipse}
\end{figure}
\end{center}

\clearpage
%\cleardoublepage
% \FloatBarrier

% \input{thesis_section_numres_new}

\chapter*{Conclusions}
\addcontentsline{toc}{chapter}{Conclusions}
From the theoretical perspective, the Reciprocity Gap Method turns out to be equivalent to the 
Linear Sampling Method, as the variational formulation of this one,
but the additional integration makes its discretization more difficult.
In both cases, the main difficulty which arises in the algorithm is the 
identification of an approximating
sequence for a generic sampling point $z$ inside the unknown domain $D$. 
This fact reflects itself 
on the 
% moderately good,
satisfying,
but not optimal numerical results.
\par
The regularization helps the stability of the Linear Sampling implementation, and 
the Morozov principle improves significantly the computed approximation, but at a high 
computational effort, associated with difficulties of very small values,
close to the machine epsilon.
\par
On the other end, the Factorization Method has the advantage of providing an approximation 
without solving any linear system, but it requires a high accuracy of data, lightly affected 
by noise.
\par
For both the methods we identified a good criterion to establish the quality of the
reconstruction, the inspection of the eigenvalues $\lambda_j$ for the Factorization Method, 
and the convergence of the iterations of the Morozov discrepancy principle.
\par
In conclusion, the combination of all these methods gives a good idea of the unknown 
inclusion, and we could expect similar results even for non constant conductivities
or for the three dimensional framework.

% \chapter*{Bibliography}
%\nocite{*}
\printbibliography              % biber
% \bibliographystyle{plain}     % bibtex
% \bibliography{sources}        % bibtex
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{End Document}
\colorbox{Orchid}{

% \framebox[0.5\textwidth][l]{
 \parbox{0.5\textwidth}{
  in evidenza:
  \begin{description}
         \item[parola chiave 1]: ...sssss;
         \item[parola chiave 2]: ....
  \end{description}

 }
%  }
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{alignat}{2}[left=\empheqlbrace]
 & u_t = H(x,t,Du) & \quad&\text{in }\mathbb{R}^n × (0,T) \\[\medskipamount]
  & u(x,0)=u_0(x) & &\text{in } \mathbb{R}^n
\end{alignat}
\vskip 1cm

\begin{subequations}
\begin{alignat}{2}[left=\empheqlbrace]
 & u_t = H(x,t,Du) &\quad & \text{in }\mathbb{R}^n × (0,T) \\[\medskipamount]
 & u(x,0)=u_0(x) & & \text{in } \mathbb{R}^n
\end{alignat}
\end{subequations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{cases}
\begin{numcases}{f(x)=}
   1 & $x\geq0$ \label{positive}
   \\
   0 & $x<0$ \label{negative}
\end{numcases}

See the second case \ref{negative} or the first \ref{positive}
% first part is ALREADY MATH MODE
\begin{subnumcases}{f(x)=}
   1 & $x\geq0$ \label{positive-subnum}
   \\
   0 & $x<0$ \label{negative-subnum}
\end{subnumcases}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}
\begin{tikzpicture}
\draw  plot[smooth, tension=0.7] coordinates {(-3.5,0.5) (-3,2.5) (-1,3.5) (1.5,3) (5,2.5) (5,0.5) (2.5,-2) (-3,-2) (-3.5,0.5)};
\end{tikzpicture}
\end{center}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{tikzpicture}
% \draw [help lines] (-4, -1) grid (4, 5);
\draw [show curve controls]
  (-3, 4) .. controls ++(135:-1) and ++(135:1) .. (0, 4); 
% \draw [show curve controls] (-1, -1) 
%   .. controls ++(165:-1) and ++(270: 1) .. ( 1.5, 1)
  .. controls ++(165:-1) and ++(165:-1) .. ( 0, 1)
  .. controls ++(165: 1) and ++(90: 1) .. (-2, 1)
  .. controls ++(90:-1) and ++(165: 1) .. ( -1, -1);
\end{tikzpicture}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\tikzstyle{mybox} = [draw=red, fill=blue!20, very thick,
    rectangle, rounded corners, inner sep=10pt, inner ysep=20pt]
\tikzstyle{fancytitle} =[fill=red, text=white]

\begin{tikzpicture}
\node [mybox] (box){%
    \begin{minipage}{0.50\textwidth}
        To calculate the horizontal position the kinematic differential
        equations are needed:
        \begin{align}
            \dot{n} &= u\cos\psi -v\sin\psi \\
            \dot{e} &= u\sin\psi + v\cos\psi
        \end{align}
        For small angles the following approximation can be used:
        \begin{align}
            \dot{n} &= u -v\delta_\psi \\
            \dot{e} &= u\delta_\psi + v
        \end{align}
    \end{minipage}
};
\node[fancytitle, right=10pt] at (box.north west) {A fancy title};
\node[fancytitle, rounded corners] at (box.east) {$\clubsuit$};
\end{tikzpicture}%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\centering
\includegraphics[width=\textwidth]{fig/prova}
