\documentclass[10pt]{beamer}
% \documentclass[handout]{beamer}
\usetheme[secheader]{Boadilla}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usefonttheme{professionalfonts}
% \usefonttheme{serif}
% \usepackage{fontspec}
% \setmainfont{Helvetica Neue}

\usepackage{listings}% http://ctan.org/pkg/listings
\usepackage{bera}
\lstset{
  basicstyle=\ttfamily,
  mathescape,
  escapeinside={||},
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
% \usepackage[english]{babel}
\usepackage[italian, english]{babel}

\usepackage[utf8]{inputenc} % needed for bibtex
\usepackage{fontenc}
\usepackage{mathrsfs}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
%\usepackage{nccmath} % mfrac
%\mathbb needs amsfonts or amssymb
\usepackage{amsfonts}
\usepackage{bm} % bold symbols math

\usepackage{centernot} % not implies symbol

% \usepackage[overload]{empheq} % left\{ for align % no crash kile ?
\usepackage{cases}
% \usepackage[usenames,dvipsnames]{xcolor} % before tikz, options for more colors
\definecolor{light-gray}{gray}{0.95}
\definecolor{dark-gray}{gray}{0.65}

% \usepackage[sort, numbers]{natbib}
% \setcitestyle{square}
% \usepackage{bbold}

\usepackage{graphicx}

\usepackage{booktabs}
\usepackage{caption}
\usepackage{subfig}
% \captionsetup[figure]{width=.85\textwidth}
\captionsetup[subfigure]{margin=0.5cm}
\usepackage{tikz}
\usetikzlibrary{matrix}
\usetikzlibrary{positioning}
% set arrows as stealth fighter jets
\tikzset{>=stealth}
% bezier
\usetikzlibrary{decorations.pathreplacing}
\tikzset{%
  show curve controls/.style={
    postaction={
      decoration={
        show path construction,
        curveto code={
          \draw [blue] 
            (\tikzinputsegmentfirst) -- (\tikzinputsegmentsupporta)
            (\tikzinputsegmentlast) -- (\tikzinputsegmentsupportb);
          \fill [red, opacity=0.5] 
            (\tikzinputsegmentsupporta) circle [radius=.5ex]
            (\tikzinputsegmentsupportb) circle [radius=.5ex];
        }
      },
      decorate
}}}
\tikzstyle{mybox} = [draw=gray, fill=light-gray, very thick,
    rectangle, rounded corners, inner sep=10pt, inner ysep=20pt]
\tikzstyle{mytitle} =[fill=gray, text=white]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
\usetikzlibrary{arrows.meta, positioning, shadows}
\newcommand*{\xMin}{0}%
\newcommand*{\xMax}{6}%
\newcommand*{\yMin}{0}%
\newcommand*{\yMax}{6}%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% plots
\usepackage{pgfplots}

%\usepackage{color}

\usepackage{xcolor}
\definecolor{bookColor}{cmyk}{1 , 1  , 0   , 0}  % 0.90\% of black
%\color{bookColor}

\usepackage{hyperref}
% \hypersetup{pdftex,colorlinks=true,allcolors=blue}

% % \usepackage[hidelinks]{hyperref}
% % \usepackage{xcolor}
% \AtBeginDocument{
% \hypersetup{
% % %     colorlinks=false,
% % %     citebordercolor = {Green},
% % %     filebordercolor = {Blue}
%     linkbordercolor = {Blue}
% % %     linkcolor={red!50!black},
% % %     citecolor={blue!50!black},
% % %     urlcolor={blue!80!black}
% }
% }


\usepackage{hypcap}
\usepackage{etoolbox}

\usepackage{csquotes}
%\usepackage[autostyle, italian=guillemets]{csquotes}

% \usepackage[chapter]{placeins} % floatbarrier

\usepackage[backend=biber, style=alphabetic]{biblatex}
\addbibresource{sources.bib}
\DeclareFieldFormat[article]{title}{\textit{#1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{smartdiagram}
\usesmartdiagramlibrary{additions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setbeamerfont{block title}{size=\normalsize}
% \theoremstyle{definition}
% \newtheorem{definition}[subsection]{Definition}
% \theoremstyle{plain}
% \newtheorem{theorem}[subsection]{Theorem}
% \theoremstyle{plain}
% \newtheorem{corollary}[subsection]{Corollary}
% \theoremstyle{plain}
\newtheorem{proposition}[subsection]{Proposition}
\theoremstyle{plain}
\newtheorem{remark}[subsection]{Remark}
\theoremstyle{plain}
% \newtheorem{lemma}[subsection]{Lemma}
% \theoremstyle{plain}
% \newtheorem{example}[subsection]{Example}
% 
% \theoremstyle{plain}
% \newtheorem{assumption}[subsection]{Assumption}
% \theoremstyle{plain}
% \newtheorem{problem}[subsection]{Problem}

\DeclareMathOperator{\divergence}{div}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\real}{Re}
\DeclareMathOperator{\imag}{Im}

\renewcommand{\i}{\textup{i}}
\let\phi\varphi
\let\epsilon\varepsilon
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amssymb,tikz}

\newcommand{\mysetminusD}{\hbox{\tikz{\draw[line width=0.6pt,line cap=round] (3pt,0) -- (0,6pt);}}}
\newcommand{\mysetminusT}{\mysetminusD}
\newcommand{\mysetminusS}{\hbox{\tikz{\draw[line width=0.45pt,line cap=round] (2pt,0) -- (0,4pt);}}}
\newcommand{\mysetminusSS}{\hbox{\tikz{\draw[line width=0.4pt,line cap=round] (1.5pt,0) -- (0,3pt);}}}

\newcommand{\mysetminus}{\mathbin{\mathchoice{\mysetminusD}{\mysetminusT}{\mysetminusS}{\mysetminusSS}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\usepackage{environ}
\NewEnviron{mybox}{%
\begin{center}
\colorbox{light-gray}{\color{black}\parbox{\textwidth}{%
% \fcolorbox{gray}{light-gray}{
\BODY
}}
\end{center}
}

\usepackage{fancyhdr}
\newcommand{\fncyblank}{\fancyhf{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% abstract e sommario
% \newenvironment{abstract} %
% {\cleardoublepage
% \fncyblank\null\vfill\begin{center} %
% \bfseries\abstractname
% \end{center}} %
% {\vfill\null}
% \newenvironment{abstractone} %
% {\clearpage
% \fncyblank\null\vfill\begin{center} %
% \bfseries\abstractname
% \end{center}} %
% {\vfill\null}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \title{Numerical Reconstruction of Inclusions in Electrical Conductors}
\title{Reconstruction of Inclusions}
\author{Giacomo Milan}
\date{3 Ottobre 2017}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%
\begin{frame}
%  \maketitle
    \begin{center}
        \normalsize
        \textsc{Politecnico di Milano}\\
%         \large
        Scuola di Ingegneria Industriale e dell'Informazione\\
        Corso di Laurea in Ingegneria Matematica\\
        \vspace{0.7cm}
        \includegraphics[width=0.15\textwidth]{fig/logoc}
%       \vfill
%       \normalsize
%       \large
        

        \vspace{0.4cm}
        \Large
        \textsc{Numerical Reconstruction of Inclusions in Electrical Conductors}
        
        \vspace{0.3cm}
%         \begin{flushleft}
%         \footnotesize
%         Relatore: Prof. Michele Di Cristo         
%         \end{flushleft}
% %         \vspace{0.2cm}
%         \begin{flushright}
%         \footnotesize
%         Tesi di Laurea di: \\
% %         \large
%         {Giacomo Milan \\ Matr. 841530}         
%         \end{flushright}
%         \normalsize
%         \footnotesize
%         Anno Accademico 2016-2017
        
    \end{center}

\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
 \frametitle{}
 \begin{tikzpicture}[
    node distance = 7mm and 9mm,
   MN/.style args = {#1/#2}{
            draw=#1,% line color
            top color=#2!10,
            bottom color=#2!80,
            rounded corners, thick,
            text width=27mm, minimum height=13mm, inner sep=1mm, 
            align=flush center},
      line/.style = {line width=2mm,
            draw=#1,%line color
            -{Triangle[length=2.8mm,width=4mm,fill=#1]},
            shorten >=1mm, shorten <=1mm
            },
        ds/.style = {drop shadow}
                    ]
                    %---
\linespread{0.9}
% bottom
\node (n1) [MN=blue/blue]                   {Linear sampling method};
% middle
\node (n2) [MN=blue/blue,right=of n1]    {Reciprocity gap method};
\node (n3) [MN=blue/blue,right=of n2]    {Factorization};
% \node (n3) [MN=blue/blue,below=of n1]    {Factorizationskkkkkkkkkkkkkkkkkskksksksksksk};
% lines
% \draw[line=red]     (n6) edge (n3)
%                     (n1) edge (n2)  (n5) to (n4);
% \draw[line=cyan]    (n2) edge (n3);
% \draw[line=blue]    (n3) edge (n4);
\only<2->
\draw[line width=2mm, draw=blue, {Triangle[length=2.8mm,width=4mm,fill=blue]}-{Triangle[length=2.8mm,width=4mm,fill=blue]}]   (n1) edge (n2);
\end{tikzpicture}                       
%  \begin{center}
% % \smartdiagram[descriptive diagram]{
% % {Set up,The set up operation consist of..},
% % }
% \smartdiagramset{
% additions={
% additional item border color=red,
% additional item width = 8cm,
% back arrow disabled = true,
% }}
% \smartdiagramadd[flow diagram:horizontal]{%
% Linear sampling method, Reciprocity gap method%
% }{%
% % below of module1/Low Level, above of module1/High level%
% }
% \smartdiagramconnect{<->}{module1/module2}
% \end{center}
\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}[noframenumbering]
\begin{center}
\Large
 1. Linear sampling method
\end{center}
\end{frame}
%%%%%%%%%%%%%%%%%
%  \only<1>{GA}\only<2>{MOGA}\only<3>{pMOGA}
\begin{frame}
 \frametitle{Neumann--to--Dirichlet maps}
  Let $v\in H^1_0(\Omega)$ be the unique solution of the {\color{blue}Laplace problem}
 \begin{columns}[T]
  \begin{column}{0.5\textwidth}
    \begin{center}
    \begin{tikzpicture}
    \draw [fill=light-gray, draw=gray] (0,0.2) ellipse (2cm and 1.5cm);
%     \node at (-2.2,0.7){${\partial \Omega}$};
    \node at (-1.2,0.1){$\Omega, 1$};
    \end{tikzpicture}
    \end{center}
  \end{column}
  \hspace{-2cm}
  \begin{column}{0.5\textwidth}
  \vspace{0.6cm}
  \begin{center}
 \begin{equation}
 \label{eq:NtoD-inclusion}
  \left\{
  \begin{aligned}
  \divergence(\nabla v) &= 0, \quad\text{in}\,\Omega, \\
            \partial_\nu v &= f, \quad\text{on}\,\partial \Omega,
  \end{aligned}
  \right.
 \end{equation}
 \end{center}
 \end{column}
 \end{columns}
 \vspace{0.6cm}
 and define
   \begin{align}
   &{N_0}: H^{-1/2}_0(\partial \Omega) \to H^{1/2}_0(\partial\Omega) && {N_0} f = v|_{\partial\Omega},
   \end{align}
\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Neumann--to--Dirichlet maps}
%   Let \only<1>{$v\in H^1_0(\Omega)$}\only<2>{$u\in H^1_0(\Omega)$} be the unique solution of the
%   \only<1>{{\color{blue}Laplace problem}}\only<2>{{\color{blue} inclusion problem} with $D\subset \Omega$}
  Let $u\in H^1_0(\Omega)$ be the unique solution of the
  {\color{blue} inclusion problem} with $D\subset \Omega$
 \begin{columns}[T]
  \begin{column}{0.5\textwidth}
  \begin{center}
    \begin{tikzpicture}
    \draw [fill=light-gray, draw=gray] (0,0.2) ellipse (2cm and 1.5cm);
    \filldraw [fill=dark-gray, draw=gray] (0, -0.1) 
     .. controls ++(165:-0.2) and ++(90:-0.5) .. ( 1, 0.1)
     .. controls ++(90:0.5) and ++(1:0.5) .. (0.2, 0.5)
     .. controls ++(1:-0.5) and ++(60:0.7) .. (-0.6, 0.2)
     .. controls ++(60:-0.7) and ++(165:0.2) .. ( 0, -0.1);
%     \node at (-2.2,0.7){${\partial \Omega}$};
%     \node at (-0.6,0.7){${\partial D}$};
    \node at (-1.2,0.1){$\Omega, 1$};
    \node at (0.1,0.1){$D, k$};
    \end{tikzpicture} 
    \end{center}
  \end{column}
 \hspace{-2cm}
 \begin{column}{0.5\textwidth}
 \vspace{0.6cm}
 \begin{center}
 \begin{equation}
 \label{eq:NtoD-inclusion}
  \left\{
  \begin{aligned}
  \divergence(\gamma\nabla u) &= 0, \quad\text{in}\,\Omega, \\
            \partial_\gamma u &= f, \quad\text{on}\,\partial \Omega,
  \end{aligned}
  \right.
 \end{equation}
 \end{center}
  \end{column}
 \end{columns}
 \vspace{0.6cm}
 with $\gamma(x) = 1\chi_{\Omega\backslash\overline{D}} + k\,\chi_D$, and define
\begin{align}
 &{N_D}: H^{-1/2}_0(\partial \Omega) \to H^{1/2}_0(\partial\Omega) && {N_D}f = u|_{\partial\Omega}.
 \end{align}
\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Linear sampling method: the map}
%  In the inverse inclusion problem, a crucial role is played by the 
We denote by ${N_r}:H_0^{\,-1/2}(\partial \Omega)\to H_0^{1/2}(\partial \Omega)$
the {\color{blue} relative} Neumann--to--Dirichlet map
% (see \cite{somersalo:preprint})
\begin{equation}
 {N_r} \coloneqq {N_0} - {N_D}.
\end{equation}
  \begin{proposition}
  The operator ${N_0} - {N_D}:H_0^{\,-1/2}(\partial \Omega)\to H_0^{1/2}(\partial \Omega)$ 
  is injective, with dense image, self-adjoint, compact and positive.
 \end{proposition}
 \begin{proposition}
There holds the strict implication
\begin{equation}
 z\notin D \, \Longrightarrow \,\psi_{0z}\notin\mathcal{R}({N_r}), \quad(z\in D \, \Longleftarrow \,\psi_{0z}\in\mathcal{R}({N_r})).
%  z\in D \,\Longleftrightarrow \, \psi_{0z}\in\mathcal{R}({N_r}^{1/2})\, \Longleftarrow \,\psi_{0z}\in\mathcal{R}({N_r}).
\end{equation} 
\end{proposition}

%  This is proved in \cite{kirsch:book}, but we present the proof for injectivity contained in \cite{somersalo:preprint}, to highlight the link with ITP.
\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Linear sampling method: the right term}
  As right term we consider the potential generated by a dipole
 \begin{equation}
 \left\{
 \begin{aligned}
   -\Delta \psi(x,z) &= \nabla\delta_{z} \cdot \vec{d}, && \textup{ in }\Omega ,\\
   \partial_\nu\psi(x,z) &= 0, &&\textup{ on }\partial \Omega,
 \end{aligned}
 \right.
 \end{equation}
 with unit vector $|\vec{d}\,|=1$.
 \par
 We use the notation
 \begin{equation}
 \vec{\Psi}(x,z)\coloneqq\nabla_x\Phi(x,z) 
 \end{equation}
 for the derivative of the fundamental solution.
 \begin{definition}
 \label{def:lsm-psi}
 We denote
 \begin{equation}
 \psi_{0z} \coloneqq \vec{\Psi}(x,z)\cdot\vec{d} - m_z - N_0\bigl(\partial_\nu \vec{\Psi}(x,z) \cdot \vec{d}\bigr),
  \end{equation}
%   and
%   \begin{equation}
%   \psi_{z} \coloneqq \vec{\Psi}(x,z)\cdot\vec{d} - m_z - M_D\bigl(\partial_\nu \vec{\Psi}(x,z) \cdot \vec{d}\bigr),
%   \end{equation}
  with $m_z$ the mean of $\vec{\Psi_z}\cdot\vec{d}$ on $\partial \Omega$.
 \end{definition}
\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \only<1>{
 \frametitle{Single layer potential}}
\begin{columns}[T]
  \begin{column}{0.50\textwidth}
  \includegraphics[width=1.1\textwidth]{fig/Spng}
  \end{column}
  \begin{column}{0.50\textwidth}
  \vspace{2cm}
  We define
   \begin{equation*}
    \mathcal{S}(\partial D,\psi)(x)\coloneqq \int_{\partial D} \Phi(x, y)\psi(y)\, dy,
%   \quad x\in\mathbb{R}^m \backslash\partial D, 
    \label{eq:definition-single-layer}
   \end{equation*}
%   with a jump on $\partial\Omega$ in the first derivative
%   \begin{align*}
% %    \mathcal{S}^\pm(z) &\coloneqq\lim_{h\to 0^\pm}\mathcal{S}(z+h\nu(z)) = S\psi(z)=\int_{\partial D}\psi(y)\Phi(z,y)\,dy \quad z\in\partial D, \label{eq:single-pm-0}\\
%    \partial_\nu\mathcal{S}^\pm(z) =  K'\psi(z) \,\mp\,\dfrac{1}{2}\psi(z) \quad z\in\partial D.\label{eq:single-pm-1}
%   \end{align*}
  \end{column}
 \end{columns}
 \vspace{0.1cm}
   with a jump on $\partial\Omega$ in the first derivative
  \begin{align*}
%    \mathcal{S}^\pm(z) &\coloneqq\lim_{h\to 0^\pm}\mathcal{S}(z+h\nu(z)) = S\psi(z)=\int_{\partial D}\psi(y)\Phi(z,y)\,dy \quad z\in\partial D, \label{eq:single-pm-0}\\
   \partial_\nu\mathcal{S}^\pm(z) =  K'\psi(z) \,\mp\,\dfrac{1}{2}\psi(z) \quad z\in\partial D.\label{eq:single-pm-1}
  \end{align*}

 \end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Double layer potential}
\begin{columns}[T]
  \begin{column}{0.50\textwidth}
  \vspace{-0.2cm}
  \includegraphics[width=1.1\textwidth]{fig/Dpng}
  \end{column}
  \begin{column}{0.50\textwidth}
  \vspace{2cm}
   We define
   \begin{equation*}
    \mathcal{D}(\partial D,\psi)(x)\coloneqq \int_{\partial D} \partial_{\nu(y)}\Phi(x, y)\psi(y)\, dy,
%   \quad x\in\mathbb{R}^m \backslash\partial D. 
    \label{eq:definition-double-layer}
   \end{equation*}
%    with a jump on $\partial\Omega$
%   \begin{align*}
%    \mathcal{D}^\pm(z) &= K\psi(z) \pm\dfrac{1}{2}\psi(z)\quad z\in\partial D. \label{eq:double-pm-0}
% %    \\
% %    \partial_\nu\mathcal{D}^+(z) &= \partial_\nu\mathcal{D}^-(z) \quad z\in\partial D. \label{eq:double-pm-1}
%   \end{align*}
  \end{column}
 \end{columns}
 \vspace{0.1cm}
   with a jump on $\partial\Omega$
  \begin{align*}
   \mathcal{D}^\pm(z) &= K\psi(z) \pm\dfrac{1}{2}\psi(z)\quad z\in\partial D. \label{eq:double-pm-0}
%    \\
%    \partial_\nu\mathcal{D}^+(z) &= \partial_\nu\mathcal{D}^-(z) \quad z\in\partial D. \label{eq:double-pm-1}
  \end{align*}
 \end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Approximating sequence for $z\in D$}
 We split the main result in two propositions.
\begin{proposition}[Constructive Part]
\label{prop:lsm-constructive}
Fix $z \in D$. Then for any $\epsilon > 0$ there exists an approximating harmonic layer $\mathcal{S}(\partial B, \omega^\epsilon_z)$ with density $\omega^\epsilon_z\in L^2(\partial B)$  such that
\begin{equation}
 \|({N_D} - {N_0})\partial_\nu\mathcal{S}(\partial B, \omega^\epsilon_z) - \psi_{0z}\|_{H^{1/2}(\partial\Omega)} < \epsilon,
\end{equation}
furthermore, when $z$ approaches the boundary $\partial D$, $\|\omega^\epsilon_z\|_{L^2(\partial B)}\to + \infty$.
\end{proposition}
\begin{remark}
 There exist a sequence 
 $v^{\epsilon_n}_z\coloneqq\mathcal{S}(\partial B, \omega^{\epsilon_n}_z)$ 
 and some
 $ v_z\in H^1(D)$, such that
\begin{equation}
 \|v^{\epsilon_n}_z - v_z\|_{H^1(D)} \to 0\quad\textup{ for }\epsilon_n \to 0.
\end{equation}
%  Obviously, $\{v^{\epsilon_n}_z\}_{n\in\mathbb{N}}$ is bounded in the same norm $H^1(D)$.
\end{remark}
% \begin{remark}
%  For fixed $z\in D$, there exist a sequence 
%  $v^{\epsilon_n}_z\coloneqq\mathcal{S}(\partial B, \omega^{\epsilon_n}_z)$ 
%  such that it's approximating as above for $\epsilon_n \to 0$,
% %  that is
% % \begin{equation}
% %  \|({N_D} - {N_0})\partial_\nu v^{\epsilon_n}_z - \psi_{0z}\|_{H^{1/2}(\partial\Omega)} < \epsilon_n, \quad \textup{ for }\epsilon_n\to 0,
% % \end{equation}
%  and it is converging to some function $v_z\in H^1(D)$
% \begin{equation}
%  \|v^{\epsilon_n}_z - v_z\|_{H^1(D)} \to 0.
% \end{equation}
%  Obviously, $\{v^{\epsilon_n}_z\}_{n\in\mathbb{N}}$ is bounded in the same norm $H^1(D)$.
% \end{remark}

\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Approximating sequence for $z\notin D$}
 \begin{proposition}[Counterpart]
\label{prop:lsm-counterpart}
Fix $z \in \Omega\backslash\overline{D}$. Then for any $\delta>0$ and $\epsilon > 0$ there exists an harmonic layer $\mathcal{S}(\partial B, \omega^{\delta, \epsilon}_z)$ with density $\omega^{\delta, \epsilon}_z\in L^2(\partial B)$ such that
\begin{equation}
 \|({N_D} - {N_0})\partial_\nu\mathcal{S}(\partial B, \omega^{\delta,\epsilon}_z) - \psi_{0z}\|_{H^{1/2}(\partial\Omega)} < \delta + \epsilon,
\end{equation}
and $\|\omega^{\delta, \epsilon}_z\|_{L^2(\partial B)}\to + \infty$ as $\delta\to 0$.
\end{proposition}
% In the next section, we will compare the plots of the norm of the computed $f$, according to Propositions
% \ref{prop:lsm-constructive} and \ref{prop:lsm-counterpart}. To take in account the norm of right term 
% $\psi_{0z}$, 
We will plot the inverse of the ratio of the two norms
\begin{equation}
 r_n(z)\coloneqq\frac{\|\psi_{0zn}\|_{L^2(\partial \Omega)}}{\|f_n\|_{L^2(\partial \Omega)}},
\end{equation}
such that $\|r_n(z)\|\to 0$ as $\|f_n\|\to \infty$.

\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}[noframenumbering]
\begin{center}
\Large
 2. Reciprocity gap method
\end{center}
\end{frame}
%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Reciprocity gap method}
 \begin{columns}[T]
 \begin{column}{0.50\textwidth}
%   \begin{tikzpicture}
%   \draw [dashed] (2,2) ellipse (3cm and 2cm);
%   \draw [dashed] (2,2) ellipse (1.5cm and 1cm);
%   \draw (2,2) circle (0.5cm);
%   %\draw (2,2) rectangle (1cm and 3cm);
%   \node at (-0.5,2){$B$};
%   \node at (1,2){$\Omega$};
%   \node at (2,2){$D,k$};
%  \end{tikzpicture}
    \begin{center}
    \begin{tikzpicture}
    \draw [draw=gray] (0,0.2) ellipse (2.5cm and 1.8cm);
    \draw [fill=light-gray, draw=gray] (0,0.2) ellipse (1.8cm and 1.2cm);
    \filldraw [fill=dark-gray, draw=gray] (0, -0.1) 
     .. controls ++(165:-0.2) and ++(90:-0.5) .. ( 1, 0.1)
     .. controls ++(90:0.5) and ++(1:0.5) .. (0.2, 0.5)
     .. controls ++(1:-0.5) and ++(60:0.7) .. (-0.6, 0.2)
     .. controls ++(60:-0.7) and ++(165:0.2) .. ( 0, -0.1);
%     \node at (-2.2,0.7){${\partial \Omega}$};
%     \node at (-0.6,0.7){${\partial D}$};
    \node at (-2.1, 0.1){$B$};
    \node at (-1.2, 0.1){$\Omega, 1$};
    \node at (0.1, 0.1){$D, k$};
    \end{tikzpicture} 
    \end{center}
 \end{column}
 \begin{column}{0.50\textwidth}
 \vspace{0.8cm}
  \begin{itemize}
   \item $\partial B$ sources boundary
   \item $\partial \Omega$ observation boundary
   \item data
   \begin{equation*}
    u\in\mathcal{U} \to u|_{\partial\Omega},\, \partial_\nu u|_{\partial\Omega}
   \end{equation*}

  \end{itemize}
 \end{column}
 \end{columns}
%  In concrete applications, the function $u$ is not computed, though it's observed on the 
% surface $\partial\Omega$ and the measures $u|_{\partial \Omega}$, 
% $\partial_\nu u|_{\partial \Omega}$ are considered for the definition of the reciprocity gap operator. Dirichlet data $f$ are the values of the generic potential which we are able to generate from the exterior: it can be a plane wave in the scattering case, or the potential generated by a point source $\delta_{x_0}$. In the latter case we are referring to the fundamental solution, and by uniqueness, the same $u$ is equal to $u(x)=\Phi_D(x,x_0)$ for $x\in \Omega$.
% In the sequel $B$ is the background medium which contains $\Omega\subset B$.

% \begin{definition}
% \label{def:setU}
% We will denote by $\mathcal{U}$ the set of functions
% \begin{equation}
%  \mathcal{U}\coloneqq\bigl\{\Phi_D(x, x_0): x_0\in \partial B\bigr\},
% \end{equation}
% where $\Phi_D$ is the fundamental solution, which solves the inclusion problem.
% \end{definition}
\vspace{0.8cm}
We denote by (where $\Phi_D$ is the fundamental solution of the inclusion problem)
\begin{itemize}
 \item $\mathcal{U}$ the set of functions
$
 \mathcal{U}\coloneqq\bigl\{\Phi_D(x, x_0): x_0\in \partial B\bigr\},
$
 \item $\mathcal{V}(\overline{B})$ the set of harmonic functions, continuously defined on $\overline{B}$,
 \item $\mathcal{V}_0(\overline{B})$ the subspace 
$
  \mathcal{V}_0(\overline{B})\coloneqq\Bigl\{v\in\mathcal{V}(\overline{B}):\int_{\partial B} v = 0\Bigr\}.
$
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%
% \begin{frame}
%  \frametitle{Reciprocity gap method: definitions}
%  \begin{definition}
% \label{def:setV}
% We denote
% % Let $u\in\mathcal{U}$, the set in Definition \ref{def:setU}. In our case $u(x,x_0)=\Phi_D(x,x_0)$, with $x_0 \in \partial B$, then
% \begin{itemize}
%  \item by $\mathcal{V}(\overline{B})$ the set of harmonic functions, continuously defined on $\overline{B}$,
%  \item by $\mathcal{V}_0(\overline{B})$ the subspace of vanishing mean functions, that is
%  \begin{equation}
%   \mathcal{V}_0(\overline{B})\coloneqq\Bigl\{v\in\mathcal{V}(\overline{B}):\int_{\partial B} v = 0\Bigr\},
% %   =\mathcal{V}(\overline{B})/\textup{span}\bigl(\{1\}\bigr),
%  \end{equation}
% \end{itemize}
% \end{definition}
% \begin{definition}
% We denote by $\textup{R} : \mathcal{V}(\overline{B})\to L^2(\partial B)$ the {\color{blue}reciprocity gap} operator defined by
% \begin{equation}
%  \textup{R}(v)(x_0)\coloneqq 
% %  \mathcal{R}_{\partial\Omega}\bigl(u(\cdot,x_0),v(\cdot)\bigr)\coloneqq \int_{\partial \Omega}\bigl(u(y,x_0)v_\nu (y) - u_\nu(y,x_0)v(y)\bigr)dy.
%  \mathcal{R}_{\partial\Omega}\bigl(u(\cdot,x_0),v(\cdot)\bigr)
%  \coloneqq \int_{\partial \Omega}\bigl(uv_\nu - u_\nu v \bigr)dy.
% \end{equation}
% \end{definition}
% \end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Reciprocity gap method: the operator R}
 We denote by $\textup{R} : \mathcal{V}(\overline{B})\to L^2(\partial B)$ the {\color{blue}reciprocity gap operator}
 defined by
\begin{equation}
 \textup{R}(v)(x_0)\coloneqq 
%  \mathcal{R}_{\partial\Omega}\bigl(u(\cdot,x_0),v(\cdot)\bigr)\coloneqq \int_{\partial \Omega}\bigl(u(y,x_0)v_\nu (y) - u_\nu(y,x_0)v(y)\bigr)dy.
 \mathcal{R}_{\partial\Omega}\bigl(u(\cdot,x_0),v(\cdot)\bigr)
 \coloneqq \int_{\partial \Omega}\bigl(uv_\nu - u_\nu v \bigr)dy.
\end{equation}

 \begin{proposition}
 The operator $\textup{R} : \mathcal{V}_0(\overline{B})\to L^2(\partial B)$
 \begin{itemize}
  \item[-] is injective,
  \item[-] its range has codimension one: $\mathcal{R}(R)^\perp=\textup{span}(\{\alpha_c\})$,
 \end{itemize}
 where $\alpha_c$ is the solution of 
 $
  \partial_\nu \mathcal{S}^-(\partial B,\alpha_c) = 0,\textup{ on }\partial B.
 $
 \end{proposition}
 The choice $\Psi_z=\nabla_x\Phi(x,z)\cdot \vec{d}$ in the right term guarantees that
 \begin{equation*}
  \mathcal{R}(u,\Psi_z) \perp \textup{span}(\{\alpha_c\})
 \end{equation*}

\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Reciprocity Gap Approximation Theorem}
 Finally we can state the key theorem which provides a binary criterion to discriminate the inclusion from the background.
\begin{theorem}[Reciprocity Gap Approximation Theorem]
 \label{theo:approximation-rg} 
%  Let $D\subset\Omega\subset B$  be an inclusion satisfying Assumption \ref{assumption:connected}, let $\{(u|_{\partial \Omega},\partial_\nu u|_{\partial \Omega})\}$ 
%  be a set of measured data with $u\in\mathcal{U}$ as in Definition \ref{def:setU} and 
%  let consider the class $\mathcal{V}(\overline{B})$ of harmonic test functions 
%  in Definition \ref{def:setV}. Then
There holds the alternative
 \begin{enumerate}
  \item if $z \in D$ then there exists a sequence $\{v_n\} \subset \mathcal{V}(\overline{B})$ such that
   \begin{equation}
     \lim_{n\to\infty}\mathcal{R}(u,v_n) = \mathcal{R}(u,\Psi_z)\quad\forall u\in\mathcal{U},\label{eq:rg-lim-constructive}
   \end{equation}
%    where $\Psi_z$ as in Definition \ref{def:fund-sol-deriv-Psi},
   $v_n|_{\partial D}\to g$ in $L^2(\partial D)$ and consequently  it's bounded in the norm $\|v_n\|_{L^2(\partial D)}$;
  \item if $z \in \Omega \backslash D$ then any sequence $\{v_n\} \subset \mathcal{V}(\overline{B})$ such that
   \begin{equation}
     \lim_{n\to\infty}\mathcal{R}(u,v_n) = \mathcal{R}(u,\Psi_z)\quad\forall u\in\mathcal{U}\label{eq:rg-lim-counterpart}
   \end{equation}
   is unbounded $\|v_n\|_{L^2(\partial D)}\to\infty$ in $L^2(\partial D)$.
 \end{enumerate}
\end{theorem}
\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Link between RGM and LSM}
 We have seen the two methods
 \begin{enumerate}
  \item the LSM
  \vspace{-0.1cm}
  \begin{equation}
  \label{eq:eq-lsm-link}
  ({N_D} - {N_0})f = \psi_{0z} \quad \text{ on }\partial \Omega.
  \end{equation}
  \item the RGM
  \vspace{-0.1cm}
  \begin{equation}
   \mathcal{R}(u, v) = \mathcal{R}(u, \vec{\Psi}_z\cdot\vec{d})\quad \forall u \in \mathcal{U}
  \end{equation}
 \end{enumerate}
% 
%  that the reciprocity gap method is formulated as an integral equation 
% of the form
% \begin{equation}
% \end{equation}
% whereas the linear sampling method deals with the following equation
% \begin{equation}
% \label{eq:eq-lsm-link}
%  ({N_D} - {N_0})f = \psi_{0z} \quad \text{ on }\partial \Omega.
% \end{equation}
We compute the duality of \eqref{eq:eq-lsm-link}, with a generic 
${g \in \bigl(H^{1/2}_0(\partial \Omega)\bigr)^* = H^{\,-1/2}_0(\partial \Omega)}$, by self-adjoint properties
% (denoting $u,v$ solutions of 
% \eqref{eq:NtoD-inclusion}), \eqref{eq:NtoD-laplace}, we have
\begin{align*}
 \label{eq:link-duality-left}
 \langle({N_D} - {N_0})f,g\rangle & =  \langle f,{N_D} g\rangle - \langle {N_0} f,g\rangle \\
                                        & = \langle \partial_\nu v,u\rangle - \langle v,\partial_\nu u\rangle
                                        = \mathcal{R}(u,v).
\end{align*}
\begin{proposition}
 The RGM corresponds to the weak formulation of the LSM,
 provided the change of $\psi_{0z}$ in $\psi_z$.
%  as right side in \eqref{eq:eq-lsm-link}
%  instead of $\psi_{0z}$, the two methods are equivalent.
\end{proposition}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Regularization of ill-posed equations}
The approximate equation for the linear sampling method is
\begin{equation}
(Kx = y)\quad N_r f = \psi_{0z}, \quad\textup{ where }N_r\in\mathcal{K}(L^2(\partial\Omega)).
\end{equation}
Let $x^{\alpha,\delta}\coloneqq R_{\alpha(\delta)} y^\delta$ the regularized solution for perturbed data $y^\delta$, $\|y^\delta - y\|\leq \delta$. 
Then
% \par
% The fundamental error estimate for any regularized solution is
\begin{align*}
\label{eq:fundamental-error-estimate}
 \|x^{\alpha, \delta} - x\| &\leq \|R_\alpha y^\delta - R_\alpha y\| + \|R_\alpha y - x\| \\
                            &\leq \|R_\alpha\| \|y^\delta - y\| + \|R_\alpha Kx - x\|.
\end{align*}
% The above estimate represents the decomposition of the approximation error, for a fixed error 
% level $\delta$ in the data $\|y^\delta - y\|\leq \delta$. By the ill-posed nature of the problem, the norm 
% $\|R_\alpha\|$ diverges as $\alpha\to 0$, while the regularization implies a converging regularized 
% solution $x^{\alpha} = R_\alpha y$ to $x=K^{-1}y$, equivalent to $\|R_\alpha Kx -x\|\to 0$, as $\alpha\to0$.
% Hence, 
\emph{We have to accept a compromise for the choice of the parameter $\alpha$, between
\begin{enumerate}
 \item the accuracy $\|R_\alpha Kx -x\|\to0$ for $\alpha\to0$,
 \item the stability $\|R_\alpha\|\to\infty$ for $\alpha\to0$,
 \end{enumerate}
and we have to elaborate a 
strategy $\alpha(\delta)$ which guarantees convergence of the error $\|x^{\alpha,\delta} - x\|$.}
%  \begin{definition}
%  An {\color{blue}regularization strategy} $R_\alpha : Y \to X$, for $\alpha> 0$, is a family of linear and bounded operators such that
%  \begin{equation}
%   \lim_{\alpha\to 0}R_\alpha Kx = x\quad \forall x \in X.
%  \end{equation}
%  An {\color{blue}admissible} regularization strategy $\alpha(\delta)$ is a function such that for $\delta \to 0$
%  \begin{equation}
%  \left\{
%  \begin{aligned}
%   &\alpha(\delta) \to 0, \\
%   &\forall x \in X: \,\sup\bigl\{\bigl\|R_{\alpha(\delta)} y^\delta - x\bigr\|:y^\delta \in Y, \|Kx - y^\delta\|\leq\delta\bigr\} \to 0.
%  \end{aligned}
%  \right.
%  \end{equation}
% \end{definition}
\end{frame}

%%%%%%%%%%%%%%%%%
% \begin{frame}
%  \frametitle{Regularization}
% The approximate equation for the linear sampling method is
% \begin{equation}
%  N_r f = \psi_{0z}, \quad\textup{ where }N_r\in\mathcal{K}(L^2(\partial\Omega))\quad(Kx = y).
% \end{equation}
%  \begin{definition}
%  An {\color{blue}regularization strategy} $R_\alpha : Y \to X$, for $\alpha> 0$, is a family of linear and bounded operators such that
%  \begin{equation}
%   \lim_{\alpha\to 0}R_\alpha Kx = x\quad \forall x \in X.
%  \end{equation}
%  An {\color{blue}admissible} regularization strategy $\alpha(\delta)$ is a function such that for $\delta \to 0$
%  \begin{equation}
%  \left\{
%  \begin{aligned}
%   &\alpha(\delta) \to 0, \\
%   &\forall x \in X: \,\sup\bigl\{\bigl\|R_{\alpha(\delta)} y^\delta - x\bigr\|:y^\delta \in Y, \|Kx - y^\delta\|\leq\delta\bigr\} \to 0.
%  \end{aligned}
%  \right.
%  \end{equation}
% \end{definition}
% \end{frame}
% %%%%%%%%%%%%%%%%%
% \begin{frame}
%  \frametitle{}
%  In the sequel we'll denote $x^{\alpha}\coloneqq R_\alpha y$ and 
% $x^{\alpha,\delta}=x^{\alpha(\delta)}\coloneqq R_\alpha y^\delta$ respectively the solutions of the regularized equation with unperturbed and perturbed data.  
% \begin{remark}
% The fundamental error estimate for any regularized solution is
% \begin{align}
% \label{eq:fundamental-error-estimate}
%  \|x^{\alpha, \delta} - x\| &\leq \|R_\alpha y^\delta - R_\alpha y\| + \|R_\alpha y - x\| \\
%                             &\leq \|R_\alpha\| \|y^\delta - y\| + \|R_\alpha Kx - x\|.
% \end{align}
% \end{remark}
% The above estimate represents the decomposition of the approximation error, for a fixed error 
% level $\delta$ in the data $\|y^\delta - y\|\leq \delta$. By the ill-posed nature of the problem, the norm 
% $\|R_\alpha\|$ diverges as $\alpha\to 0$, while the regularization implies a converging regularized 
% solution $x^{\alpha} = R_\alpha y$ to $x=K^{-1}y$, equivalent to $\|R_\alpha Kx -x\|\to 0$, as $\alpha\to0$.
% Hence, \emph{we have to accept a compromise for the choice of the parameter $\alpha$, between 
% the accuracy $\|R_\alpha Kx -x\|$ and the stability $\|R_\alpha\|$}, and we have to elaborate a 
% strategy $\alpha(\delta)$ which guarantees convergence of the error $\|x^{\alpha,\delta} - x\|$.
% 
% \end{frame}

%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Tikhonov regularization}
% where $N_r:L^2(\partial\Omega)\to L^2(\partial\Omega)$ is a compact operator.
% \par
We proceed with the {\color{blue}Tikhonov regularization}, minimizing the functional $J_\alpha$
% $J_\alpha:X\to \mathbb{R}$ as
 \begin{equation}
  \textup{min}\,J_\alpha(x),
 \end{equation}
where $J_\alpha(x)\coloneqq\|Kx - y\|^2 + \alpha\|x\|^2\quad x\in X$. It's
\begin{center}
\emph{
% We can interpret it as
%  the minimization of $J_\alpha$, as 
%  \begin{itemize}
the minimization of the residual $\|Kx^{\alpha} - y\|$,
penalized by 
% the norm of the solution 
$\|x^\alpha\|$.
%  \end{itemize}
}
\end{center}
We compute the solution imposing vanishing of the first derivative
\begin{align}
 &\alpha x^{\alpha} + K^TKx^{\alpha} = K^Ty.
%  &\alpha_n f_n^{\alpha_n} + N_{rn}^TN_{rn}f_n^{\alpha_n} = \psi_{0zn}\label{eq:tikh-reg-lsm-discrete}.
\end{align}
In terms of the discretized relative map $N_{rn}$, we solve
\begin{align}
%  &\alpha_n f^{\alpha_n} + N_r^TN_rf^{\alpha_n} = \psi_{0z}\label{eq:tikh-reg-lsm}, \\
 &\alpha f_n^{\alpha} + N_{rn}^TN_{rn}f_n^{\alpha} = N_{rn}^T\psi_{0zn}\label{eq:tikh-reg-lsm-discrete}.
\end{align}

\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Discrepancy Principle of Morozov}
 \begin{definition}
 We denote by $\Delta(\alpha)$ the \emph{discrepancy} function
%  and its variants. The mostly used 
%  are the classical and the normalized discrepancy:
 \begin{align}
  \Delta(\alpha)&\coloneqq\|Kx^{\alpha,\delta} - y^\delta\| - \delta, \label{eq:def-disc}\\
  \Delta_N(\alpha)&\coloneqq\|Kx^{\alpha,\delta} - y^\delta\| - \delta\|x^{\alpha,\delta}\|.\label{eq:def-disc-N}
 \end{align}
%  \begin{align}
%   \Delta(\alpha)&\coloneqq\|N_rf^{\alpha,\delta} - \psi_{0z}^\delta\| - \delta, \label{eq:def-disc}\\
%   \Delta_N(\alpha)&\coloneqq\|N_rf^{\alpha,\delta} - \psi_{0z}^\delta\| - \delta\|f^{\alpha,\delta}\|.\label{eq:def-disc-N}
%  \end{align}
\end{definition}
Therefore the determination of $\alpha(\delta)$ is equivalent to the computation 
of the unique zero of the function $\Delta_N(\alpha)$.
\begin{proposition}
\label{prop:strategy-disc}
%  By previous Proposition \ref{prop:properties-disc}, let $\delta$ be fixed, then there 
%  exists unique zero $\alpha^*(\delta)$ of the discrepancy function, 
%  such that $\Delta\bigl(\alpha^*\bigr)=0$. The same is still true for $\Delta_N(\alpha)$ 
%  (see \cite{kirsch:shape-1998}).
 Let $\delta$ be fixed, then there exists a unique 
 couple $(\alpha(\delta), x^{\alpha(\delta)})$ such that
 \begin{equation}
  \left\{
  \begin{split}
   & \alpha(\delta) x^{\alpha(\delta)} + K^TKx^{\alpha(\delta)} = K^Ty^\delta, \\
   & \Delta(\alpha(\delta))=0, \quad\textup{ or }\quad \Delta_N(\alpha(\delta))=0.
  \end{split}
  \right.
 \end{equation}
\end{proposition}
\end{frame}
%%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Validation}
Let $\tilde{R}_\alpha$ be a regularization, then there holds the same for $R_\alpha\coloneqq TA\tilde{R}_\alpha$
\begin{columns}[T]
 \begin{column}{0.5\textwidth}
  \begin{tikzpicture}
 \node at (0,0) {$ L^2_0(\partial \Omega) \xrightarrow{A} Z \xrightarrow{T} Z\xrightarrow{A^*} L^2_0(\partial\Omega)$};
%  \node[label=below:$x_1$]  (x1) at (-5,0)  {$\bullet$};
%  \node[label=above:$x_0$]  (x0) at (5,0)  {$\bullet$};  
 \node (x1) at (1.8, 0.1) {$ $};
 \node (x0) at (-1.8, 0.1) {$ $};  
 \node (x1_2) at (1.8, -0.2) {$ $};
 \node (x0_2) at (0.5, -0.2) {$ $};  
%  \node (x1) at (3.5, 0.1) {$ $};
%  \node (x0) at (-3.5, 0.1) {$ $};  
%  \node (x1_2) at (3.5, -0.2) {$ $};
%  \node (x0_2) at (1, -0.2) {$ $};  
 
%  \draw[->] ($(R.east)+(20pt,0)$)  to [out=0,in=140] node[right,midway]{$F(1,t_2)$}(x1);
 \draw[->] (x1) to [out=130,in=50] node[above,midway]{$\tilde{R}_\alpha$}(x0);
 \draw[->] (x1_2) to [out=-130,in=-50] node[below,midway]{$R_\alpha$}(x0_2);
\end{tikzpicture}
 \end{column}
 \begin{column}{0.5\textwidth}
 \begin{itemize}
  \item $f_z^{\alpha_n}:=\tilde{R}_{\alpha_n}\psi_{0z}$,
  \item $\phi_z^{\alpha_n}:=R_{\alpha_n}\psi_{0z} = TA f_z^{\alpha_n}$
 \end{itemize}
  \end{column}
\end{columns}

\begin{corollary}
%  Let $\tilde{R}_\alpha$ and $R_\alpha$ regularizations for some admissible strategy $\alpha_n\to 0$, defined previously and set
%  \begin{equation}
%   f_z^{\alpha_n}:=\tilde{R}_{\alpha_n}\psi_{0z},\quad \phi_z^{\alpha_n}:=R_{\alpha_n}\psi_{0z},\quad\textup{ for }\alpha_n \to 0.
%  \end{equation}
%  In addition, there holds the direct relation
%  \begin{equation}
%   \phi_z^{\alpha_n} = TAf_z^{\alpha_n}.
%  \end{equation}
Then
\begin{enumerate}
%  \item if $z\in D$, then $\phi_z^{\alpha_n}$ is a converging sequence, and $f_z^{\alpha_n}$ cannot diverge, it's bounded
 \item if $z\notin D$, $A^*\phi_z^{\alpha_n} = {N_r}f_z^{\alpha_n}$ is an 
 approximating sequence, and
%  by Theorem \ref{prop:lsm-counterpart}
%  we have $\|\phi_z^{\alpha_n}\|\to\infty$. Furthermore boundedness of $TA$ implies $\|f_z^{\alpha_n}\|\to\infty$;
\begin{equation*}
 \|\phi_z^{\alpha_n}\|\to\infty\,\Rightarrow\|f_z^{\alpha_n}\|\to\infty,
\end{equation*}

 \item if $z \in D$, 
%  $\phi_z^{\alpha_n}\to \phi$ for some $\phi\in Z$, such that $A^*\phi = \psi_{0z}$. If the corresponding $f_z^{\alpha_n}$ would be bounded, by compactness with respect of weak convergence in $L^2_0(\partial\Omega)$, and by compactness of $A$, up to renaming some subsequence,
%  \begin{equation}
%   f_z^{\alpha_n}\rightharpoonup f \,\Rightarrow \phi_z^{\alpha_n} \to TA f = \phi.
%  \end{equation}
% Consequently, as necessary condition, $\psi_{0z}=A^*TAf$ and $\psi_{0z}\in\mathcal{R}({N_r})$, which is not always verified by all points $z\in D$.
% This last observation implies boundedness of the sequence $f_z^{\alpha_n}$ only for $\psi_{0z}\in\mathcal{R}({N_r})$.
the sequence $f_z^{\alpha_n}$ is bounded only for $\psi_{0z}\in\mathcal{R}({N_r})$, but 
$$
z\in D \centernot\implies \psi_{0z}\in\mathcal{R}({N_r}).
$$
\end{enumerate}
\end{corollary}

\end{frame}

%%%%%%%%%%%%%%%%%
\begin{frame}[noframenumbering]
 \begin{center}
 \Large
 3. Factorization method 
 \end{center}
\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Factorization method}
 The aim is to factorize the relative Neumann--to--Dirichlet map ${N_0} - {N_D}$, in the form
\begin{equation}
 {N_r}\coloneqq{N_0} - {N_D} = A^*TA,
\end{equation}
where
% $A,T$ are operators suitably chosen and 
$A^*$ is the adjoint operator of A. 
The choice of the operators is not unique, for instance
\begin{columns}[T]
\begin{column}{0.5\textwidth}
\vspace{0.8cm}
\begin{itemize}
 \item 
%  $A:L^2_0(\partial \Omega) \to L^2(D;\,\mathbb{R}^2)$ defined as 
 $A\,f = \nabla v|_D,$
 \item 
%  $T:L^2(D;\,\mathbb{R}^2)\to L^2(D;\,\mathbb{R}^2)$ as 
 $TA\,f = 
%  (k-1) (\nabla v - \nabla w) =
 (k-1) \nabla u|_D.$
\end{itemize}\end{column}
\begin{column}{0.5\textwidth}
\begin{tikzpicture}
    % set up the nodes
    \node (n11) at (0,0) {$L^2_0(\partial\Omega)$};
    \node[right=of n11] (n12) {$L^2(D;\,\mathbb{R}^2)$};
    \node[below=of n12] (n22) {$L^2(D;\,\mathbb{R}^2)$};
    \node[below=of n11] (n21) {$L^2_0(\partial\Omega)$};
    \node (n112) at ([xshift=0.1]n11) {$ $};
    \node (n212) at ([xshift=0.1]n21) {$ $};
    % draw arrows and text between them
    \draw[->] (n11) to node [midway,right] {${N_r}$} (n21);
    \draw[->] (n11) to node [midway,above] {$A$} (n12);
    \draw[->] (n12) to node [midway,right] {$T$} (n22);
    \draw[->] (n22) to node [midway,above] {$A^*$} (n21);
%     \draw[->] (n21.south) [out=-60, in=-120]to node [midway,below] {$R_\alpha$} (n22.south);
%     \draw[->] (n21.west) [out=170, in=-170]to node [midway,left] {$\tilde{R}_\alpha$} (n11.west);
\end{tikzpicture}
\end{column}
\end{columns}

\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Range characterization}
\begin{theorem}
 There holds the equivalence 
 \begin{equation}
  z \in D \,\Longleftrightarrow \,\psi_{0z} \in \mathcal{R}(A^*).
 \end{equation}
\end{theorem}
Both the following factorizations hold
\begin{align*}
\label{eq:factorization-two}
 {N_0} - {N_D}&=({N_0} - {N_D})^{1/2}\,I\,({N_0} - {N_D})^{1/2}\\
 &= A^*TA.
\end{align*}
\vspace{-0.8cm}
 \begin{theorem}
 The range of two operators is the same, that is
 \begin{equation}
  \mathcal{R}(A^*) = \mathcal{R}(({N_0} - {N_D})^{1/2}).
 \end{equation}
Therefore an equivalent criterion can be stated as
 \begin{equation}
  z \in D \,\Longleftrightarrow \,\psi_{0z} \in \mathcal{R}(({N_0} - {N_D})^{1/2}).
 \end{equation}
\end{theorem}
\end{frame}
%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{Range criterion}
We compute the square root of a
compact, self-adjoint and positive operator 
from its spectral decomposition
\begin{align}
({N_0} - {N_D}) f &= \sum_{j\in \mathbb{N}}^\infty \lambda_j(f,\psi_j)_{L^2(\partial\Omega)} \psi_j ,\\
({N_0} - {N_D})^{1/2} f &= \sum_{j\in \mathbb{N}}^\infty \sqrt{\lambda_j}(f,\psi_j)_{L^2(\partial\Omega)} \psi_j.
\end{align}
We deduce, by Picard's theorem,
\begin{equation}
   \psi_{0z} \in \mathcal{R}(({N_0} - {N_D})^{1/2})
   \,\Longleftrightarrow \,
   \sum_{j\in \mathbb{N}}^\infty \frac{(\psi_{0z},\psi_j)^2}{\lambda_j}<\infty. 
\end{equation}
\end{frame}
%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Range criterion}
%  a test to establish the convergence of the previous sum, with finitely many terms, after discretization. 
In most of geometries, the decay of singular values $\bigl\{\lambda_j\bigr\}_j$ is typically exponential
% Let's assume an exponential behavior for the components $(\psi_{0z},\psi_j )^2$, parametrized as
\begin{align}
 \lambda_j &\sim a_j (r_j) ^j,  & \log\lambda_j &\sim c_j + j\log r_j,\label{eq:straightline-eig}\\
 (\psi_{0z}, \psi_j)^2 &\sim A_j(R_j)^j, & \log(\psi_{0z}, \psi_j)^2 &\sim C_j + j\log R_j\label{eq:straightline-data},
\end{align}
\vspace{0.1cm}
% then we comparing the slopes of the straight lines
% interpolating 
% eigenvalues \eqref{eq:straightline-eig} and computed data \eqref{eq:straightline-data}
\begin{columns}[T]
\begin{column}{0.42\textwidth}
\vspace{0.1cm}
then we compare the slopes of the straight lines
\begin{equation*}
 z\in D \,\Longleftrightarrow\,
%  \dfrac{R_j}{r_j} < 1 \,\Longleftrightarrow\,
 \log R_j < \log r_j.
\end{equation*}
{
\scriptsize
\begin{itemize}
 \item[$\bullet$] $\bigtriangleup$ for components of $\psi_{0z}$ with $z\in D$
 \item[$\bullet$] $\bigtriangledown$ for components of $\psi_{0z}$ with $z\notin D$
 \item[$\bullet$] $\circ$ for eigenvalues $\lambda_j$
\end{itemize}
}
\end{column}
\begin{column}{0.6\textwidth}
\centering
\includegraphics[width=0.7\textwidth]{fig/first_compare_factcases_fm_one_ellipse_m040_eig}
\end{column}
\end{columns}
\end{frame}
%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
 \frametitle{Algorithm}
  \begin{columns}[T]
    \begin{column}{0.5\textwidth}
    \footnotesize
     \begin{lstlisting}
      fix $n$, $\delta$
      COMPUTE direct relative map $N_{rn}$
      |\textbf{for} z \textbf{in} samplingSet|
        fix $\alpha_n$
        |\textbf{for} k \textbf{in} numberIterationsAlpha|
          SOLVE $(\alpha^{(k)}_nI + N_{rn}^TN_{rn})f_n=N_{rn}^T\psi_{0z}$
          UPDATE $\alpha^{(k)}_n$
          
        COMPUTE $r(z) = \|\psi_{0z}\| / \|f_n\|$
        
      plot $r(z)$
      
     \end{lstlisting}

     

    \end{column}
  \begin{column}{0.5\textwidth}
  \begin{center}
    \begin{tikzpicture}
%      \foreach \i in {\xMin,...,\xMax} {
%         \draw [very thin,gray] (\i,\yMin) -- (\i,\yMax)  node [below] at (\i,\yMin) {$\i$};
%     }
%     \foreach \i in {\yMin,...,\yMax} {
%         \draw [very thin,gray] (\xMin,\i) -- (\xMax,\i) node [left] at (\xMin,\i) {$\i$};
%     }

    \draw [fill=light-gray, draw=gray] (0,0) ellipse (2cm and 1.5cm);
    \filldraw [fill=dark-gray, draw=gray] (0, -0.1) 
     .. controls ++(165:-0.2) and ++(90:-0.5) .. ( 1, 0.1)
     .. controls ++(90:0.5) and ++(1:0.5) .. (0.2, 0.5)
     .. controls ++(1:-0.5) and ++(60:0.7) .. (-0.6, 0.2)
     .. controls ++(60:-0.7) and ++(165:0.2) .. ( 0, -0.1);
%     \node at (-2.2,0.7){${\partial \Omega}$};
%     \node at (-0.6,0.7){${\partial D}$};
    \node at (-1.2,0.1){$\Omega, 1$};
    \node at (0.1,0.1){$D, k$};
\draw [step=0.5,blue, thin] (-2.2,-1.8) grid (2.2,1.8);
\end{tikzpicture}
\end{center}
\end{column}
\end{columns}
\end{frame}
%%%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{}
{
\includegraphics[width=.30\textwidth]{fig/one_ellipse_lsm_ellipse2_alpha1e-06_no100nd80}
}
{
\includegraphics[width=.30\textwidth]{fig/one_ellipse_lsm_ellipse2_alpha1e-10_no100nd80}
}
{
\includegraphics[width=.30\textwidth]{fig/one_ellipse_lsm_ellipse2_alpha1e-13_no100nd80}
}
\\
Shape and size approximations for an elliptic sharp inclusion, with $\alpha=\mathrm{1e}{-6}$, 
$\alpha=\mathrm{1e}{-10}$, $\alpha=\mathrm{1e}{-13}$ respectively, and $m=30$ in FM.

\end{frame}
%%%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{}
{
\includegraphics[width=.30\textwidth, height=.30\textwidth]{fig/first_compare_fm_two_ellipse_m040_eig}
}
{
\includegraphics[width=.30\textwidth]{fig/first_compare_fm_two_ellipse0_m030}
}
{
\includegraphics[width=.30\textwidth]{fig/first_compare_fm_two_ellipse0_m040}
}\\
Factorization Method for $m=30$, $m=40$, respectively. The linear regression of the
eigenvalues $\log\lambda_j$ of the map $N_r$ in Figure \ref{subfig:eig_two_ellipse} suggests $m=40$ as the best choice.
\end{frame}
%%%%%%%%%%%%%%%%%%%
% \begin{frame}
%  \frametitle{}
% {
% \includegraphics[width=.30\textwidth, height=.30\textwidth]{fig/first_compare_fm_three_ellipse_m030_eig}
% }
% {
% \includegraphics[width=.30\textwidth]{fig/first_compare_fm_three_ellipse0_m030}
% }
% {
% \includegraphics[width=.30\textwidth]{fig/first_compare_fm_three_ellipse0_m040}
% }
% \\
% Factorization Method for $m=30$, $m=40$, respectively. The linear regression of the
% eigenvalues $\log\lambda_j$ of the map $N_r$ in Figure \ref{subfig:eig_three_ellipse} suggests  $m=30$ as the best choice.
% \end{frame}
%%%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{}
\end{frame}
%%%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{}
\end{frame}
%%%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{}
\end{frame}
%%%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{}
\end{frame}
%%%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{}
\end{frame}
\end{document}
 \begin{equation}
  (({N_D} - {N_0})f,f) = ( Af,TAf) \geq c\|Af\|^2_{L^2(D;\,\mathbb{R}^2)} > 0 \quad \forall f\in L^2_0(\partial \Omega) \quad f\neq0.
 \end{equation}
